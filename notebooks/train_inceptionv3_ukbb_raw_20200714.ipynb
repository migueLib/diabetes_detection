{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import abspath\n",
    "import sys\n",
    "import torch\n",
    "import copy\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/diabetes_detection'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load local libraries\n",
    "# ROOT contais the project directory \n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import local libraries\n",
    "from src.logger import set_logger as sl\n",
    "\n",
    "# Load transformations\n",
    "from src.transformations.CC_RRC_RVF_RHF_RA import get_transform as gt_train\n",
    "from src.transformations.CC_R import get_transform as gt_valid\n",
    "from src.plot_images import plot_images\n",
    "from src.train_validation import train_validation_phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up logger\n",
    "try:\n",
    "    if logger is None:\n",
    "        logger = sl(\"info\")\n",
    "except:\n",
    "    logger = sl(\"info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put data\n",
    "epochs        = 100\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum      = 0.9\n",
    "\n",
    "batch_size    = 16\n",
    "num_workers   = os.cpu_count()\n",
    "is_pretrained = False\n",
    "\n",
    "crop_size     = 1536\n",
    "im_size       = (800, 800)\n",
    "is_grayscale  = False\n",
    "\n",
    "train_pth     = abspath('./data/raw/train/')\n",
    "valid_pth     = abspath('./data/raw/validation/')\n",
    "\n",
    "name = f\"diabetes_ukkb-raw-4da-cs{crop_size}-ims{im_size[0]}x{im_size[1]}_iv3-e{epochs}-bs{batch_size}-lrv{str(learning_rate)[2:]}-m{str(momentum)[2:]}\"\n",
    "\n",
    "model_pth     = abspath(f'./output/models/{name}.pth')\n",
    "\n",
    "device        = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-25 11:12:23,198 - INFO - System Python version  = 3.7.9 (default, Aug 31 2020, 12:42:55) \n",
      "[GCC 7.3.0]\n",
      "2020-10-25 11:12:23,199 - INFO - System Pytorch version = 1.6.0\n",
      "2020-10-25 11:12:23,200 - INFO - System usable CPUs     = 4\n",
      "2020-10-25 11:12:23,200 - INFO - System training device = cpu\n",
      "2020-10-25 11:12:23,201 - INFO - Path working directory = /home/ubuntu/diabetes_detection\n",
      "2020-10-25 11:12:23,202 - INFO - Path input train       = /home/ubuntu/diabetes_detection/data/raw/train\n",
      "2020-10-25 11:12:23,203 - INFO - Path input validation  = /home/ubuntu/diabetes_detection/data/raw/validation\n",
      "2020-10-25 11:12:23,203 - INFO - Path model             = /home/ubuntu/diabetes_detection/output/models/diabetes_ukkb-raw-4da-cs1536-ims800x800_iv3-e100-bs16-lrv01-m9.pth\n",
      "2020-10-25 11:12:23,204 - INFO - Model learning rate    = 0.01\n",
      "2020-10-25 11:12:23,204 - INFO - Model momentum         = 0.9\n",
      "2020-10-25 11:12:23,205 - INFO - Model batch_size       = 16\n",
      "2020-10-25 11:12:23,206 - INFO - Model num_workers      = 4\n",
      "2020-10-25 11:12:23,207 - INFO - Model pretrained       = False\n"
     ]
    }
   ],
   "source": [
    "######################################################################################\n",
    "# Initial report\n",
    "logger.info(f\"System Python version  = {sys.version}\")\n",
    "logger.info(f\"System Pytorch version = {torch.__version__}\")\n",
    "logger.info(f\"System usable CPUs     = {os.cpu_count()}\")\n",
    "\n",
    "# Device setting and CUDA report \n",
    "logger.info(f\"System training device = {device}\")\n",
    "if  torch.cuda.is_available():\n",
    "    logger.info(f\"System CUDA version    = {torch.version.cuda}\")\n",
    "    logger.info(f\"System CUDA count      = {torch.cuda.device_count()}\")\n",
    "    logger.info(f\"System CUDA name       = {torch.cuda.get_device_name()}\")\n",
    "    \n",
    "# Load train and validation dataset\n",
    "logger.info(f\"Path working directory = {os.getcwd()}\")\n",
    "logger.info(f\"Path input train       = {train_pth}\")\n",
    "logger.info(f\"Path input validation  = {valid_pth}\")\n",
    "logger.info(f\"Path model             = {model_pth}\")\n",
    "\n",
    "# Starting momentum and learning rate\n",
    "logger.info(f\"Model learning rate    = {learning_rate}\")\n",
    "logger.info(f\"Model momentum         = {momentum}\")\n",
    "logger.info(f\"Model batch_size       = {batch_size}\")\n",
    "logger.info(f\"Model num_workers      = {num_workers}\")\n",
    "logger.info(f\"Model pretrained       = {is_pretrained}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-20 10:25:49,178 - INFO - Loading datasets\n",
      "2020-10-20 10:25:50,644 - INFO - Dataset size training   = 29640\n",
      "2020-10-20 10:25:50,645 - INFO - Dataset size validation = 1483\n",
      "2020-10-20 10:25:50,646 - INFO - Dataset labels/classes  = ['nont2d', 't2d']\n",
      "2020-10-20 10:25:50,647 - INFO - Loading dataloaders\n",
      "2020-10-20 10:25:50,648 - INFO - Plot sample images\n",
      "nont2d nont2d nont2d nont2d nont2d   t2d nont2d nont2d\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "######################################################################################\n",
    "# Load datasets and apply transformations\n",
    "logger.info(f\"Loading datasets\")\n",
    "dataset = dict()\n",
    "dataset[\"train\"] = datasets.ImageFolder(train_pth, gt_train(crop_size, resize=im_size, grayscale=is_grayscale))\n",
    "dataset[\"valid\"] = datasets.ImageFolder(valid_pth, gt_valid(crop_size, resize=im_size, grayscale=is_grayscale))\n",
    "\n",
    "# Get the size of the datasets train and valid(ation)\n",
    "size = dict()\n",
    "size[\"train\"] = len(dataset[\"train\"])\n",
    "size[\"valid\"] = len(dataset[\"valid\"])\n",
    "logger.info(f\"Dataset size training   = {size['train']}\")\n",
    "logger.info(f\"Dataset size validation = {size['valid']}\")\n",
    "logger.info(f\"Dataset labels/classes  = {dataset['train'].classes}\")\n",
    "\n",
    "# Dataloader for train and valid(ation)\n",
    "logger.info(f\"Loading dataloaders\")\n",
    "dataloader = dict()\n",
    "dataloader[\"train\"] = DataLoader(dataset[\"train\"], batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "dataloader[\"valid\"] = DataLoader(dataset[\"valid\"], batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "######################################################################################\n",
    "# Get sample images\n",
    "logger.info(f\"Plot sample images\")\n",
    "plot_images(dataloader[\"train\"],  dataset[\"train\"].classes, title=\"Sample Fundus\", save=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.miniconda3/envs/dd/lib/python3.7/site-packages/torchvision/models/inception.py:77: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  ' due to scipy/scipy#11299), please set init_weights=True.', FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-20 10:26:17,556 - INFO - Model loading            = Inception3\n",
      "2020-10-20 10:26:17,559 - INFO - Model number of features = 2048\n",
      "2020-10-20 10:26:17,608 - INFO - Let's use 8 GPUs!\n",
      "2020-10-20 10:26:58,652 - INFO - Epoch [  1/100] - Batch [     0/ 29640] ( 0%) - Loss 0.7203\n",
      "2020-10-20 10:28:06,945 - INFO - Epoch [  1/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.6218\n",
      "2020-10-20 10:29:14,668 - INFO - Epoch [  1/100] - Batch [  3200/ 29640] (11%) - Loss 0.5806\n",
      "2020-10-20 10:30:22,321 - INFO - Epoch [  1/100] - Batch [  4800/ 29640] (16%) - Loss 0.5092\n",
      "2020-10-20 10:31:30,280 - INFO - Epoch [  1/100] - Batch [  6400/ 29640] (22%) - Loss 0.6027\n",
      "2020-10-20 10:32:38,059 - INFO - Epoch [  1/100] - Batch [  8000/ 29640] (27%) - Loss 0.5546\n",
      "2020-10-20 10:33:45,832 - INFO - Epoch [  1/100] - Batch [  9600/ 29640] (32%) - Loss 0.4356\n",
      "2020-10-20 10:34:53,596 - INFO - Epoch [  1/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3008\n",
      "2020-10-20 10:36:01,324 - INFO - Epoch [  1/100] - Batch [ 12800/ 29640] (43%) - Loss 0.2285\n",
      "2020-10-20 10:37:09,204 - INFO - Epoch [  1/100] - Batch [ 14400/ 29640] (49%) - Loss 0.5674\n",
      "2020-10-20 10:38:16,491 - INFO - Epoch [  1/100] - Batch [ 16000/ 29640] (54%) - Loss 0.7395\n",
      "2020-10-20 10:39:23,899 - INFO - Epoch [  1/100] - Batch [ 17600/ 29640] (59%) - Loss 0.1097\n",
      "2020-10-20 10:40:32,151 - INFO - Epoch [  1/100] - Batch [ 19200/ 29640] (65%) - Loss 0.3441\n",
      "2020-10-20 10:41:40,379 - INFO - Epoch [  1/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5558\n",
      "2020-10-20 10:42:48,487 - INFO - Epoch [  1/100] - Batch [ 22400/ 29640] (76%) - Loss 0.6143\n",
      "2020-10-20 10:43:56,044 - INFO - Epoch [  1/100] - Batch [ 24000/ 29640] (81%) - Loss 0.6372\n",
      "2020-10-20 10:45:03,727 - INFO - Epoch [  1/100] - Batch [ 25600/ 29640] (86%) - Loss 0.5835\n",
      "2020-10-20 10:46:10,901 - INFO - Epoch [  1/100] - Batch [ 27200/ 29640] (92%) - Loss 0.4794\n",
      "2020-10-20 10:47:17,649 - INFO - Epoch [  1/100] - Batch [ 28800/ 29640] (97%) - Loss 0.6156\n",
      "2020-10-20 10:47:52,422 - INFO - Current lr: 0.01\n",
      "2020-10-20 10:47:52,423 - INFO - train, Loss: 0.6018 Acc: 0.7668\n",
      "2020-10-20 10:48:08,575 - INFO - Epoch [  1/100] - Batch [     0/  1483] ( 0%) - Loss 1.3988\n",
      "2020-10-20 10:48:40,579 - INFO - Current lr: 0.01\n",
      "2020-10-20 10:48:40,580 - INFO - valid, Loss: 2.1957 Acc: 0.5017\n",
      "0.5014893559248399\n",
      "2020-10-20 10:48:50,317 - INFO - Epoch [  2/100] - Batch [     0/ 29640] ( 0%) - Loss 0.3291\n",
      "2020-10-20 10:50:02,796 - INFO - Epoch [  2/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.3642\n",
      "2020-10-20 10:51:11,861 - INFO - Epoch [  2/100] - Batch [  3200/ 29640] (11%) - Loss 0.2853\n",
      "2020-10-20 10:52:20,364 - INFO - Epoch [  2/100] - Batch [  4800/ 29640] (16%) - Loss 0.5655\n",
      "2020-10-20 10:53:28,743 - INFO - Epoch [  2/100] - Batch [  6400/ 29640] (22%) - Loss 0.3987\n",
      "2020-10-20 10:54:37,256 - INFO - Epoch [  2/100] - Batch [  8000/ 29640] (27%) - Loss 0.3747\n",
      "2020-10-20 10:55:45,776 - INFO - Epoch [  2/100] - Batch [  9600/ 29640] (32%) - Loss 0.5466\n",
      "2020-10-20 10:56:54,755 - INFO - Epoch [  2/100] - Batch [ 11200/ 29640] (38%) - Loss 0.8039\n",
      "2020-10-20 10:58:03,015 - INFO - Epoch [  2/100] - Batch [ 12800/ 29640] (43%) - Loss 0.2635\n",
      "2020-10-20 10:59:11,112 - INFO - Epoch [  2/100] - Batch [ 14400/ 29640] (49%) - Loss 0.6456\n",
      "2020-10-20 11:00:19,314 - INFO - Epoch [  2/100] - Batch [ 16000/ 29640] (54%) - Loss 0.6386\n",
      "2020-10-20 11:01:28,067 - INFO - Epoch [  2/100] - Batch [ 17600/ 29640] (59%) - Loss 0.5454\n",
      "2020-10-20 11:02:36,667 - INFO - Epoch [  2/100] - Batch [ 19200/ 29640] (65%) - Loss 0.3817\n",
      "2020-10-20 11:03:45,123 - INFO - Epoch [  2/100] - Batch [ 20800/ 29640] (70%) - Loss 0.2469\n",
      "2020-10-20 11:04:53,610 - INFO - Epoch [  2/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4378\n",
      "2020-10-20 11:06:02,175 - INFO - Epoch [  2/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4236\n",
      "2020-10-20 11:07:10,602 - INFO - Epoch [  2/100] - Batch [ 25600/ 29640] (86%) - Loss 0.2934\n",
      "2020-10-20 11:08:17,920 - INFO - Epoch [  2/100] - Batch [ 27200/ 29640] (92%) - Loss 0.5050\n",
      "2020-10-20 11:09:23,924 - INFO - Epoch [  2/100] - Batch [ 28800/ 29640] (97%) - Loss 0.4372\n",
      "2020-10-20 11:09:58,506 - INFO - Current lr: 0.01\n",
      "2020-10-20 11:09:58,508 - INFO - train, Loss: 0.5312 Acc: 0.7927\n",
      "2020-10-20 11:10:09,559 - INFO - Epoch [  2/100] - Batch [     0/  1483] ( 0%) - Loss 9.3652\n",
      "2020-10-20 11:10:41,596 - INFO - Current lr: 0.01\n",
      "2020-10-20 11:10:41,597 - INFO - valid, Loss: 29.3377 Acc: 0.5003\n",
      "0.5\n",
      "2020-10-20 11:10:54,725 - INFO - Epoch [  3/100] - Batch [     0/ 29640] ( 0%) - Loss 0.7627\n",
      "2020-10-20 11:12:05,183 - INFO - Epoch [  3/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.4436\n",
      "2020-10-20 11:13:14,632 - INFO - Epoch [  3/100] - Batch [  3200/ 29640] (11%) - Loss 0.4167\n",
      "2020-10-20 11:14:23,786 - INFO - Epoch [  3/100] - Batch [  4800/ 29640] (16%) - Loss 0.4024\n",
      "2020-10-20 11:15:32,785 - INFO - Epoch [  3/100] - Batch [  6400/ 29640] (22%) - Loss 0.4794\n",
      "2020-10-20 11:16:41,700 - INFO - Epoch [  3/100] - Batch [  8000/ 29640] (27%) - Loss 0.2278\n",
      "2020-10-20 11:17:50,488 - INFO - Epoch [  3/100] - Batch [  9600/ 29640] (32%) - Loss 0.8490\n",
      "2020-10-20 11:18:59,309 - INFO - Epoch [  3/100] - Batch [ 11200/ 29640] (38%) - Loss 0.4394\n",
      "2020-10-20 11:20:07,965 - INFO - Epoch [  3/100] - Batch [ 12800/ 29640] (43%) - Loss 0.5155\n",
      "2020-10-20 11:21:16,425 - INFO - Epoch [  3/100] - Batch [ 14400/ 29640] (49%) - Loss 0.6152\n",
      "2020-10-20 11:22:25,011 - INFO - Epoch [  3/100] - Batch [ 16000/ 29640] (54%) - Loss 0.4544\n",
      "2020-10-20 11:23:33,618 - INFO - Epoch [  3/100] - Batch [ 17600/ 29640] (59%) - Loss 0.8180\n",
      "2020-10-20 11:24:42,362 - INFO - Epoch [  3/100] - Batch [ 19200/ 29640] (65%) - Loss 0.5385\n",
      "2020-10-20 11:25:51,225 - INFO - Epoch [  3/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5859\n",
      "2020-10-20 11:27:00,465 - INFO - Epoch [  3/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4015\n",
      "2020-10-20 11:28:09,431 - INFO - Epoch [  3/100] - Batch [ 24000/ 29640] (81%) - Loss 0.3218\n",
      "2020-10-20 11:29:18,607 - INFO - Epoch [  3/100] - Batch [ 25600/ 29640] (86%) - Loss 0.7363\n",
      "2020-10-20 11:30:27,022 - INFO - Epoch [  3/100] - Batch [ 27200/ 29640] (92%) - Loss 0.4392\n",
      "2020-10-20 11:31:34,263 - INFO - Epoch [  3/100] - Batch [ 28800/ 29640] (97%) - Loss 0.5655\n",
      "2020-10-20 11:32:09,121 - INFO - Current lr: 0.01\n",
      "2020-10-20 11:32:09,123 - INFO - train, Loss: 0.5206 Acc: 0.7975\n",
      "2020-10-20 11:32:16,112 - INFO - Epoch [  3/100] - Batch [     0/  1483] ( 0%) - Loss 0.9973\n",
      "2020-10-20 11:32:52,287 - INFO - Current lr: 0.01\n",
      "2020-10-20 11:32:52,288 - INFO - valid, Loss: 0.9423 Acc: 0.5010\n",
      "0.5015150918376725\n",
      "2020-10-20 11:33:05,747 - INFO - Epoch [  4/100] - Batch [     0/ 29640] ( 0%) - Loss 0.3553\n",
      "2020-10-20 11:34:15,854 - INFO - Epoch [  4/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.8890\n",
      "2020-10-20 11:35:24,755 - INFO - Epoch [  4/100] - Batch [  3200/ 29640] (11%) - Loss 0.5505\n",
      "2020-10-20 11:36:33,979 - INFO - Epoch [  4/100] - Batch [  4800/ 29640] (16%) - Loss 0.6522\n",
      "2020-10-20 11:37:43,483 - INFO - Epoch [  4/100] - Batch [  6400/ 29640] (22%) - Loss 0.6681\n",
      "2020-10-20 11:38:52,768 - INFO - Epoch [  4/100] - Batch [  8000/ 29640] (27%) - Loss 0.4584\n",
      "2020-10-20 11:40:01,839 - INFO - Epoch [  4/100] - Batch [  9600/ 29640] (32%) - Loss 0.4071\n",
      "2020-10-20 11:41:10,857 - INFO - Epoch [  4/100] - Batch [ 11200/ 29640] (38%) - Loss 0.4125\n",
      "2020-10-20 11:42:19,916 - INFO - Epoch [  4/100] - Batch [ 12800/ 29640] (43%) - Loss 0.5715\n",
      "2020-10-20 11:43:28,802 - INFO - Epoch [  4/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4155\n",
      "2020-10-20 11:44:37,818 - INFO - Epoch [  4/100] - Batch [ 16000/ 29640] (54%) - Loss 0.5103\n",
      "2020-10-20 11:45:47,177 - INFO - Epoch [  4/100] - Batch [ 17600/ 29640] (59%) - Loss 0.4408\n",
      "2020-10-20 11:46:56,687 - INFO - Epoch [  4/100] - Batch [ 19200/ 29640] (65%) - Loss 0.3454\n",
      "2020-10-20 11:48:05,921 - INFO - Epoch [  4/100] - Batch [ 20800/ 29640] (70%) - Loss 0.3783\n",
      "2020-10-20 11:49:14,950 - INFO - Epoch [  4/100] - Batch [ 22400/ 29640] (76%) - Loss 0.2850\n",
      "2020-10-20 11:50:24,375 - INFO - Epoch [  4/100] - Batch [ 24000/ 29640] (81%) - Loss 0.6601\n",
      "2020-10-20 11:51:33,578 - INFO - Epoch [  4/100] - Batch [ 25600/ 29640] (86%) - Loss 0.3793\n",
      "2020-10-20 11:52:41,718 - INFO - Epoch [  4/100] - Batch [ 27200/ 29640] (92%) - Loss 0.5418\n",
      "2020-10-20 11:53:48,510 - INFO - Epoch [  4/100] - Batch [ 28800/ 29640] (97%) - Loss 0.6149\n",
      "2020-10-20 11:54:23,258 - INFO - Current lr: 0.01\n",
      "2020-10-20 11:54:23,260 - INFO - train, Loss: 0.5136 Acc: 0.7989\n",
      "2020-10-20 11:54:31,262 - INFO - Epoch [  4/100] - Batch [     0/  1483] ( 0%) - Loss 2.7429\n",
      "2020-10-20 11:55:06,346 - INFO - Current lr: 0.01\n",
      "2020-10-20 11:55:06,348 - INFO - valid, Loss: 5.7436 Acc: 0.5003\n",
      "0.5\n",
      "2020-10-20 11:55:15,995 - INFO - Epoch [  5/100] - Batch [     0/ 29640] ( 0%) - Loss 0.5060\n",
      "2020-10-20 11:56:28,194 - INFO - Epoch [  5/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.3654\n",
      "2020-10-20 11:57:37,238 - INFO - Epoch [  5/100] - Batch [  3200/ 29640] (11%) - Loss 0.4535\n",
      "2020-10-20 11:58:45,848 - INFO - Epoch [  5/100] - Batch [  4800/ 29640] (16%) - Loss 0.3137\n",
      "2020-10-20 11:59:54,391 - INFO - Epoch [  5/100] - Batch [  6400/ 29640] (22%) - Loss 0.3355\n",
      "2020-10-20 12:01:03,135 - INFO - Epoch [  5/100] - Batch [  8000/ 29640] (27%) - Loss 0.6905\n",
      "2020-10-20 12:02:11,824 - INFO - Epoch [  5/100] - Batch [  9600/ 29640] (32%) - Loss 0.7306\n",
      "2020-10-20 12:03:20,687 - INFO - Epoch [  5/100] - Batch [ 11200/ 29640] (38%) - Loss 0.6926\n",
      "2020-10-20 12:04:29,203 - INFO - Epoch [  5/100] - Batch [ 12800/ 29640] (43%) - Loss 0.6830\n",
      "2020-10-20 12:05:37,633 - INFO - Epoch [  5/100] - Batch [ 14400/ 29640] (49%) - Loss 0.5754\n",
      "2020-10-20 12:06:46,241 - INFO - Epoch [  5/100] - Batch [ 16000/ 29640] (54%) - Loss 0.6416\n",
      "2020-10-20 12:07:54,824 - INFO - Epoch [  5/100] - Batch [ 17600/ 29640] (59%) - Loss 0.6280\n",
      "2020-10-20 12:09:03,382 - INFO - Epoch [  5/100] - Batch [ 19200/ 29640] (65%) - Loss 0.7394\n",
      "2020-10-20 12:10:11,701 - INFO - Epoch [  5/100] - Batch [ 20800/ 29640] (70%) - Loss 0.2624\n",
      "2020-10-20 12:11:19,908 - INFO - Epoch [  5/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4559\n",
      "2020-10-20 12:12:28,452 - INFO - Epoch [  5/100] - Batch [ 24000/ 29640] (81%) - Loss 0.3229\n",
      "2020-10-20 12:13:36,527 - INFO - Epoch [  5/100] - Batch [ 25600/ 29640] (86%) - Loss 0.5154\n",
      "2020-10-20 12:14:44,133 - INFO - Epoch [  5/100] - Batch [ 27200/ 29640] (92%) - Loss 0.5480\n",
      "2020-10-20 12:15:50,429 - INFO - Epoch [  5/100] - Batch [ 28800/ 29640] (97%) - Loss 0.6220\n",
      "2020-10-20 12:16:25,196 - INFO - Current lr: 0.01\n",
      "2020-10-20 12:16:25,197 - INFO - train, Loss: 0.5104 Acc: 0.7990\n",
      "2020-10-20 12:16:33,174 - INFO - Epoch [  5/100] - Batch [     0/  1483] ( 0%) - Loss 2.9064\n",
      "2020-10-20 12:17:06,704 - INFO - Current lr: 0.01\n",
      "2020-10-20 12:17:06,706 - INFO - valid, Loss: 1.2963 Acc: 0.4997\n",
      "0.4989247311827957\n",
      "2020-10-20 12:17:16,288 - INFO - Epoch [  6/100] - Batch [     0/ 29640] ( 0%) - Loss 0.2870\n",
      "2020-10-20 12:18:29,133 - INFO - Epoch [  6/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.3203\n",
      "2020-10-20 12:19:38,451 - INFO - Epoch [  6/100] - Batch [  3200/ 29640] (11%) - Loss 0.5326\n",
      "2020-10-20 12:20:47,446 - INFO - Epoch [  6/100] - Batch [  4800/ 29640] (16%) - Loss 0.3844\n",
      "2020-10-20 12:21:56,540 - INFO - Epoch [  6/100] - Batch [  6400/ 29640] (22%) - Loss 0.3496\n",
      "2020-10-20 12:23:05,611 - INFO - Epoch [  6/100] - Batch [  8000/ 29640] (27%) - Loss 0.4713\n",
      "2020-10-20 12:24:14,550 - INFO - Epoch [  6/100] - Batch [  9600/ 29640] (32%) - Loss 0.4168\n",
      "2020-10-20 12:25:23,654 - INFO - Epoch [  6/100] - Batch [ 11200/ 29640] (38%) - Loss 0.5193\n",
      "2020-10-20 12:26:33,085 - INFO - Epoch [  6/100] - Batch [ 12800/ 29640] (43%) - Loss 0.3680\n",
      "2020-10-20 12:27:42,922 - INFO - Epoch [  6/100] - Batch [ 14400/ 29640] (49%) - Loss 0.5741\n",
      "2020-10-20 12:28:52,353 - INFO - Epoch [  6/100] - Batch [ 16000/ 29640] (54%) - Loss 0.9565\n",
      "2020-10-20 12:30:01,628 - INFO - Epoch [  6/100] - Batch [ 17600/ 29640] (59%) - Loss 0.3455\n",
      "2020-10-20 12:31:11,173 - INFO - Epoch [  6/100] - Batch [ 19200/ 29640] (65%) - Loss 0.4957\n",
      "2020-10-20 12:32:20,624 - INFO - Epoch [  6/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5297\n",
      "2020-10-20 12:33:29,559 - INFO - Epoch [  6/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5966\n",
      "2020-10-20 12:34:38,619 - INFO - Epoch [  6/100] - Batch [ 24000/ 29640] (81%) - Loss 0.3645\n",
      "2020-10-20 12:35:47,874 - INFO - Epoch [  6/100] - Batch [ 25600/ 29640] (86%) - Loss 0.5170\n",
      "2020-10-20 12:36:56,560 - INFO - Epoch [  6/100] - Batch [ 27200/ 29640] (92%) - Loss 0.5822\n",
      "2020-10-20 12:38:03,731 - INFO - Epoch [  6/100] - Batch [ 28800/ 29640] (97%) - Loss 0.6917\n",
      "2020-10-20 12:38:38,778 - INFO - Current lr: 0.01\n",
      "2020-10-20 12:38:38,779 - INFO - train, Loss: 0.5060 Acc: 0.7995\n",
      "2020-10-20 12:38:45,990 - INFO - Epoch [  6/100] - Batch [     0/  1483] ( 0%) - Loss 0.7836\n",
      "2020-10-20 12:39:21,107 - INFO - Current lr: 0.01\n",
      "2020-10-20 12:39:21,108 - INFO - valid, Loss: 1.6454 Acc: 0.4700\n",
      "0.47064772145417294\n",
      "2020-10-20 12:39:21,109 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-20 12:39:31,372 - INFO - Epoch [  7/100] - Batch [     0/ 29640] ( 0%) - Loss 0.3213\n",
      "2020-10-20 12:40:43,063 - INFO - Epoch [  7/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.4297\n",
      "2020-10-20 12:41:52,521 - INFO - Epoch [  7/100] - Batch [  3200/ 29640] (11%) - Loss 0.4800\n",
      "2020-10-20 12:43:01,712 - INFO - Epoch [  7/100] - Batch [  4800/ 29640] (16%) - Loss 0.5170\n",
      "2020-10-20 12:44:10,519 - INFO - Epoch [  7/100] - Batch [  6400/ 29640] (22%) - Loss 0.4122\n",
      "2020-10-20 12:45:19,664 - INFO - Epoch [  7/100] - Batch [  8000/ 29640] (27%) - Loss 0.6203\n",
      "2020-10-20 12:46:29,338 - INFO - Epoch [  7/100] - Batch [  9600/ 29640] (32%) - Loss 0.5277\n",
      "2020-10-20 12:47:38,923 - INFO - Epoch [  7/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3926\n",
      "2020-10-20 12:48:47,956 - INFO - Epoch [  7/100] - Batch [ 12800/ 29640] (43%) - Loss 0.3819\n",
      "2020-10-20 12:49:56,841 - INFO - Epoch [  7/100] - Batch [ 14400/ 29640] (49%) - Loss 0.6604\n",
      "2020-10-20 12:51:06,421 - INFO - Epoch [  7/100] - Batch [ 16000/ 29640] (54%) - Loss 0.8376\n",
      "2020-10-20 12:52:16,081 - INFO - Epoch [  7/100] - Batch [ 17600/ 29640] (59%) - Loss 0.3766\n",
      "2020-10-20 12:53:24,989 - INFO - Epoch [  7/100] - Batch [ 19200/ 29640] (65%) - Loss 0.4411\n",
      "2020-10-20 12:54:34,013 - INFO - Epoch [  7/100] - Batch [ 20800/ 29640] (70%) - Loss 0.4761\n",
      "2020-10-20 12:55:43,331 - INFO - Epoch [  7/100] - Batch [ 22400/ 29640] (76%) - Loss 0.7577\n",
      "2020-10-20 12:56:52,675 - INFO - Epoch [  7/100] - Batch [ 24000/ 29640] (81%) - Loss 0.2962\n",
      "2020-10-20 12:58:01,707 - INFO - Epoch [  7/100] - Batch [ 25600/ 29640] (86%) - Loss 0.3511\n",
      "2020-10-20 12:59:09,935 - INFO - Epoch [  7/100] - Batch [ 27200/ 29640] (92%) - Loss 0.5988\n",
      "2020-10-20 13:00:16,696 - INFO - Epoch [  7/100] - Batch [ 28800/ 29640] (97%) - Loss 0.6625\n",
      "2020-10-20 13:00:51,643 - INFO - Current lr: 0.01\n",
      "2020-10-20 13:00:51,645 - INFO - train, Loss: 0.5041 Acc: 0.7997\n",
      "2020-10-20 13:00:59,814 - INFO - Epoch [  7/100] - Batch [     0/  1483] ( 0%) - Loss 1.4093\n",
      "2020-10-20 13:01:34,435 - INFO - Current lr: 0.01\n",
      "2020-10-20 13:01:34,436 - INFO - valid, Loss: 2.3803 Acc: 0.4997\n",
      "0.4994026284348865\n",
      "2020-10-20 13:01:43,227 - INFO - Epoch [  8/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4046\n",
      "2020-10-20 13:02:56,078 - INFO - Epoch [  8/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.7219\n",
      "2020-10-20 13:04:05,421 - INFO - Epoch [  8/100] - Batch [  3200/ 29640] (11%) - Loss 0.5515\n",
      "2020-10-20 13:05:14,570 - INFO - Epoch [  8/100] - Batch [  4800/ 29640] (16%) - Loss 0.3199\n",
      "2020-10-20 13:06:23,628 - INFO - Epoch [  8/100] - Batch [  6400/ 29640] (22%) - Loss 0.6073\n",
      "2020-10-20 13:07:32,883 - INFO - Epoch [  8/100] - Batch [  8000/ 29640] (27%) - Loss 0.7939\n",
      "2020-10-20 13:08:42,000 - INFO - Epoch [  8/100] - Batch [  9600/ 29640] (32%) - Loss 0.5523\n",
      "2020-10-20 13:09:51,143 - INFO - Epoch [  8/100] - Batch [ 11200/ 29640] (38%) - Loss 0.6182\n",
      "2020-10-20 13:11:00,289 - INFO - Epoch [  8/100] - Batch [ 12800/ 29640] (43%) - Loss 0.5139\n",
      "2020-10-20 13:12:09,304 - INFO - Epoch [  8/100] - Batch [ 14400/ 29640] (49%) - Loss 0.3452\n",
      "2020-10-20 13:13:18,008 - INFO - Epoch [  8/100] - Batch [ 16000/ 29640] (54%) - Loss 0.4472\n",
      "2020-10-20 13:14:26,768 - INFO - Epoch [  8/100] - Batch [ 17600/ 29640] (59%) - Loss 0.5747\n",
      "2020-10-20 13:15:35,453 - INFO - Epoch [  8/100] - Batch [ 19200/ 29640] (65%) - Loss 0.7296\n",
      "2020-10-20 13:16:44,293 - INFO - Epoch [  8/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5436\n",
      "2020-10-20 13:17:53,056 - INFO - Epoch [  8/100] - Batch [ 22400/ 29640] (76%) - Loss 0.3483\n",
      "2020-10-20 13:19:01,981 - INFO - Epoch [  8/100] - Batch [ 24000/ 29640] (81%) - Loss 0.5421\n",
      "2020-10-20 13:20:10,718 - INFO - Epoch [  8/100] - Batch [ 25600/ 29640] (86%) - Loss 0.3547\n",
      "2020-10-20 13:21:19,040 - INFO - Epoch [  8/100] - Batch [ 27200/ 29640] (92%) - Loss 0.5142\n",
      "2020-10-20 13:22:25,989 - INFO - Epoch [  8/100] - Batch [ 28800/ 29640] (97%) - Loss 0.3810\n",
      "2020-10-20 13:23:01,188 - INFO - Current lr: 0.01\n",
      "2020-10-20 13:23:01,190 - INFO - train, Loss: 0.5036 Acc: 0.7998\n",
      "2020-10-20 13:23:11,234 - INFO - Epoch [  8/100] - Batch [     0/  1483] ( 0%) - Loss 1.9491\n",
      "2020-10-20 13:23:43,856 - INFO - Current lr: 0.01\n",
      "2020-10-20 13:23:43,857 - INFO - valid, Loss: 7.3606 Acc: 0.4545\n",
      "0.4551053188149964\n",
      "2020-10-20 13:23:43,857 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-20 13:23:54,761 - INFO - Epoch [  9/100] - Batch [     0/ 29640] ( 0%) - Loss 0.5618\n",
      "2020-10-20 13:25:06,222 - INFO - Epoch [  9/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.5795\n",
      "2020-10-20 13:26:15,723 - INFO - Epoch [  9/100] - Batch [  3200/ 29640] (11%) - Loss 0.5920\n",
      "2020-10-20 13:27:24,990 - INFO - Epoch [  9/100] - Batch [  4800/ 29640] (16%) - Loss 0.3627\n",
      "2020-10-20 13:28:34,243 - INFO - Epoch [  9/100] - Batch [  6400/ 29640] (22%) - Loss 0.4070\n",
      "2020-10-20 13:29:43,688 - INFO - Epoch [  9/100] - Batch [  8000/ 29640] (27%) - Loss 0.5590\n",
      "2020-10-20 13:30:53,180 - INFO - Epoch [  9/100] - Batch [  9600/ 29640] (32%) - Loss 0.4631\n",
      "2020-10-20 13:32:02,721 - INFO - Epoch [  9/100] - Batch [ 11200/ 29640] (38%) - Loss 0.5909\n",
      "2020-10-20 13:33:11,840 - INFO - Epoch [  9/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4595\n",
      "2020-10-20 13:34:20,561 - INFO - Epoch [  9/100] - Batch [ 14400/ 29640] (49%) - Loss 0.2849\n",
      "2020-10-20 13:35:29,514 - INFO - Epoch [  9/100] - Batch [ 16000/ 29640] (54%) - Loss 0.3478\n",
      "2020-10-20 13:36:38,786 - INFO - Epoch [  9/100] - Batch [ 17600/ 29640] (59%) - Loss 0.5508\n",
      "2020-10-20 13:37:47,777 - INFO - Epoch [  9/100] - Batch [ 19200/ 29640] (65%) - Loss 0.4413\n",
      "2020-10-20 13:38:56,927 - INFO - Epoch [  9/100] - Batch [ 20800/ 29640] (70%) - Loss 0.2814\n",
      "2020-10-20 13:40:06,112 - INFO - Epoch [  9/100] - Batch [ 22400/ 29640] (76%) - Loss 0.7433\n",
      "2020-10-20 13:41:15,293 - INFO - Epoch [  9/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4829\n",
      "2020-10-20 13:42:24,024 - INFO - Epoch [  9/100] - Batch [ 25600/ 29640] (86%) - Loss 0.8527\n",
      "2020-10-20 13:43:31,987 - INFO - Epoch [  9/100] - Batch [ 27200/ 29640] (92%) - Loss 0.6417\n",
      "2020-10-20 13:44:38,944 - INFO - Epoch [  9/100] - Batch [ 28800/ 29640] (97%) - Loss 0.4570\n",
      "2020-10-20 13:45:13,944 - INFO - Current lr: 0.01\n",
      "2020-10-20 13:45:13,946 - INFO - train, Loss: 0.5020 Acc: 0.7999\n",
      "2020-10-20 13:45:21,867 - INFO - Epoch [  9/100] - Batch [     0/  1483] ( 0%) - Loss 0.8652\n",
      "2020-10-20 13:45:56,992 - INFO - Current lr: 0.01\n",
      "2020-10-20 13:45:56,993 - INFO - valid, Loss: 1.5852 Acc: 0.4990\n",
      "0.49846390168970817\n",
      "2020-10-20 13:46:06,471 - INFO - Epoch [ 10/100] - Batch [     0/ 29640] ( 0%) - Loss 0.6707\n",
      "2020-10-20 13:47:19,016 - INFO - Epoch [ 10/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.2393\n",
      "2020-10-20 13:48:29,034 - INFO - Epoch [ 10/100] - Batch [  3200/ 29640] (11%) - Loss 0.6097\n",
      "2020-10-20 13:49:38,634 - INFO - Epoch [ 10/100] - Batch [  4800/ 29640] (16%) - Loss 0.4312\n",
      "2020-10-20 13:50:48,509 - INFO - Epoch [ 10/100] - Batch [  6400/ 29640] (22%) - Loss 0.3600\n",
      "2020-10-20 13:51:57,892 - INFO - Epoch [ 10/100] - Batch [  8000/ 29640] (27%) - Loss 0.2816\n",
      "2020-10-20 13:53:07,068 - INFO - Epoch [ 10/100] - Batch [  9600/ 29640] (32%) - Loss 0.4887\n",
      "2020-10-20 13:54:16,664 - INFO - Epoch [ 10/100] - Batch [ 11200/ 29640] (38%) - Loss 0.5281\n",
      "2020-10-20 13:55:25,442 - INFO - Epoch [ 10/100] - Batch [ 12800/ 29640] (43%) - Loss 0.3201\n",
      "2020-10-20 13:56:34,684 - INFO - Epoch [ 10/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4716\n",
      "2020-10-20 13:57:43,924 - INFO - Epoch [ 10/100] - Batch [ 16000/ 29640] (54%) - Loss 0.5101\n",
      "2020-10-20 13:58:53,148 - INFO - Epoch [ 10/100] - Batch [ 17600/ 29640] (59%) - Loss 0.4362\n",
      "2020-10-20 14:00:02,637 - INFO - Epoch [ 10/100] - Batch [ 19200/ 29640] (65%) - Loss 0.5246\n",
      "2020-10-20 14:01:11,903 - INFO - Epoch [ 10/100] - Batch [ 20800/ 29640] (70%) - Loss 0.4896\n",
      "2020-10-20 14:02:21,319 - INFO - Epoch [ 10/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4604\n",
      "2020-10-20 14:03:30,272 - INFO - Epoch [ 10/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4297\n",
      "2020-10-20 14:04:39,265 - INFO - Epoch [ 10/100] - Batch [ 25600/ 29640] (86%) - Loss 0.3235\n",
      "2020-10-20 14:05:47,810 - INFO - Epoch [ 10/100] - Batch [ 27200/ 29640] (92%) - Loss 0.4755\n",
      "2020-10-20 14:06:55,349 - INFO - Epoch [ 10/100] - Batch [ 28800/ 29640] (97%) - Loss 0.4762\n",
      "2020-10-20 14:07:30,436 - INFO - Current lr: 0.01\n",
      "2020-10-20 14:07:30,437 - INFO - train, Loss: 0.5018 Acc: 0.7999\n",
      "2020-10-20 14:07:38,317 - INFO - Epoch [ 10/100] - Batch [     0/  1483] ( 0%) - Loss 0.6940\n",
      "2020-10-20 14:08:12,435 - INFO - Current lr: 0.01\n",
      "2020-10-20 14:08:12,436 - INFO - valid, Loss: 1.5990 Acc: 0.4720\n",
      "0.4761350059737158\n",
      "2020-10-20 14:08:12,437 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-20 14:08:25,093 - INFO - Epoch [ 11/100] - Batch [     0/ 29640] ( 0%) - Loss 0.3381\n",
      "2020-10-20 14:09:35,184 - INFO - Epoch [ 11/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.7694\n",
      "2020-10-20 14:10:44,242 - INFO - Epoch [ 11/100] - Batch [  3200/ 29640] (11%) - Loss 0.3694\n",
      "2020-10-20 14:11:53,203 - INFO - Epoch [ 11/100] - Batch [  4800/ 29640] (16%) - Loss 0.4924\n",
      "2020-10-20 14:13:01,694 - INFO - Epoch [ 11/100] - Batch [  6400/ 29640] (22%) - Loss 0.5248\n",
      "2020-10-20 14:14:09,919 - INFO - Epoch [ 11/100] - Batch [  8000/ 29640] (27%) - Loss 0.2281\n",
      "2020-10-20 14:15:18,821 - INFO - Epoch [ 11/100] - Batch [  9600/ 29640] (32%) - Loss 0.2096\n",
      "2020-10-20 14:16:27,446 - INFO - Epoch [ 11/100] - Batch [ 11200/ 29640] (38%) - Loss 0.7615\n",
      "2020-10-20 14:17:36,230 - INFO - Epoch [ 11/100] - Batch [ 12800/ 29640] (43%) - Loss 0.5656\n",
      "2020-10-20 14:18:44,804 - INFO - Epoch [ 11/100] - Batch [ 14400/ 29640] (49%) - Loss 0.5162\n",
      "2020-10-20 14:19:52,930 - INFO - Epoch [ 11/100] - Batch [ 16000/ 29640] (54%) - Loss 0.4944\n",
      "2020-10-20 14:21:01,181 - INFO - Epoch [ 11/100] - Batch [ 17600/ 29640] (59%) - Loss 0.5251\n",
      "2020-10-20 14:22:09,527 - INFO - Epoch [ 11/100] - Batch [ 19200/ 29640] (65%) - Loss 0.4012\n",
      "2020-10-20 14:23:17,973 - INFO - Epoch [ 11/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5256\n",
      "2020-10-20 14:24:26,530 - INFO - Epoch [ 11/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5396\n",
      "2020-10-20 14:25:35,413 - INFO - Epoch [ 11/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4087\n",
      "2020-10-20 14:26:44,445 - INFO - Epoch [ 11/100] - Batch [ 25600/ 29640] (86%) - Loss 0.2873\n",
      "2020-10-20 14:27:52,404 - INFO - Epoch [ 11/100] - Batch [ 27200/ 29640] (92%) - Loss 0.5088\n",
      "2020-10-20 14:28:59,295 - INFO - Epoch [ 11/100] - Batch [ 28800/ 29640] (97%) - Loss 0.5807\n",
      "2020-10-20 14:29:34,192 - INFO - Current lr: 0.01\n",
      "2020-10-20 14:29:34,194 - INFO - train, Loss: 0.4997 Acc: 0.8000\n",
      "2020-10-20 14:29:41,558 - INFO - Epoch [ 11/100] - Batch [     0/  1483] ( 0%) - Loss 6.2332\n",
      "2020-10-20 14:30:17,127 - INFO - Current lr: 0.01\n",
      "2020-10-20 14:30:17,128 - INFO - valid, Loss: 4.9862 Acc: 0.5003\n",
      "0.5\n",
      "2020-10-20 14:30:26,594 - INFO - Epoch [ 12/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4936\n",
      "2020-10-20 14:31:39,974 - INFO - Epoch [ 12/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.5364\n",
      "2020-10-20 14:32:49,447 - INFO - Epoch [ 12/100] - Batch [  3200/ 29640] (11%) - Loss 0.6808\n",
      "2020-10-20 14:33:58,559 - INFO - Epoch [ 12/100] - Batch [  4800/ 29640] (16%) - Loss 0.3799\n",
      "2020-10-20 14:35:07,782 - INFO - Epoch [ 12/100] - Batch [  6400/ 29640] (22%) - Loss 0.4004\n",
      "2020-10-20 14:36:17,329 - INFO - Epoch [ 12/100] - Batch [  8000/ 29640] (27%) - Loss 0.4889\n",
      "2020-10-20 14:37:26,888 - INFO - Epoch [ 12/100] - Batch [  9600/ 29640] (32%) - Loss 0.4117\n",
      "2020-10-20 14:38:35,911 - INFO - Epoch [ 12/100] - Batch [ 11200/ 29640] (38%) - Loss 0.4646\n",
      "2020-10-20 14:39:44,803 - INFO - Epoch [ 12/100] - Batch [ 12800/ 29640] (43%) - Loss 0.2972\n",
      "2020-10-20 14:40:53,717 - INFO - Epoch [ 12/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4172\n",
      "2020-10-20 14:42:02,956 - INFO - Epoch [ 12/100] - Batch [ 16000/ 29640] (54%) - Loss 0.3854\n",
      "2020-10-20 14:43:11,527 - INFO - Epoch [ 12/100] - Batch [ 17600/ 29640] (59%) - Loss 0.4102\n",
      "2020-10-20 14:44:20,160 - INFO - Epoch [ 12/100] - Batch [ 19200/ 29640] (65%) - Loss 0.5790\n",
      "2020-10-20 14:45:29,468 - INFO - Epoch [ 12/100] - Batch [ 20800/ 29640] (70%) - Loss 0.7557\n",
      "2020-10-20 14:46:39,052 - INFO - Epoch [ 12/100] - Batch [ 22400/ 29640] (76%) - Loss 0.2766\n",
      "2020-10-20 14:47:47,977 - INFO - Epoch [ 12/100] - Batch [ 24000/ 29640] (81%) - Loss 0.5621\n",
      "2020-10-20 14:48:56,714 - INFO - Epoch [ 12/100] - Batch [ 25600/ 29640] (86%) - Loss 0.3824\n",
      "2020-10-20 14:50:04,901 - INFO - Epoch [ 12/100] - Batch [ 27200/ 29640] (92%) - Loss 0.3832\n",
      "2020-10-20 14:51:12,425 - INFO - Epoch [ 12/100] - Batch [ 28800/ 29640] (97%) - Loss 0.3941\n",
      "2020-10-20 14:51:47,602 - INFO - Current lr: 0.01\n",
      "2020-10-20 14:51:47,603 - INFO - train, Loss: 0.5040 Acc: 0.7996\n",
      "2020-10-20 14:51:55,520 - INFO - Epoch [ 12/100] - Batch [     0/  1483] ( 0%) - Loss 0.9302\n",
      "2020-10-20 14:52:31,131 - INFO - Current lr: 0.01\n",
      "2020-10-20 14:52:31,133 - INFO - valid, Loss: 0.9152 Acc: 0.5003\n",
      "0.5\n",
      "2020-10-20 14:52:41,848 - INFO - Epoch [ 13/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4163\n",
      "2020-10-20 14:53:53,828 - INFO - Epoch [ 13/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.5901\n",
      "2020-10-20 14:55:03,904 - INFO - Epoch [ 13/100] - Batch [  3200/ 29640] (11%) - Loss 0.5043\n",
      "2020-10-20 14:56:14,024 - INFO - Epoch [ 13/100] - Batch [  4800/ 29640] (16%) - Loss 0.7808\n",
      "2020-10-20 14:57:23,853 - INFO - Epoch [ 13/100] - Batch [  6400/ 29640] (22%) - Loss 0.5287\n",
      "2020-10-20 14:58:33,040 - INFO - Epoch [ 13/100] - Batch [  8000/ 29640] (27%) - Loss 0.5287\n",
      "2020-10-20 14:59:42,442 - INFO - Epoch [ 13/100] - Batch [  9600/ 29640] (32%) - Loss 0.4477\n",
      "2020-10-20 15:00:51,702 - INFO - Epoch [ 13/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3414\n",
      "2020-10-20 15:02:01,103 - INFO - Epoch [ 13/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4772\n",
      "2020-10-20 15:03:10,127 - INFO - Epoch [ 13/100] - Batch [ 14400/ 29640] (49%) - Loss 0.8981\n",
      "2020-10-20 15:04:19,439 - INFO - Epoch [ 13/100] - Batch [ 16000/ 29640] (54%) - Loss 0.3882\n",
      "2020-10-20 15:05:28,408 - INFO - Epoch [ 13/100] - Batch [ 17600/ 29640] (59%) - Loss 0.3578\n",
      "2020-10-20 15:06:37,682 - INFO - Epoch [ 13/100] - Batch [ 19200/ 29640] (65%) - Loss 0.4673\n",
      "2020-10-20 15:07:46,554 - INFO - Epoch [ 13/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5762\n",
      "2020-10-20 15:08:55,472 - INFO - Epoch [ 13/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5246\n",
      "2020-10-20 15:10:04,759 - INFO - Epoch [ 13/100] - Batch [ 24000/ 29640] (81%) - Loss 0.3723\n",
      "2020-10-20 15:11:13,954 - INFO - Epoch [ 13/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4847\n",
      "2020-10-20 15:12:21,859 - INFO - Epoch [ 13/100] - Batch [ 27200/ 29640] (92%) - Loss 0.7456\n",
      "2020-10-20 15:13:28,451 - INFO - Epoch [ 13/100] - Batch [ 28800/ 29640] (97%) - Loss 0.4192\n",
      "2020-10-20 15:14:03,172 - INFO - Current lr: 0.01\n",
      "2020-10-20 15:14:03,173 - INFO - train, Loss: 0.5009 Acc: 0.7999\n",
      "2020-10-20 15:14:13,857 - INFO - Epoch [ 13/100] - Batch [     0/  1483] ( 0%) - Loss 1.2229\n",
      "2020-10-20 15:14:46,087 - INFO - Current lr: 0.01\n",
      "2020-10-20 15:14:46,089 - INFO - valid, Loss: 0.9089 Acc: 0.5003\n",
      "0.5\n",
      "2020-10-20 15:14:57,554 - INFO - Epoch [ 14/100] - Batch [     0/ 29640] ( 0%) - Loss 0.7737\n",
      "2020-10-20 15:16:08,834 - INFO - Epoch [ 14/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.4244\n",
      "2020-10-20 15:17:17,686 - INFO - Epoch [ 14/100] - Batch [  3200/ 29640] (11%) - Loss 0.4870\n",
      "2020-10-20 15:18:26,722 - INFO - Epoch [ 14/100] - Batch [  4800/ 29640] (16%) - Loss 0.6324\n",
      "2020-10-20 15:19:35,699 - INFO - Epoch [ 14/100] - Batch [  6400/ 29640] (22%) - Loss 0.7760\n",
      "2020-10-20 15:20:44,697 - INFO - Epoch [ 14/100] - Batch [  8000/ 29640] (27%) - Loss 0.6414\n",
      "2020-10-20 15:21:53,478 - INFO - Epoch [ 14/100] - Batch [  9600/ 29640] (32%) - Loss 0.3143\n",
      "2020-10-20 15:23:02,002 - INFO - Epoch [ 14/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3681\n",
      "2020-10-20 15:24:10,674 - INFO - Epoch [ 14/100] - Batch [ 12800/ 29640] (43%) - Loss 0.6025\n",
      "2020-10-20 15:25:19,372 - INFO - Epoch [ 14/100] - Batch [ 14400/ 29640] (49%) - Loss 0.5573\n",
      "2020-10-20 15:26:28,931 - INFO - Epoch [ 14/100] - Batch [ 16000/ 29640] (54%) - Loss 0.5791\n",
      "2020-10-20 15:27:37,967 - INFO - Epoch [ 14/100] - Batch [ 17600/ 29640] (59%) - Loss 0.4839\n",
      "2020-10-20 15:28:46,791 - INFO - Epoch [ 14/100] - Batch [ 19200/ 29640] (65%) - Loss 0.6323\n",
      "2020-10-20 15:29:55,649 - INFO - Epoch [ 14/100] - Batch [ 20800/ 29640] (70%) - Loss 0.4724\n",
      "2020-10-20 15:31:04,572 - INFO - Epoch [ 14/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4769\n",
      "2020-10-20 15:32:13,503 - INFO - Epoch [ 14/100] - Batch [ 24000/ 29640] (81%) - Loss 0.2918\n",
      "2020-10-20 15:33:22,396 - INFO - Epoch [ 14/100] - Batch [ 25600/ 29640] (86%) - Loss 0.6282\n",
      "2020-10-20 15:34:30,104 - INFO - Epoch [ 14/100] - Batch [ 27200/ 29640] (92%) - Loss 0.3168\n",
      "2020-10-20 15:35:37,032 - INFO - Epoch [ 14/100] - Batch [ 28800/ 29640] (97%) - Loss 0.3946\n",
      "2020-10-20 15:36:12,132 - INFO - Current lr: 0.01\n",
      "2020-10-20 15:36:12,134 - INFO - train, Loss: 0.5005 Acc: 0.7999\n",
      "2020-10-20 15:36:20,114 - INFO - Epoch [ 14/100] - Batch [     0/  1483] ( 0%) - Loss 0.8376\n",
      "2020-10-20 15:36:54,739 - INFO - Current lr: 0.01\n",
      "2020-10-20 15:36:54,740 - INFO - valid, Loss: 0.8596 Acc: 0.5003\n",
      "0.5\n",
      "2020-10-20 15:37:05,082 - INFO - Epoch [ 15/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4531\n",
      "2020-10-20 15:38:16,987 - INFO - Epoch [ 15/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.5441\n",
      "2020-10-20 15:39:26,075 - INFO - Epoch [ 15/100] - Batch [  3200/ 29640] (11%) - Loss 0.2605\n",
      "2020-10-20 15:40:34,900 - INFO - Epoch [ 15/100] - Batch [  4800/ 29640] (16%) - Loss 0.4046\n",
      "2020-10-20 15:41:43,876 - INFO - Epoch [ 15/100] - Batch [  6400/ 29640] (22%) - Loss 0.7841\n",
      "2020-10-20 15:42:52,364 - INFO - Epoch [ 15/100] - Batch [  8000/ 29640] (27%) - Loss 0.7429\n",
      "2020-10-20 15:44:01,167 - INFO - Epoch [ 15/100] - Batch [  9600/ 29640] (32%) - Loss 0.6110\n",
      "2020-10-20 15:45:09,924 - INFO - Epoch [ 15/100] - Batch [ 11200/ 29640] (38%) - Loss 0.4950\n",
      "2020-10-20 15:46:18,775 - INFO - Epoch [ 15/100] - Batch [ 12800/ 29640] (43%) - Loss 0.2846\n",
      "2020-10-20 15:47:27,637 - INFO - Epoch [ 15/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4822\n",
      "2020-10-20 15:48:36,356 - INFO - Epoch [ 15/100] - Batch [ 16000/ 29640] (54%) - Loss 0.6976\n",
      "2020-10-20 15:49:44,859 - INFO - Epoch [ 15/100] - Batch [ 17600/ 29640] (59%) - Loss 0.5078\n",
      "2020-10-20 15:50:53,748 - INFO - Epoch [ 15/100] - Batch [ 19200/ 29640] (65%) - Loss 0.5775\n",
      "2020-10-20 15:52:03,039 - INFO - Epoch [ 15/100] - Batch [ 20800/ 29640] (70%) - Loss 0.3783\n",
      "2020-10-20 15:53:12,080 - INFO - Epoch [ 15/100] - Batch [ 22400/ 29640] (76%) - Loss 0.6921\n",
      "2020-10-20 15:54:20,580 - INFO - Epoch [ 15/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4418\n",
      "2020-10-20 15:55:29,657 - INFO - Epoch [ 15/100] - Batch [ 25600/ 29640] (86%) - Loss 0.6133\n",
      "2020-10-20 15:56:37,647 - INFO - Epoch [ 15/100] - Batch [ 27200/ 29640] (92%) - Loss 0.3409\n",
      "2020-10-20 15:57:44,773 - INFO - Epoch [ 15/100] - Batch [ 28800/ 29640] (97%) - Loss 0.4952\n",
      "2020-10-20 15:58:19,594 - INFO - Current lr: 0.01\n",
      "2020-10-20 15:58:19,595 - INFO - train, Loss: 0.5018 Acc: 0.8000\n",
      "2020-10-20 15:58:27,805 - INFO - Epoch [ 15/100] - Batch [     0/  1483] ( 0%) - Loss 0.8225\n",
      "2020-10-20 15:59:02,426 - INFO - Current lr: 0.01\n",
      "2020-10-20 15:59:02,428 - INFO - valid, Loss: 0.9020 Acc: 0.5017\n",
      "0.500990123973995\n",
      "2020-10-20 15:59:02,429 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-20 15:59:14,400 - INFO - Epoch [ 16/100] - Batch [     0/ 29640] ( 0%) - Loss 0.5931\n",
      "2020-10-20 16:00:25,646 - INFO - Epoch [ 16/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.5003\n",
      "2020-10-20 16:01:35,691 - INFO - Epoch [ 16/100] - Batch [  3200/ 29640] (11%) - Loss 0.4549\n",
      "2020-10-20 16:02:45,132 - INFO - Epoch [ 16/100] - Batch [  4800/ 29640] (16%) - Loss 0.4626\n",
      "2020-10-20 16:03:54,158 - INFO - Epoch [ 16/100] - Batch [  6400/ 29640] (22%) - Loss 0.5384\n",
      "2020-10-20 16:05:03,249 - INFO - Epoch [ 16/100] - Batch [  8000/ 29640] (27%) - Loss 0.7052\n",
      "2020-10-20 16:06:12,353 - INFO - Epoch [ 16/100] - Batch [  9600/ 29640] (32%) - Loss 0.4864\n",
      "2020-10-20 16:07:21,268 - INFO - Epoch [ 16/100] - Batch [ 11200/ 29640] (38%) - Loss 0.6524\n",
      "2020-10-20 16:08:29,686 - INFO - Epoch [ 16/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4629\n",
      "2020-10-20 16:09:38,290 - INFO - Epoch [ 16/100] - Batch [ 14400/ 29640] (49%) - Loss 0.8680\n",
      "2020-10-20 16:10:46,973 - INFO - Epoch [ 16/100] - Batch [ 16000/ 29640] (54%) - Loss 0.5739\n",
      "2020-10-20 16:11:55,661 - INFO - Epoch [ 16/100] - Batch [ 17600/ 29640] (59%) - Loss 0.6364\n",
      "2020-10-20 16:13:04,541 - INFO - Epoch [ 16/100] - Batch [ 19200/ 29640] (65%) - Loss 0.3030\n",
      "2020-10-20 16:14:13,560 - INFO - Epoch [ 16/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5178\n",
      "2020-10-20 16:15:22,515 - INFO - Epoch [ 16/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5840\n",
      "2020-10-20 16:16:31,686 - INFO - Epoch [ 16/100] - Batch [ 24000/ 29640] (81%) - Loss 0.5675\n",
      "2020-10-20 16:17:40,542 - INFO - Epoch [ 16/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4935\n",
      "2020-10-20 16:18:48,438 - INFO - Epoch [ 16/100] - Batch [ 27200/ 29640] (92%) - Loss 0.3816\n",
      "2020-10-20 16:19:55,348 - INFO - Epoch [ 16/100] - Batch [ 28800/ 29640] (97%) - Loss 0.3971\n",
      "2020-10-20 16:20:30,280 - INFO - Current lr: 0.01\n",
      "2020-10-20 16:20:30,281 - INFO - train, Loss: 0.5010 Acc: 0.7999\n",
      "2020-10-20 16:20:38,397 - INFO - Epoch [ 16/100] - Batch [     0/  1483] ( 0%) - Loss 0.9801\n",
      "2020-10-20 16:21:13,309 - INFO - Current lr: 0.01\n",
      "2020-10-20 16:21:13,311 - INFO - valid, Loss: 0.9109 Acc: 0.5381\n",
      "0.5352569324343517\n",
      "2020-10-20 16:21:23,817 - INFO - Epoch [ 17/100] - Batch [     0/ 29640] ( 0%) - Loss 0.5135\n",
      "2020-10-20 16:22:37,271 - INFO - Epoch [ 17/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.3748\n",
      "2020-10-20 16:23:47,621 - INFO - Epoch [ 17/100] - Batch [  3200/ 29640] (11%) - Loss 0.5220\n",
      "2020-10-20 16:24:57,460 - INFO - Epoch [ 17/100] - Batch [  4800/ 29640] (16%) - Loss 0.4953\n",
      "2020-10-20 16:26:07,510 - INFO - Epoch [ 17/100] - Batch [  6400/ 29640] (22%) - Loss 0.3925\n",
      "2020-10-20 16:27:17,150 - INFO - Epoch [ 17/100] - Batch [  8000/ 29640] (27%) - Loss 0.5147\n",
      "2020-10-20 16:28:26,250 - INFO - Epoch [ 17/100] - Batch [  9600/ 29640] (32%) - Loss 0.4041\n",
      "2020-10-20 16:29:35,829 - INFO - Epoch [ 17/100] - Batch [ 11200/ 29640] (38%) - Loss 0.6690\n",
      "2020-10-20 16:30:45,126 - INFO - Epoch [ 17/100] - Batch [ 12800/ 29640] (43%) - Loss 0.5196\n",
      "2020-10-20 16:31:54,751 - INFO - Epoch [ 17/100] - Batch [ 14400/ 29640] (49%) - Loss 0.3955\n",
      "2020-10-20 16:33:04,225 - INFO - Epoch [ 17/100] - Batch [ 16000/ 29640] (54%) - Loss 0.5612\n",
      "2020-10-20 16:34:13,441 - INFO - Epoch [ 17/100] - Batch [ 17600/ 29640] (59%) - Loss 0.7738\n",
      "2020-10-20 16:35:22,915 - INFO - Epoch [ 17/100] - Batch [ 19200/ 29640] (65%) - Loss 0.4102\n",
      "2020-10-20 16:36:32,892 - INFO - Epoch [ 17/100] - Batch [ 20800/ 29640] (70%) - Loss 0.4719\n",
      "2020-10-20 16:37:42,435 - INFO - Epoch [ 17/100] - Batch [ 22400/ 29640] (76%) - Loss 0.2989\n",
      "2020-10-20 16:38:51,612 - INFO - Epoch [ 17/100] - Batch [ 24000/ 29640] (81%) - Loss 0.5527\n",
      "2020-10-20 16:40:01,191 - INFO - Epoch [ 17/100] - Batch [ 25600/ 29640] (86%) - Loss 0.2453\n",
      "2020-10-20 16:41:10,178 - INFO - Epoch [ 17/100] - Batch [ 27200/ 29640] (92%) - Loss 0.8079\n",
      "2020-10-20 16:42:17,474 - INFO - Epoch [ 17/100] - Batch [ 28800/ 29640] (97%) - Loss 0.6712\n",
      "2020-10-20 16:42:52,392 - INFO - Current lr: 0.01\n",
      "2020-10-20 16:42:52,393 - INFO - train, Loss: 0.5021 Acc: 0.7999\n",
      "2020-10-20 16:43:00,297 - INFO - Epoch [ 17/100] - Batch [     0/  1483] ( 0%) - Loss 1.5021\n",
      "2020-10-20 16:43:34,115 - INFO - Current lr: 0.01\n",
      "2020-10-20 16:43:34,117 - INFO - valid, Loss: 2.1136 Acc: 0.5003\n",
      "0.5\n",
      "2020-10-20 16:43:34,118 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-20 16:43:45,157 - INFO - Epoch [ 18/100] - Batch [     0/ 29640] ( 0%) - Loss 0.3992\n",
      "2020-10-20 16:44:58,458 - INFO - Epoch [ 18/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.4039\n",
      "2020-10-20 16:46:08,822 - INFO - Epoch [ 18/100] - Batch [  3200/ 29640] (11%) - Loss 0.2900\n",
      "2020-10-20 16:47:19,066 - INFO - Epoch [ 18/100] - Batch [  4800/ 29640] (16%) - Loss 0.5542\n",
      "2020-10-20 16:48:28,535 - INFO - Epoch [ 18/100] - Batch [  6400/ 29640] (22%) - Loss 0.5728\n",
      "2020-10-20 16:49:37,949 - INFO - Epoch [ 18/100] - Batch [  8000/ 29640] (27%) - Loss 0.5897\n",
      "2020-10-20 16:50:47,627 - INFO - Epoch [ 18/100] - Batch [  9600/ 29640] (32%) - Loss 0.5250\n",
      "2020-10-20 16:51:57,648 - INFO - Epoch [ 18/100] - Batch [ 11200/ 29640] (38%) - Loss 0.6767\n",
      "2020-10-20 16:53:07,228 - INFO - Epoch [ 18/100] - Batch [ 12800/ 29640] (43%) - Loss 0.5611\n",
      "2020-10-20 16:54:16,581 - INFO - Epoch [ 18/100] - Batch [ 14400/ 29640] (49%) - Loss 0.5922\n",
      "2020-10-20 16:55:25,946 - INFO - Epoch [ 18/100] - Batch [ 16000/ 29640] (54%) - Loss 0.3265\n",
      "2020-10-20 16:56:35,869 - INFO - Epoch [ 18/100] - Batch [ 17600/ 29640] (59%) - Loss 0.5368\n",
      "2020-10-20 16:57:45,177 - INFO - Epoch [ 18/100] - Batch [ 19200/ 29640] (65%) - Loss 0.2207\n",
      "2020-10-20 16:58:54,487 - INFO - Epoch [ 18/100] - Batch [ 20800/ 29640] (70%) - Loss 0.6865\n",
      "2020-10-20 17:00:03,848 - INFO - Epoch [ 18/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5932\n",
      "2020-10-20 17:01:13,564 - INFO - Epoch [ 18/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4437\n",
      "2020-10-20 17:02:23,207 - INFO - Epoch [ 18/100] - Batch [ 25600/ 29640] (86%) - Loss 0.7065\n",
      "2020-10-20 17:03:31,964 - INFO - Epoch [ 18/100] - Batch [ 27200/ 29640] (92%) - Loss 0.6896\n",
      "2020-10-20 17:04:39,634 - INFO - Epoch [ 18/100] - Batch [ 28800/ 29640] (97%) - Loss 0.3180\n",
      "2020-10-20 17:05:14,682 - INFO - Current lr: 0.01\n",
      "2020-10-20 17:05:14,684 - INFO - train, Loss: 0.5012 Acc: 0.8000\n",
      "2020-10-20 17:05:22,709 - INFO - Epoch [ 18/100] - Batch [     0/  1483] ( 0%) - Loss 1.3690\n",
      "2020-10-20 17:05:57,002 - INFO - Current lr: 0.01\n",
      "2020-10-20 17:05:57,003 - INFO - valid, Loss: 0.9566 Acc: 0.5475\n",
      "0.5493667175118788\n",
      "2020-10-20 17:06:08,029 - INFO - Epoch [ 19/100] - Batch [     0/ 29640] ( 0%) - Loss 0.5659\n",
      "2020-10-20 17:07:20,812 - INFO - Epoch [ 19/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.4976\n",
      "2020-10-20 17:08:30,099 - INFO - Epoch [ 19/100] - Batch [  3200/ 29640] (11%) - Loss 0.5938\n",
      "2020-10-20 17:09:39,336 - INFO - Epoch [ 19/100] - Batch [  4800/ 29640] (16%) - Loss 0.4200\n",
      "2020-10-20 17:10:48,191 - INFO - Epoch [ 19/100] - Batch [  6400/ 29640] (22%) - Loss 0.5406\n",
      "2020-10-20 17:11:56,991 - INFO - Epoch [ 19/100] - Batch [  8000/ 29640] (27%) - Loss 0.4207\n",
      "2020-10-20 17:13:05,842 - INFO - Epoch [ 19/100] - Batch [  9600/ 29640] (32%) - Loss 0.6219\n",
      "2020-10-20 17:14:14,780 - INFO - Epoch [ 19/100] - Batch [ 11200/ 29640] (38%) - Loss 0.2828\n",
      "2020-10-20 17:15:23,900 - INFO - Epoch [ 19/100] - Batch [ 12800/ 29640] (43%) - Loss 0.7698\n",
      "2020-10-20 17:16:33,223 - INFO - Epoch [ 19/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4611\n",
      "2020-10-20 17:17:42,304 - INFO - Epoch [ 19/100] - Batch [ 16000/ 29640] (54%) - Loss 0.4947\n",
      "2020-10-20 17:18:51,048 - INFO - Epoch [ 19/100] - Batch [ 17600/ 29640] (59%) - Loss 0.4089\n",
      "2020-10-20 17:20:00,005 - INFO - Epoch [ 19/100] - Batch [ 19200/ 29640] (65%) - Loss 0.7219\n",
      "2020-10-20 17:21:08,947 - INFO - Epoch [ 19/100] - Batch [ 20800/ 29640] (70%) - Loss 0.2894\n",
      "2020-10-20 17:22:17,735 - INFO - Epoch [ 19/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5178\n",
      "2020-10-20 17:23:27,157 - INFO - Epoch [ 19/100] - Batch [ 24000/ 29640] (81%) - Loss 0.3795\n",
      "2020-10-20 17:24:36,448 - INFO - Epoch [ 19/100] - Batch [ 25600/ 29640] (86%) - Loss 0.5270\n",
      "2020-10-20 17:25:44,679 - INFO - Epoch [ 19/100] - Batch [ 27200/ 29640] (92%) - Loss 0.2181\n",
      "2020-10-20 17:26:52,153 - INFO - Epoch [ 19/100] - Batch [ 28800/ 29640] (97%) - Loss 0.6419\n",
      "2020-10-20 17:27:27,564 - INFO - Current lr: 0.01\n",
      "2020-10-20 17:27:27,566 - INFO - train, Loss: 0.4999 Acc: 0.8000\n",
      "2020-10-20 17:27:35,745 - INFO - Epoch [ 19/100] - Batch [     0/  1483] ( 0%) - Loss 3.2991\n",
      "2020-10-20 17:28:10,154 - INFO - Current lr: 0.01\n",
      "2020-10-20 17:28:10,155 - INFO - valid, Loss: 2.9838 Acc: 0.5523\n",
      "0.5571079458176232\n",
      "2020-10-20 17:28:20,674 - INFO - Epoch [ 20/100] - Batch [     0/ 29640] ( 0%) - Loss 0.3431\n",
      "2020-10-20 17:29:33,806 - INFO - Epoch [ 20/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.7581\n",
      "2020-10-20 17:30:43,788 - INFO - Epoch [ 20/100] - Batch [  3200/ 29640] (11%) - Loss 0.2365\n",
      "2020-10-20 17:31:54,090 - INFO - Epoch [ 20/100] - Batch [  4800/ 29640] (16%) - Loss 0.5563\n",
      "2020-10-20 17:33:03,331 - INFO - Epoch [ 20/100] - Batch [  6400/ 29640] (22%) - Loss 0.3435\n",
      "2020-10-20 17:34:12,249 - INFO - Epoch [ 20/100] - Batch [  8000/ 29640] (27%) - Loss 0.4061\n",
      "2020-10-20 17:35:21,451 - INFO - Epoch [ 20/100] - Batch [  9600/ 29640] (32%) - Loss 0.3686\n",
      "2020-10-20 17:36:30,794 - INFO - Epoch [ 20/100] - Batch [ 11200/ 29640] (38%) - Loss 0.6114\n",
      "2020-10-20 17:37:40,376 - INFO - Epoch [ 20/100] - Batch [ 12800/ 29640] (43%) - Loss 0.6147\n",
      "2020-10-20 17:38:49,255 - INFO - Epoch [ 20/100] - Batch [ 14400/ 29640] (49%) - Loss 0.6157\n",
      "2020-10-20 17:39:58,034 - INFO - Epoch [ 20/100] - Batch [ 16000/ 29640] (54%) - Loss 0.4710\n",
      "2020-10-20 17:41:07,095 - INFO - Epoch [ 20/100] - Batch [ 17600/ 29640] (59%) - Loss 0.5531\n",
      "2020-10-20 17:42:16,244 - INFO - Epoch [ 20/100] - Batch [ 19200/ 29640] (65%) - Loss 0.5872\n",
      "2020-10-20 17:43:25,445 - INFO - Epoch [ 20/100] - Batch [ 20800/ 29640] (70%) - Loss 0.3992\n",
      "2020-10-20 17:44:34,669 - INFO - Epoch [ 20/100] - Batch [ 22400/ 29640] (76%) - Loss 0.6296\n",
      "2020-10-20 17:45:44,055 - INFO - Epoch [ 20/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4763\n",
      "2020-10-20 17:46:53,132 - INFO - Epoch [ 20/100] - Batch [ 25600/ 29640] (86%) - Loss 0.3832\n",
      "2020-10-20 17:48:01,118 - INFO - Epoch [ 20/100] - Batch [ 27200/ 29640] (92%) - Loss 0.3270\n",
      "2020-10-20 17:49:07,884 - INFO - Epoch [ 20/100] - Batch [ 28800/ 29640] (97%) - Loss 0.5458\n",
      "2020-10-20 17:49:42,774 - INFO - Current lr: 0.01\n",
      "2020-10-20 17:49:42,776 - INFO - train, Loss: 0.4981 Acc: 0.8000\n",
      "2020-10-20 17:49:50,749 - INFO - Epoch [ 20/100] - Batch [     0/  1483] ( 0%) - Loss 1.9135\n",
      "2020-10-20 17:50:25,279 - INFO - Current lr: 0.01\n",
      "2020-10-20 17:50:25,280 - INFO - valid, Loss: 1.0739 Acc: 0.5057\n",
      "0.5060123120606992\n",
      "2020-10-20 17:50:25,281 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-20 17:50:34,633 - INFO - Epoch [ 21/100] - Batch [     0/ 29640] ( 0%) - Loss 0.7382\n",
      "2020-10-20 17:51:47,102 - INFO - Epoch [ 21/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.3915\n",
      "2020-10-20 17:52:56,077 - INFO - Epoch [ 21/100] - Batch [  3200/ 29640] (11%) - Loss 0.3320\n",
      "2020-10-20 17:54:04,719 - INFO - Epoch [ 21/100] - Batch [  4800/ 29640] (16%) - Loss 0.3187\n",
      "2020-10-20 17:55:13,358 - INFO - Epoch [ 21/100] - Batch [  6400/ 29640] (22%) - Loss 0.4239\n",
      "2020-10-20 17:56:21,961 - INFO - Epoch [ 21/100] - Batch [  8000/ 29640] (27%) - Loss 0.2716\n",
      "2020-10-20 17:57:30,683 - INFO - Epoch [ 21/100] - Batch [  9600/ 29640] (32%) - Loss 0.7419\n",
      "2020-10-20 17:58:38,715 - INFO - Epoch [ 21/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3891\n",
      "2020-10-20 17:59:47,152 - INFO - Epoch [ 21/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4817\n",
      "2020-10-20 18:00:55,486 - INFO - Epoch [ 21/100] - Batch [ 14400/ 29640] (49%) - Loss 0.6986\n",
      "2020-10-20 18:02:04,554 - INFO - Epoch [ 21/100] - Batch [ 16000/ 29640] (54%) - Loss 0.3929\n",
      "2020-10-20 18:03:13,258 - INFO - Epoch [ 21/100] - Batch [ 17600/ 29640] (59%) - Loss 0.4998\n",
      "2020-10-20 18:04:21,544 - INFO - Epoch [ 21/100] - Batch [ 19200/ 29640] (65%) - Loss 0.5768\n",
      "2020-10-20 18:05:29,914 - INFO - Epoch [ 21/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5564\n",
      "2020-10-20 18:06:39,285 - INFO - Epoch [ 21/100] - Batch [ 22400/ 29640] (76%) - Loss 0.3134\n",
      "2020-10-20 18:07:47,924 - INFO - Epoch [ 21/100] - Batch [ 24000/ 29640] (81%) - Loss 0.5011\n",
      "2020-10-20 18:08:56,352 - INFO - Epoch [ 21/100] - Batch [ 25600/ 29640] (86%) - Loss 0.6278\n",
      "2020-10-20 18:10:04,343 - INFO - Epoch [ 21/100] - Batch [ 27200/ 29640] (92%) - Loss 0.5861\n",
      "2020-10-20 18:11:10,855 - INFO - Epoch [ 21/100] - Batch [ 28800/ 29640] (97%) - Loss 0.3893\n",
      "2020-10-20 18:11:45,829 - INFO - Current lr: 0.01\n",
      "2020-10-20 18:11:45,831 - INFO - train, Loss: 0.4975 Acc: 0.8000\n",
      "2020-10-20 18:11:55,879 - INFO - Epoch [ 21/100] - Batch [     0/  1483] ( 0%) - Loss 0.7080\n",
      "2020-10-20 18:12:28,597 - INFO - Current lr: 0.01\n",
      "2020-10-20 18:12:28,599 - INFO - valid, Loss: 2.7496 Acc: 0.5003\n",
      "0.5002304147465438\n",
      "new best model  with acc = 0.5003371544167229\n",
      "2020-10-20 18:12:28,941 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-20 18:12:39,480 - INFO - Epoch [ 22/100] - Batch [     0/ 29640] ( 0%) - Loss 0.5629\n",
      "2020-10-20 18:13:50,833 - INFO - Epoch [ 22/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.4162\n",
      "2020-10-20 18:14:59,872 - INFO - Epoch [ 22/100] - Batch [  3200/ 29640] (11%) - Loss 0.4130\n",
      "2020-10-20 18:16:08,983 - INFO - Epoch [ 22/100] - Batch [  4800/ 29640] (16%) - Loss 0.3979\n",
      "2020-10-20 18:17:18,137 - INFO - Epoch [ 22/100] - Batch [  6400/ 29640] (22%) - Loss 0.4114\n",
      "2020-10-20 18:18:26,772 - INFO - Epoch [ 22/100] - Batch [  8000/ 29640] (27%) - Loss 0.4856\n",
      "2020-10-20 18:19:35,991 - INFO - Epoch [ 22/100] - Batch [  9600/ 29640] (32%) - Loss 0.7417\n",
      "2020-10-20 18:20:44,761 - INFO - Epoch [ 22/100] - Batch [ 11200/ 29640] (38%) - Loss 0.4106\n",
      "2020-10-20 18:21:53,503 - INFO - Epoch [ 22/100] - Batch [ 12800/ 29640] (43%) - Loss 0.5479\n",
      "2020-10-20 18:23:02,147 - INFO - Epoch [ 22/100] - Batch [ 14400/ 29640] (49%) - Loss 0.7341\n",
      "2020-10-20 18:24:11,445 - INFO - Epoch [ 22/100] - Batch [ 16000/ 29640] (54%) - Loss 0.3622\n",
      "2020-10-20 18:25:20,286 - INFO - Epoch [ 22/100] - Batch [ 17600/ 29640] (59%) - Loss 0.3990\n",
      "2020-10-20 18:26:29,570 - INFO - Epoch [ 22/100] - Batch [ 19200/ 29640] (65%) - Loss 0.5297\n",
      "2020-10-20 18:27:38,399 - INFO - Epoch [ 22/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5877\n",
      "2020-10-20 18:28:47,169 - INFO - Epoch [ 22/100] - Batch [ 22400/ 29640] (76%) - Loss 0.2729\n",
      "2020-10-20 18:29:56,207 - INFO - Epoch [ 22/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4418\n",
      "2020-10-20 18:31:05,419 - INFO - Epoch [ 22/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4966\n",
      "2020-10-20 18:32:13,608 - INFO - Epoch [ 22/100] - Batch [ 27200/ 29640] (92%) - Loss 0.3162\n",
      "2020-10-20 18:33:20,554 - INFO - Epoch [ 22/100] - Batch [ 28800/ 29640] (97%) - Loss 0.7550\n",
      "2020-10-20 18:33:55,739 - INFO - Current lr: 0.01\n",
      "2020-10-20 18:33:55,740 - INFO - train, Loss: 0.4971 Acc: 0.8000\n",
      "2020-10-20 18:34:06,307 - INFO - Epoch [ 22/100] - Batch [     0/  1483] ( 0%) - Loss 13.7654\n",
      "2020-10-20 18:34:38,889 - INFO - Current lr: 0.01\n",
      "2020-10-20 18:34:38,890 - INFO - valid, Loss: 21.1688 Acc: 0.4646\n",
      "0.4656849273784756\n",
      "2020-10-20 18:34:38,891 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-20 18:34:49,459 - INFO - Epoch [ 23/100] - Batch [     0/ 29640] ( 0%) - Loss 0.3860\n",
      "2020-10-20 18:36:01,727 - INFO - Epoch [ 23/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.5071\n",
      "2020-10-20 18:37:11,688 - INFO - Epoch [ 23/100] - Batch [  3200/ 29640] (11%) - Loss 0.5766\n",
      "2020-10-20 18:38:20,970 - INFO - Epoch [ 23/100] - Batch [  4800/ 29640] (16%) - Loss 0.6070\n",
      "2020-10-20 18:39:30,189 - INFO - Epoch [ 23/100] - Batch [  6400/ 29640] (22%) - Loss 0.4844\n",
      "2020-10-20 18:40:39,255 - INFO - Epoch [ 23/100] - Batch [  8000/ 29640] (27%) - Loss 0.4226\n",
      "2020-10-20 18:41:48,583 - INFO - Epoch [ 23/100] - Batch [  9600/ 29640] (32%) - Loss 0.6140\n",
      "2020-10-20 18:42:57,732 - INFO - Epoch [ 23/100] - Batch [ 11200/ 29640] (38%) - Loss 0.4686\n",
      "2020-10-20 18:44:06,633 - INFO - Epoch [ 23/100] - Batch [ 12800/ 29640] (43%) - Loss 0.3330\n",
      "2020-10-20 18:45:15,619 - INFO - Epoch [ 23/100] - Batch [ 14400/ 29640] (49%) - Loss 0.6098\n",
      "2020-10-20 18:46:24,588 - INFO - Epoch [ 23/100] - Batch [ 16000/ 29640] (54%) - Loss 0.7226\n",
      "2020-10-20 18:47:33,601 - INFO - Epoch [ 23/100] - Batch [ 17600/ 29640] (59%) - Loss 0.5513\n",
      "2020-10-20 18:48:42,095 - INFO - Epoch [ 23/100] - Batch [ 19200/ 29640] (65%) - Loss 0.3086\n",
      "2020-10-20 18:49:50,852 - INFO - Epoch [ 23/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5120\n",
      "2020-10-20 18:50:59,993 - INFO - Epoch [ 23/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5761\n",
      "2020-10-20 18:52:09,030 - INFO - Epoch [ 23/100] - Batch [ 24000/ 29640] (81%) - Loss 0.5141\n",
      "2020-10-20 18:53:17,744 - INFO - Epoch [ 23/100] - Batch [ 25600/ 29640] (86%) - Loss 0.3156\n",
      "2020-10-20 18:54:25,486 - INFO - Epoch [ 23/100] - Batch [ 27200/ 29640] (92%) - Loss 0.3652\n",
      "2020-10-20 18:55:32,498 - INFO - Epoch [ 23/100] - Batch [ 28800/ 29640] (97%) - Loss 0.5949\n",
      "2020-10-20 18:56:07,847 - INFO - Current lr: 0.01\n",
      "2020-10-20 18:56:07,849 - INFO - train, Loss: 0.4968 Acc: 0.8000\n",
      "2020-10-20 18:56:16,352 - INFO - Epoch [ 23/100] - Batch [     0/  1483] ( 0%) - Loss 1.1695\n",
      "2020-10-20 18:56:50,182 - INFO - Current lr: 0.01\n",
      "2020-10-20 18:56:50,184 - INFO - valid, Loss: 1.6196 Acc: 0.4990\n",
      "0.49878605564089434\n",
      "2020-10-20 18:56:50,184 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-20 18:57:02,618 - INFO - Epoch [ 24/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4117\n",
      "2020-10-20 18:58:14,057 - INFO - Epoch [ 24/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.5777\n",
      "2020-10-20 18:59:23,183 - INFO - Epoch [ 24/100] - Batch [  3200/ 29640] (11%) - Loss 0.2809\n",
      "2020-10-20 19:00:32,458 - INFO - Epoch [ 24/100] - Batch [  4800/ 29640] (16%) - Loss 0.3592\n",
      "2020-10-20 19:01:42,310 - INFO - Epoch [ 24/100] - Batch [  6400/ 29640] (22%) - Loss 0.4716\n",
      "2020-10-20 19:02:51,403 - INFO - Epoch [ 24/100] - Batch [  8000/ 29640] (27%) - Loss 0.5760\n",
      "2020-10-20 19:04:00,594 - INFO - Epoch [ 24/100] - Batch [  9600/ 29640] (32%) - Loss 0.4978\n",
      "2020-10-20 19:05:10,170 - INFO - Epoch [ 24/100] - Batch [ 11200/ 29640] (38%) - Loss 0.2785\n",
      "2020-10-20 19:06:19,784 - INFO - Epoch [ 24/100] - Batch [ 12800/ 29640] (43%) - Loss 0.3756\n",
      "2020-10-20 19:07:29,533 - INFO - Epoch [ 24/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4512\n",
      "2020-10-20 19:08:38,477 - INFO - Epoch [ 24/100] - Batch [ 16000/ 29640] (54%) - Loss 0.5131\n",
      "2020-10-20 19:09:47,219 - INFO - Epoch [ 24/100] - Batch [ 17600/ 29640] (59%) - Loss 0.7008\n",
      "2020-10-20 19:10:56,033 - INFO - Epoch [ 24/100] - Batch [ 19200/ 29640] (65%) - Loss 0.4925\n",
      "2020-10-20 19:12:05,373 - INFO - Epoch [ 24/100] - Batch [ 20800/ 29640] (70%) - Loss 0.4787\n",
      "2020-10-20 19:13:14,576 - INFO - Epoch [ 24/100] - Batch [ 22400/ 29640] (76%) - Loss 0.3036\n",
      "2020-10-20 19:14:23,471 - INFO - Epoch [ 24/100] - Batch [ 24000/ 29640] (81%) - Loss 0.7699\n",
      "2020-10-20 19:15:32,532 - INFO - Epoch [ 24/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4434\n",
      "2020-10-20 19:16:40,731 - INFO - Epoch [ 24/100] - Batch [ 27200/ 29640] (92%) - Loss 0.5364\n",
      "2020-10-20 19:17:48,263 - INFO - Epoch [ 24/100] - Batch [ 28800/ 29640] (97%) - Loss 0.4049\n",
      "2020-10-20 19:18:23,473 - INFO - Current lr: 0.01\n",
      "2020-10-20 19:18:23,475 - INFO - train, Loss: 0.4968 Acc: 0.8000\n",
      "2020-10-20 19:18:30,819 - INFO - Epoch [ 24/100] - Batch [     0/  1483] ( 0%) - Loss 1.0490\n",
      "2020-10-20 19:19:06,772 - INFO - Current lr: 0.01\n",
      "2020-10-20 19:19:06,775 - INFO - valid, Loss: 4.4856 Acc: 0.4693\n",
      "0.46383855093532506\n",
      "2020-10-20 19:19:06,775 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-20 19:19:17,593 - INFO - Epoch [ 25/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4545\n",
      "2020-10-20 19:20:28,842 - INFO - Epoch [ 25/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.2853\n",
      "2020-10-20 19:21:37,946 - INFO - Epoch [ 25/100] - Batch [  3200/ 29640] (11%) - Loss 0.5158\n",
      "2020-10-20 19:22:47,059 - INFO - Epoch [ 25/100] - Batch [  4800/ 29640] (16%) - Loss 0.3689\n",
      "2020-10-20 19:23:55,993 - INFO - Epoch [ 25/100] - Batch [  6400/ 29640] (22%) - Loss 0.3887\n",
      "2020-10-20 19:25:05,193 - INFO - Epoch [ 25/100] - Batch [  8000/ 29640] (27%) - Loss 0.7255\n",
      "2020-10-20 19:26:14,466 - INFO - Epoch [ 25/100] - Batch [  9600/ 29640] (32%) - Loss 0.4188\n",
      "2020-10-20 19:27:23,793 - INFO - Epoch [ 25/100] - Batch [ 11200/ 29640] (38%) - Loss 0.5406\n",
      "2020-10-20 19:28:33,025 - INFO - Epoch [ 25/100] - Batch [ 12800/ 29640] (43%) - Loss 0.6538\n",
      "2020-10-20 19:29:42,196 - INFO - Epoch [ 25/100] - Batch [ 14400/ 29640] (49%) - Loss 0.6209\n",
      "2020-10-20 19:30:51,241 - INFO - Epoch [ 25/100] - Batch [ 16000/ 29640] (54%) - Loss 0.5046\n",
      "2020-10-20 19:32:00,307 - INFO - Epoch [ 25/100] - Batch [ 17600/ 29640] (59%) - Loss 0.5027\n",
      "2020-10-20 19:33:09,550 - INFO - Epoch [ 25/100] - Batch [ 19200/ 29640] (65%) - Loss 0.4667\n",
      "2020-10-20 19:34:18,298 - INFO - Epoch [ 25/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5049\n",
      "2020-10-20 19:35:27,027 - INFO - Epoch [ 25/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4535\n",
      "2020-10-20 19:36:36,469 - INFO - Epoch [ 25/100] - Batch [ 24000/ 29640] (81%) - Loss 0.6633\n",
      "2020-10-20 19:37:45,047 - INFO - Epoch [ 25/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4512\n",
      "2020-10-20 19:38:52,674 - INFO - Epoch [ 25/100] - Batch [ 27200/ 29640] (92%) - Loss 0.5147\n",
      "2020-10-20 19:39:59,156 - INFO - Epoch [ 25/100] - Batch [ 28800/ 29640] (97%) - Loss 0.3403\n",
      "2020-10-20 19:40:34,065 - INFO - Current lr: 0.01\n",
      "2020-10-20 19:40:34,066 - INFO - train, Loss: 0.4966 Acc: 0.7999\n",
      "2020-10-20 19:40:45,252 - INFO - Epoch [ 25/100] - Batch [     0/  1483] ( 0%) - Loss 3.5797\n",
      "2020-10-20 19:41:16,429 - INFO - Current lr: 0.01\n",
      "2020-10-20 19:41:16,431 - INFO - valid, Loss: 2.3227 Acc: 0.5212\n",
      "0.5202386770935159\n",
      "new best model  with acc = 0.5212407282535402\n",
      "2020-10-20 19:41:27,040 - INFO - Epoch [ 26/100] - Batch [     0/ 29640] ( 0%) - Loss 0.5340\n",
      "2020-10-20 19:42:40,157 - INFO - Epoch [ 26/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.2880\n",
      "2020-10-20 19:43:50,510 - INFO - Epoch [ 26/100] - Batch [  3200/ 29640] (11%) - Loss 0.3865\n",
      "2020-10-20 19:45:00,136 - INFO - Epoch [ 26/100] - Batch [  4800/ 29640] (16%) - Loss 0.6916\n",
      "2020-10-20 19:46:10,337 - INFO - Epoch [ 26/100] - Batch [  6400/ 29640] (22%) - Loss 0.6164\n",
      "2020-10-20 19:47:20,344 - INFO - Epoch [ 26/100] - Batch [  8000/ 29640] (27%) - Loss 0.5525\n",
      "2020-10-20 19:48:29,567 - INFO - Epoch [ 26/100] - Batch [  9600/ 29640] (32%) - Loss 0.3872\n",
      "2020-10-20 19:49:39,284 - INFO - Epoch [ 26/100] - Batch [ 11200/ 29640] (38%) - Loss 0.7014\n",
      "2020-10-20 19:50:48,797 - INFO - Epoch [ 26/100] - Batch [ 12800/ 29640] (43%) - Loss 0.5671\n",
      "2020-10-20 19:51:58,259 - INFO - Epoch [ 26/100] - Batch [ 14400/ 29640] (49%) - Loss 0.6818\n",
      "2020-10-20 19:53:07,530 - INFO - Epoch [ 26/100] - Batch [ 16000/ 29640] (54%) - Loss 0.3002\n",
      "2020-10-20 19:54:16,713 - INFO - Epoch [ 26/100] - Batch [ 17600/ 29640] (59%) - Loss 0.3958\n",
      "2020-10-20 19:55:26,156 - INFO - Epoch [ 26/100] - Batch [ 19200/ 29640] (65%) - Loss 0.4664\n",
      "2020-10-20 19:56:35,824 - INFO - Epoch [ 26/100] - Batch [ 20800/ 29640] (70%) - Loss 0.7189\n",
      "2020-10-20 19:57:44,940 - INFO - Epoch [ 26/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4258\n",
      "2020-10-20 19:58:54,046 - INFO - Epoch [ 26/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4586\n",
      "2020-10-20 20:00:03,549 - INFO - Epoch [ 26/100] - Batch [ 25600/ 29640] (86%) - Loss 0.3730\n",
      "2020-10-20 20:01:12,042 - INFO - Epoch [ 26/100] - Batch [ 27200/ 29640] (92%) - Loss 0.5652\n",
      "2020-10-20 20:02:19,418 - INFO - Epoch [ 26/100] - Batch [ 28800/ 29640] (97%) - Loss 0.4707\n",
      "2020-10-20 20:02:54,413 - INFO - Current lr: 0.01\n",
      "2020-10-20 20:02:54,415 - INFO - train, Loss: 0.4973 Acc: 0.8000\n",
      "2020-10-20 20:03:07,008 - INFO - Epoch [ 26/100] - Batch [     0/  1483] ( 0%) - Loss 1.3007\n",
      "2020-10-20 20:03:38,540 - INFO - Current lr: 0.01\n",
      "2020-10-20 20:03:38,542 - INFO - valid, Loss: 1.8745 Acc: 0.4976\n",
      "0.4976087084958053\n",
      "2020-10-20 20:03:49,208 - INFO - Epoch [ 27/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4139\n",
      "2020-10-20 20:05:02,919 - INFO - Epoch [ 27/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.8347\n",
      "2020-10-20 20:06:13,471 - INFO - Epoch [ 27/100] - Batch [  3200/ 29640] (11%) - Loss 0.6543\n",
      "2020-10-20 20:07:23,765 - INFO - Epoch [ 27/100] - Batch [  4800/ 29640] (16%) - Loss 0.4073\n",
      "2020-10-20 20:08:33,596 - INFO - Epoch [ 27/100] - Batch [  6400/ 29640] (22%) - Loss 0.5616\n",
      "2020-10-20 20:09:42,993 - INFO - Epoch [ 27/100] - Batch [  8000/ 29640] (27%) - Loss 0.4381\n",
      "2020-10-20 20:10:52,325 - INFO - Epoch [ 27/100] - Batch [  9600/ 29640] (32%) - Loss 0.5934\n",
      "2020-10-20 20:12:01,554 - INFO - Epoch [ 27/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3266\n",
      "2020-10-20 20:13:10,749 - INFO - Epoch [ 27/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4074\n",
      "2020-10-20 20:14:19,854 - INFO - Epoch [ 27/100] - Batch [ 14400/ 29640] (49%) - Loss 0.5572\n",
      "2020-10-20 20:15:29,490 - INFO - Epoch [ 27/100] - Batch [ 16000/ 29640] (54%) - Loss 0.3919\n",
      "2020-10-20 20:16:38,750 - INFO - Epoch [ 27/100] - Batch [ 17600/ 29640] (59%) - Loss 0.5821\n",
      "2020-10-20 20:17:47,884 - INFO - Epoch [ 27/100] - Batch [ 19200/ 29640] (65%) - Loss 0.6276\n",
      "2020-10-20 20:18:57,230 - INFO - Epoch [ 27/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5114\n",
      "2020-10-20 20:20:06,455 - INFO - Epoch [ 27/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5163\n",
      "2020-10-20 20:21:15,759 - INFO - Epoch [ 27/100] - Batch [ 24000/ 29640] (81%) - Loss 0.5008\n",
      "2020-10-20 20:22:25,316 - INFO - Epoch [ 27/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4898\n",
      "2020-10-20 20:23:33,505 - INFO - Epoch [ 27/100] - Batch [ 27200/ 29640] (92%) - Loss 0.5552\n",
      "2020-10-20 20:24:40,768 - INFO - Epoch [ 27/100] - Batch [ 28800/ 29640] (97%) - Loss 0.4051\n",
      "2020-10-20 20:25:16,185 - INFO - Current lr: 0.01\n",
      "2020-10-20 20:25:16,187 - INFO - train, Loss: 0.4967 Acc: 0.8000\n",
      "2020-10-20 20:25:25,824 - INFO - Epoch [ 27/100] - Batch [     0/  1483] ( 0%) - Loss 1.1094\n",
      "2020-10-20 20:25:58,983 - INFO - Current lr: 0.01\n",
      "2020-10-20 20:25:58,985 - INFO - valid, Loss: 0.8814 Acc: 0.5199\n",
      "0.5227502485567002\n",
      "2020-10-20 20:26:12,308 - INFO - Epoch [ 28/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4505\n",
      "2020-10-20 20:27:23,618 - INFO - Epoch [ 28/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.4645\n",
      "2020-10-20 20:28:33,226 - INFO - Epoch [ 28/100] - Batch [  3200/ 29640] (11%) - Loss 0.3970\n",
      "2020-10-20 20:29:42,390 - INFO - Epoch [ 28/100] - Batch [  4800/ 29640] (16%) - Loss 0.3007\n",
      "2020-10-20 20:30:51,642 - INFO - Epoch [ 28/100] - Batch [  6400/ 29640] (22%) - Loss 0.4768\n",
      "2020-10-20 20:32:00,990 - INFO - Epoch [ 28/100] - Batch [  8000/ 29640] (27%) - Loss 0.3618\n",
      "2020-10-20 20:33:10,113 - INFO - Epoch [ 28/100] - Batch [  9600/ 29640] (32%) - Loss 0.5886\n",
      "2020-10-20 20:34:19,800 - INFO - Epoch [ 28/100] - Batch [ 11200/ 29640] (38%) - Loss 0.6521\n",
      "2020-10-20 20:35:29,190 - INFO - Epoch [ 28/100] - Batch [ 12800/ 29640] (43%) - Loss 0.3908\n",
      "2020-10-20 20:36:38,500 - INFO - Epoch [ 28/100] - Batch [ 14400/ 29640] (49%) - Loss 0.5299\n",
      "2020-10-20 20:37:47,798 - INFO - Epoch [ 28/100] - Batch [ 16000/ 29640] (54%) - Loss 0.3799\n",
      "2020-10-20 20:38:57,107 - INFO - Epoch [ 28/100] - Batch [ 17600/ 29640] (59%) - Loss 0.4459\n",
      "2020-10-20 20:40:06,223 - INFO - Epoch [ 28/100] - Batch [ 19200/ 29640] (65%) - Loss 0.5799\n",
      "2020-10-20 20:41:15,627 - INFO - Epoch [ 28/100] - Batch [ 20800/ 29640] (70%) - Loss 0.6550\n",
      "2020-10-20 20:42:25,017 - INFO - Epoch [ 28/100] - Batch [ 22400/ 29640] (76%) - Loss 0.3236\n",
      "2020-10-20 20:43:33,939 - INFO - Epoch [ 28/100] - Batch [ 24000/ 29640] (81%) - Loss 0.7742\n",
      "2020-10-20 20:44:43,111 - INFO - Epoch [ 28/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4662\n",
      "2020-10-20 20:45:51,954 - INFO - Epoch [ 28/100] - Batch [ 27200/ 29640] (92%) - Loss 0.5682\n",
      "2020-10-20 20:46:59,745 - INFO - Epoch [ 28/100] - Batch [ 28800/ 29640] (97%) - Loss 0.5764\n",
      "2020-10-20 20:47:35,058 - INFO - Current lr: 0.01\n",
      "2020-10-20 20:47:35,060 - INFO - train, Loss: 0.4996 Acc: 0.8000\n",
      "2020-10-20 20:47:43,315 - INFO - Epoch [ 28/100] - Batch [     0/  1483] ( 0%) - Loss 1.2860\n",
      "2020-10-20 20:48:17,819 - INFO - Current lr: 0.01\n",
      "2020-10-20 20:48:17,820 - INFO - valid, Loss: 1.2197 Acc: 0.5003\n",
      "0.5\n",
      "2020-10-20 20:48:17,821 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-20 20:48:31,513 - INFO - Epoch [ 29/100] - Batch [     0/ 29640] ( 0%) - Loss 0.5888\n",
      "2020-10-20 20:49:42,026 - INFO - Epoch [ 29/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.2867\n",
      "2020-10-20 20:50:51,439 - INFO - Epoch [ 29/100] - Batch [  3200/ 29640] (11%) - Loss 0.5714\n",
      "2020-10-20 20:52:01,224 - INFO - Epoch [ 29/100] - Batch [  4800/ 29640] (16%) - Loss 0.5862\n",
      "2020-10-20 20:53:10,357 - INFO - Epoch [ 29/100] - Batch [  6400/ 29640] (22%) - Loss 0.6001\n",
      "2020-10-20 20:54:19,350 - INFO - Epoch [ 29/100] - Batch [  8000/ 29640] (27%) - Loss 0.5656\n",
      "2020-10-20 20:55:28,416 - INFO - Epoch [ 29/100] - Batch [  9600/ 29640] (32%) - Loss 0.2965\n",
      "2020-10-20 20:56:37,478 - INFO - Epoch [ 29/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3582\n",
      "2020-10-20 20:57:46,243 - INFO - Epoch [ 29/100] - Batch [ 12800/ 29640] (43%) - Loss 0.5727\n",
      "2020-10-20 20:58:54,899 - INFO - Epoch [ 29/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4007\n",
      "2020-10-20 21:00:04,260 - INFO - Epoch [ 29/100] - Batch [ 16000/ 29640] (54%) - Loss 0.6010\n",
      "2020-10-20 21:01:13,492 - INFO - Epoch [ 29/100] - Batch [ 17600/ 29640] (59%) - Loss 0.4975\n",
      "2020-10-20 21:02:22,919 - INFO - Epoch [ 29/100] - Batch [ 19200/ 29640] (65%) - Loss 0.4201\n",
      "2020-10-20 21:03:32,021 - INFO - Epoch [ 29/100] - Batch [ 20800/ 29640] (70%) - Loss 0.4710\n",
      "2020-10-20 21:04:41,067 - INFO - Epoch [ 29/100] - Batch [ 22400/ 29640] (76%) - Loss 0.7289\n",
      "2020-10-20 21:05:50,411 - INFO - Epoch [ 29/100] - Batch [ 24000/ 29640] (81%) - Loss 0.6658\n",
      "2020-10-20 21:07:00,367 - INFO - Epoch [ 29/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4862\n",
      "2020-10-20 21:08:09,001 - INFO - Epoch [ 29/100] - Batch [ 27200/ 29640] (92%) - Loss 0.5715\n",
      "2020-10-20 21:09:16,257 - INFO - Epoch [ 29/100] - Batch [ 28800/ 29640] (97%) - Loss 0.6617\n",
      "2020-10-20 21:09:51,391 - INFO - Current lr: 0.01\n",
      "2020-10-20 21:09:51,392 - INFO - train, Loss: 0.4993 Acc: 0.8000\n",
      "2020-10-20 21:10:03,228 - INFO - Epoch [ 29/100] - Batch [     0/  1483] ( 0%) - Loss 1.9084\n",
      "2020-10-20 21:10:34,271 - INFO - Current lr: 0.01\n",
      "2020-10-20 21:10:34,272 - INFO - valid, Loss: 1.1978 Acc: 0.5003\n",
      "0.5\n",
      "2020-10-20 21:10:34,273 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-20 21:10:44,806 - INFO - Epoch [ 30/100] - Batch [     0/ 29640] ( 0%) - Loss 0.2892\n",
      "2020-10-20 21:11:57,033 - INFO - Epoch [ 30/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.8157\n",
      "2020-10-20 21:13:06,563 - INFO - Epoch [ 30/100] - Batch [  3200/ 29640] (11%) - Loss 0.7446\n",
      "2020-10-20 21:14:16,544 - INFO - Epoch [ 30/100] - Batch [  4800/ 29640] (16%) - Loss 0.4846\n",
      "2020-10-20 21:15:26,428 - INFO - Epoch [ 30/100] - Batch [  6400/ 29640] (22%) - Loss 0.7220\n",
      "2020-10-20 21:16:36,915 - INFO - Epoch [ 30/100] - Batch [  8000/ 29640] (27%) - Loss 0.6100\n",
      "2020-10-20 21:17:46,566 - INFO - Epoch [ 30/100] - Batch [  9600/ 29640] (32%) - Loss 0.2944\n",
      "2020-10-20 21:18:56,233 - INFO - Epoch [ 30/100] - Batch [ 11200/ 29640] (38%) - Loss 0.4708\n",
      "2020-10-20 21:20:06,049 - INFO - Epoch [ 30/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4856\n",
      "2020-10-20 21:21:15,376 - INFO - Epoch [ 30/100] - Batch [ 14400/ 29640] (49%) - Loss 0.3886\n",
      "2020-10-20 21:22:25,109 - INFO - Epoch [ 30/100] - Batch [ 16000/ 29640] (54%) - Loss 0.4053\n",
      "2020-10-20 21:23:34,435 - INFO - Epoch [ 30/100] - Batch [ 17600/ 29640] (59%) - Loss 0.3283\n",
      "2020-10-20 21:24:43,729 - INFO - Epoch [ 30/100] - Batch [ 19200/ 29640] (65%) - Loss 0.3853\n",
      "2020-10-20 21:25:53,312 - INFO - Epoch [ 30/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5903\n",
      "2020-10-20 21:27:02,975 - INFO - Epoch [ 30/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5192\n",
      "2020-10-20 21:28:12,419 - INFO - Epoch [ 30/100] - Batch [ 24000/ 29640] (81%) - Loss 0.6344\n",
      "2020-10-20 21:29:21,906 - INFO - Epoch [ 30/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4626\n",
      "2020-10-20 21:30:30,804 - INFO - Epoch [ 30/100] - Batch [ 27200/ 29640] (92%) - Loss 0.4662\n",
      "2020-10-20 21:31:38,755 - INFO - Epoch [ 30/100] - Batch [ 28800/ 29640] (97%) - Loss 0.4176\n",
      "2020-10-20 21:32:14,077 - INFO - Current lr: 0.01\n",
      "2020-10-20 21:32:14,079 - INFO - train, Loss: 0.4980 Acc: 0.8000\n",
      "2020-10-20 21:32:24,148 - INFO - Epoch [ 30/100] - Batch [     0/  1483] ( 0%) - Loss 0.9324\n",
      "2020-10-20 21:32:57,146 - INFO - Current lr: 0.01\n",
      "2020-10-20 21:32:57,147 - INFO - valid, Loss: 1.0540 Acc: 0.5172\n",
      "0.5175073134750556\n",
      "2020-10-20 21:33:06,418 - INFO - Epoch [ 31/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4429\n",
      "2020-10-20 21:34:19,762 - INFO - Epoch [ 31/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.3945\n",
      "2020-10-20 21:35:29,744 - INFO - Epoch [ 31/100] - Batch [  3200/ 29640] (11%) - Loss 0.5807\n",
      "2020-10-20 21:36:39,777 - INFO - Epoch [ 31/100] - Batch [  4800/ 29640] (16%) - Loss 0.2752\n",
      "2020-10-20 21:37:49,291 - INFO - Epoch [ 31/100] - Batch [  6400/ 29640] (22%) - Loss 0.5698\n",
      "2020-10-20 21:38:58,805 - INFO - Epoch [ 31/100] - Batch [  8000/ 29640] (27%) - Loss 0.7105\n",
      "2020-10-20 21:40:08,256 - INFO - Epoch [ 31/100] - Batch [  9600/ 29640] (32%) - Loss 0.5096\n",
      "2020-10-20 21:41:17,967 - INFO - Epoch [ 31/100] - Batch [ 11200/ 29640] (38%) - Loss 0.1914\n",
      "2020-10-20 21:42:27,536 - INFO - Epoch [ 31/100] - Batch [ 12800/ 29640] (43%) - Loss 0.3914\n",
      "2020-10-20 21:43:37,266 - INFO - Epoch [ 31/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4638\n",
      "2020-10-20 21:44:46,519 - INFO - Epoch [ 31/100] - Batch [ 16000/ 29640] (54%) - Loss 0.4595\n",
      "2020-10-20 21:45:55,750 - INFO - Epoch [ 31/100] - Batch [ 17600/ 29640] (59%) - Loss 0.4554\n",
      "2020-10-20 21:47:05,772 - INFO - Epoch [ 31/100] - Batch [ 19200/ 29640] (65%) - Loss 0.6558\n",
      "2020-10-20 21:48:14,882 - INFO - Epoch [ 31/100] - Batch [ 20800/ 29640] (70%) - Loss 0.7729\n",
      "2020-10-20 21:49:24,255 - INFO - Epoch [ 31/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4041\n",
      "2020-10-20 21:50:33,816 - INFO - Epoch [ 31/100] - Batch [ 24000/ 29640] (81%) - Loss 0.3705\n",
      "2020-10-20 21:51:43,831 - INFO - Epoch [ 31/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4529\n",
      "2020-10-20 21:52:52,221 - INFO - Epoch [ 31/100] - Batch [ 27200/ 29640] (92%) - Loss 0.3934\n",
      "2020-10-20 21:53:59,509 - INFO - Epoch [ 31/100] - Batch [ 28800/ 29640] (97%) - Loss 0.2905\n",
      "2020-10-20 21:54:34,502 - INFO - Current lr: 0.01\n",
      "2020-10-20 21:54:34,504 - INFO - train, Loss: 0.4975 Acc: 0.8000\n",
      "2020-10-20 21:54:46,243 - INFO - Epoch [ 31/100] - Batch [     0/  1483] ( 0%) - Loss 0.8103\n",
      "2020-10-20 21:55:17,361 - INFO - Current lr: 0.01\n",
      "2020-10-20 21:55:17,363 - INFO - valid, Loss: 0.8989 Acc: 0.5273\n",
      "0.5277935475516119\n",
      "new best model  with acc = 0.5273095077545515\n",
      "2020-10-20 21:55:28,883 - INFO - Epoch [ 32/100] - Batch [     0/ 29640] ( 0%) - Loss 0.5735\n",
      "2020-10-20 21:56:40,281 - INFO - Epoch [ 32/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.7909\n",
      "2020-10-20 21:57:49,049 - INFO - Epoch [ 32/100] - Batch [  3200/ 29640] (11%) - Loss 0.5594\n",
      "2020-10-20 21:58:57,650 - INFO - Epoch [ 32/100] - Batch [  4800/ 29640] (16%) - Loss 0.6407\n",
      "2020-10-20 22:00:06,532 - INFO - Epoch [ 32/100] - Batch [  6400/ 29640] (22%) - Loss 0.4512\n",
      "2020-10-20 22:01:15,798 - INFO - Epoch [ 32/100] - Batch [  8000/ 29640] (27%) - Loss 0.2110\n",
      "2020-10-20 22:02:24,433 - INFO - Epoch [ 32/100] - Batch [  9600/ 29640] (32%) - Loss 0.4619\n",
      "2020-10-20 22:03:32,981 - INFO - Epoch [ 32/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3498\n",
      "2020-10-20 22:04:41,922 - INFO - Epoch [ 32/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4407\n",
      "2020-10-20 22:05:50,535 - INFO - Epoch [ 32/100] - Batch [ 14400/ 29640] (49%) - Loss 0.2986\n",
      "2020-10-20 22:06:59,517 - INFO - Epoch [ 32/100] - Batch [ 16000/ 29640] (54%) - Loss 0.3682\n",
      "2020-10-20 22:08:07,925 - INFO - Epoch [ 32/100] - Batch [ 17600/ 29640] (59%) - Loss 0.3970\n",
      "2020-10-20 22:09:16,190 - INFO - Epoch [ 32/100] - Batch [ 19200/ 29640] (65%) - Loss 0.4714\n",
      "2020-10-20 22:10:24,200 - INFO - Epoch [ 32/100] - Batch [ 20800/ 29640] (70%) - Loss 0.4242\n",
      "2020-10-20 22:11:32,599 - INFO - Epoch [ 32/100] - Batch [ 22400/ 29640] (76%) - Loss 0.6060\n",
      "2020-10-20 22:12:41,291 - INFO - Epoch [ 32/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4608\n",
      "2020-10-20 22:13:49,461 - INFO - Epoch [ 32/100] - Batch [ 25600/ 29640] (86%) - Loss 0.6538\n",
      "2020-10-20 22:14:57,101 - INFO - Epoch [ 32/100] - Batch [ 27200/ 29640] (92%) - Loss 0.5448\n",
      "2020-10-20 22:16:04,449 - INFO - Epoch [ 32/100] - Batch [ 28800/ 29640] (97%) - Loss 0.3870\n",
      "2020-10-20 22:16:39,722 - INFO - Current lr: 0.01\n",
      "2020-10-20 22:16:39,723 - INFO - train, Loss: 0.4966 Acc: 0.8000\n",
      "2020-10-20 22:16:49,218 - INFO - Epoch [ 32/100] - Batch [     0/  1483] ( 0%) - Loss 1.0691\n",
      "2020-10-20 22:17:22,515 - INFO - Current lr: 0.01\n",
      "2020-10-20 22:17:22,516 - INFO - valid, Loss: 1.0425 Acc: 0.5064\n",
      "0.5060701096991419\n",
      "2020-10-20 22:17:22,517 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-20 22:17:33,251 - INFO - Epoch [ 33/100] - Batch [     0/ 29640] ( 0%) - Loss 0.6922\n",
      "2020-10-20 22:18:46,314 - INFO - Epoch [ 33/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.6711\n",
      "2020-10-20 22:19:56,441 - INFO - Epoch [ 33/100] - Batch [  3200/ 29640] (11%) - Loss 0.5650\n",
      "2020-10-20 22:21:06,211 - INFO - Epoch [ 33/100] - Batch [  4800/ 29640] (16%) - Loss 0.6164\n",
      "2020-10-20 22:22:15,964 - INFO - Epoch [ 33/100] - Batch [  6400/ 29640] (22%) - Loss 0.5460\n",
      "2020-10-20 22:23:25,966 - INFO - Epoch [ 33/100] - Batch [  8000/ 29640] (27%) - Loss 0.7981\n",
      "2020-10-20 22:24:35,734 - INFO - Epoch [ 33/100] - Batch [  9600/ 29640] (32%) - Loss 0.6613\n",
      "2020-10-20 22:25:45,641 - INFO - Epoch [ 33/100] - Batch [ 11200/ 29640] (38%) - Loss 0.2933\n",
      "2020-10-20 22:26:55,533 - INFO - Epoch [ 33/100] - Batch [ 12800/ 29640] (43%) - Loss 0.3625\n",
      "2020-10-20 22:28:05,385 - INFO - Epoch [ 33/100] - Batch [ 14400/ 29640] (49%) - Loss 0.7461\n",
      "2020-10-20 22:29:15,151 - INFO - Epoch [ 33/100] - Batch [ 16000/ 29640] (54%) - Loss 0.8201\n",
      "2020-10-20 22:30:24,880 - INFO - Epoch [ 33/100] - Batch [ 17600/ 29640] (59%) - Loss 0.8164\n",
      "2020-10-20 22:31:34,698 - INFO - Epoch [ 33/100] - Batch [ 19200/ 29640] (65%) - Loss 0.3990\n",
      "2020-10-20 22:32:44,560 - INFO - Epoch [ 33/100] - Batch [ 20800/ 29640] (70%) - Loss 0.6625\n",
      "2020-10-20 22:33:54,473 - INFO - Epoch [ 33/100] - Batch [ 22400/ 29640] (76%) - Loss 0.6634\n",
      "2020-10-20 22:35:04,157 - INFO - Epoch [ 33/100] - Batch [ 24000/ 29640] (81%) - Loss 0.7219\n",
      "2020-10-20 22:36:14,008 - INFO - Epoch [ 33/100] - Batch [ 25600/ 29640] (86%) - Loss 0.5418\n",
      "2020-10-20 22:37:22,895 - INFO - Epoch [ 33/100] - Batch [ 27200/ 29640] (92%) - Loss 0.4738\n",
      "2020-10-20 22:38:30,309 - INFO - Epoch [ 33/100] - Batch [ 28800/ 29640] (97%) - Loss 0.5770\n",
      "2020-10-20 22:39:05,691 - INFO - Current lr: 0.01\n",
      "2020-10-20 22:39:05,693 - INFO - train, Loss: 0.4953 Acc: 0.8000\n",
      "2020-10-20 22:39:14,101 - INFO - Epoch [ 33/100] - Batch [     0/  1483] ( 0%) - Loss 0.7115\n",
      "2020-10-20 22:39:48,754 - INFO - Current lr: 0.01\n",
      "2020-10-20 22:39:48,755 - INFO - valid, Loss: 1.0648 Acc: 0.4895\n",
      "0.48736371155726\n",
      "2020-10-20 22:39:48,756 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-20 22:39:59,099 - INFO - Epoch [ 34/100] - Batch [     0/ 29640] ( 0%) - Loss 0.5684\n",
      "2020-10-20 22:41:11,629 - INFO - Epoch [ 34/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.5079\n",
      "2020-10-20 22:42:21,084 - INFO - Epoch [ 34/100] - Batch [  3200/ 29640] (11%) - Loss 0.5192\n",
      "2020-10-20 22:43:30,687 - INFO - Epoch [ 34/100] - Batch [  4800/ 29640] (16%) - Loss 0.4507\n",
      "2020-10-20 22:44:39,827 - INFO - Epoch [ 34/100] - Batch [  6400/ 29640] (22%) - Loss 0.7717\n",
      "2020-10-20 22:45:49,018 - INFO - Epoch [ 34/100] - Batch [  8000/ 29640] (27%) - Loss 0.4315\n",
      "2020-10-20 22:46:58,289 - INFO - Epoch [ 34/100] - Batch [  9600/ 29640] (32%) - Loss 0.3124\n",
      "2020-10-20 22:48:07,701 - INFO - Epoch [ 34/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3839\n",
      "2020-10-20 22:49:16,885 - INFO - Epoch [ 34/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4305\n",
      "2020-10-20 22:50:26,071 - INFO - Epoch [ 34/100] - Batch [ 14400/ 29640] (49%) - Loss 0.5890\n",
      "2020-10-20 22:51:35,217 - INFO - Epoch [ 34/100] - Batch [ 16000/ 29640] (54%) - Loss 0.6787\n",
      "2020-10-20 22:52:44,597 - INFO - Epoch [ 34/100] - Batch [ 17600/ 29640] (59%) - Loss 0.3465\n",
      "2020-10-20 22:53:53,675 - INFO - Epoch [ 34/100] - Batch [ 19200/ 29640] (65%) - Loss 0.5154\n",
      "2020-10-20 22:55:02,856 - INFO - Epoch [ 34/100] - Batch [ 20800/ 29640] (70%) - Loss 0.4357\n",
      "2020-10-20 22:56:12,385 - INFO - Epoch [ 34/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5349\n",
      "2020-10-20 22:57:21,800 - INFO - Epoch [ 34/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4653\n",
      "2020-10-20 22:58:30,801 - INFO - Epoch [ 34/100] - Batch [ 25600/ 29640] (86%) - Loss 0.3882\n",
      "2020-10-20 22:59:39,326 - INFO - Epoch [ 34/100] - Batch [ 27200/ 29640] (92%) - Loss 0.2715\n",
      "2020-10-20 23:00:47,142 - INFO - Epoch [ 34/100] - Batch [ 28800/ 29640] (97%) - Loss 0.3043\n",
      "2020-10-20 23:01:22,710 - INFO - Current lr: 0.01\n",
      "2020-10-20 23:01:22,712 - INFO - train, Loss: 0.4977 Acc: 0.8000\n",
      "2020-10-20 23:01:32,758 - INFO - Epoch [ 34/100] - Batch [     0/  1483] ( 0%) - Loss 1.1459\n",
      "2020-10-20 23:02:05,367 - INFO - Current lr: 0.01\n",
      "2020-10-20 23:02:05,368 - INFO - valid, Loss: 0.8206 Acc: 0.5401\n",
      "0.5402887882726594\n",
      "new best model  with acc = 0.5401213755900203\n",
      "2020-10-20 23:02:15,055 - INFO - Epoch [ 35/100] - Batch [     0/ 29640] ( 0%) - Loss 0.3324\n",
      "2020-10-20 23:03:27,872 - INFO - Epoch [ 35/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.4886\n",
      "2020-10-20 23:04:37,638 - INFO - Epoch [ 35/100] - Batch [  3200/ 29640] (11%) - Loss 0.6008\n",
      "2020-10-20 23:05:47,706 - INFO - Epoch [ 35/100] - Batch [  4800/ 29640] (16%) - Loss 0.7418\n",
      "2020-10-20 23:06:57,657 - INFO - Epoch [ 35/100] - Batch [  6400/ 29640] (22%) - Loss 0.3839\n",
      "2020-10-20 23:08:06,885 - INFO - Epoch [ 35/100] - Batch [  8000/ 29640] (27%) - Loss 0.5564\n",
      "2020-10-20 23:09:15,794 - INFO - Epoch [ 35/100] - Batch [  9600/ 29640] (32%) - Loss 0.3972\n",
      "2020-10-20 23:10:24,697 - INFO - Epoch [ 35/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3835\n",
      "2020-10-20 23:11:33,647 - INFO - Epoch [ 35/100] - Batch [ 12800/ 29640] (43%) - Loss 0.6373\n",
      "2020-10-20 23:12:42,349 - INFO - Epoch [ 35/100] - Batch [ 14400/ 29640] (49%) - Loss 0.5862\n",
      "2020-10-20 23:13:51,180 - INFO - Epoch [ 35/100] - Batch [ 16000/ 29640] (54%) - Loss 0.5616\n",
      "2020-10-20 23:15:00,434 - INFO - Epoch [ 35/100] - Batch [ 17600/ 29640] (59%) - Loss 0.7145\n",
      "2020-10-20 23:16:09,848 - INFO - Epoch [ 35/100] - Batch [ 19200/ 29640] (65%) - Loss 0.7283\n",
      "2020-10-20 23:17:19,050 - INFO - Epoch [ 35/100] - Batch [ 20800/ 29640] (70%) - Loss 0.6440\n",
      "2020-10-20 23:18:28,517 - INFO - Epoch [ 35/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4664\n",
      "2020-10-20 23:19:37,646 - INFO - Epoch [ 35/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4845\n",
      "2020-10-20 23:20:46,877 - INFO - Epoch [ 35/100] - Batch [ 25600/ 29640] (86%) - Loss 0.5665\n",
      "2020-10-20 23:21:55,020 - INFO - Epoch [ 35/100] - Batch [ 27200/ 29640] (92%) - Loss 0.4820\n",
      "2020-10-20 23:23:01,866 - INFO - Epoch [ 35/100] - Batch [ 28800/ 29640] (97%) - Loss 0.6816\n",
      "2020-10-20 23:23:36,960 - INFO - Current lr: 0.01\n",
      "2020-10-20 23:23:36,962 - INFO - train, Loss: 0.4983 Acc: 0.8000\n",
      "2020-10-20 23:23:46,011 - INFO - Epoch [ 35/100] - Batch [     0/  1483] ( 0%) - Loss 0.7573\n",
      "2020-10-20 23:24:20,273 - INFO - Current lr: 0.01\n",
      "2020-10-20 23:24:20,274 - INFO - valid, Loss: 4.8844 Acc: 0.5071\n",
      "0.5062495151204828\n",
      "2020-10-20 23:24:20,275 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-20 23:24:31,153 - INFO - Epoch [ 36/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4848\n",
      "2020-10-20 23:25:43,487 - INFO - Epoch [ 36/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.6188\n",
      "2020-10-20 23:26:53,438 - INFO - Epoch [ 36/100] - Batch [  3200/ 29640] (11%) - Loss 0.5976\n",
      "2020-10-20 23:28:02,944 - INFO - Epoch [ 36/100] - Batch [  4800/ 29640] (16%) - Loss 0.4927\n",
      "2020-10-20 23:29:12,365 - INFO - Epoch [ 36/100] - Batch [  6400/ 29640] (22%) - Loss 0.4159\n",
      "2020-10-20 23:30:21,761 - INFO - Epoch [ 36/100] - Batch [  8000/ 29640] (27%) - Loss 0.5132\n",
      "2020-10-20 23:31:31,307 - INFO - Epoch [ 36/100] - Batch [  9600/ 29640] (32%) - Loss 0.4140\n",
      "2020-10-20 23:32:40,318 - INFO - Epoch [ 36/100] - Batch [ 11200/ 29640] (38%) - Loss 0.5664\n",
      "2020-10-20 23:33:49,037 - INFO - Epoch [ 36/100] - Batch [ 12800/ 29640] (43%) - Loss 0.2313\n",
      "2020-10-20 23:34:57,895 - INFO - Epoch [ 36/100] - Batch [ 14400/ 29640] (49%) - Loss 0.7480\n",
      "2020-10-20 23:36:07,193 - INFO - Epoch [ 36/100] - Batch [ 16000/ 29640] (54%) - Loss 0.3969\n",
      "2020-10-20 23:37:16,610 - INFO - Epoch [ 36/100] - Batch [ 17600/ 29640] (59%) - Loss 0.5322\n",
      "2020-10-20 23:38:25,407 - INFO - Epoch [ 36/100] - Batch [ 19200/ 29640] (65%) - Loss 0.6571\n",
      "2020-10-20 23:39:34,897 - INFO - Epoch [ 36/100] - Batch [ 20800/ 29640] (70%) - Loss 0.3206\n",
      "2020-10-20 23:40:44,713 - INFO - Epoch [ 36/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5879\n",
      "2020-10-20 23:41:54,619 - INFO - Epoch [ 36/100] - Batch [ 24000/ 29640] (81%) - Loss 0.7721\n",
      "2020-10-20 23:43:04,275 - INFO - Epoch [ 36/100] - Batch [ 25600/ 29640] (86%) - Loss 0.5828\n",
      "2020-10-20 23:44:12,652 - INFO - Epoch [ 36/100] - Batch [ 27200/ 29640] (92%) - Loss 0.4342\n",
      "2020-10-20 23:45:20,046 - INFO - Epoch [ 36/100] - Batch [ 28800/ 29640] (97%) - Loss 0.5225\n",
      "2020-10-20 23:45:55,276 - INFO - Current lr: 0.01\n",
      "2020-10-20 23:45:55,278 - INFO - train, Loss: 0.4967 Acc: 0.8000\n",
      "2020-10-20 23:46:02,647 - INFO - Epoch [ 36/100] - Batch [     0/  1483] ( 0%) - Loss 3.4142\n",
      "2020-10-20 23:46:38,127 - INFO - Current lr: 0.01\n",
      "2020-10-20 23:46:38,129 - INFO - valid, Loss: 5.3843 Acc: 0.5152\n",
      "0.5143239824691439\n",
      "2020-10-20 23:46:38,130 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-20 23:46:51,800 - INFO - Epoch [ 37/100] - Batch [     0/ 29640] ( 0%) - Loss 0.3717\n",
      "2020-10-20 23:48:02,871 - INFO - Epoch [ 37/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.5760\n",
      "2020-10-20 23:49:12,222 - INFO - Epoch [ 37/100] - Batch [  3200/ 29640] (11%) - Loss 0.6505\n",
      "2020-10-20 23:50:21,256 - INFO - Epoch [ 37/100] - Batch [  4800/ 29640] (16%) - Loss 0.4238\n",
      "2020-10-20 23:51:30,354 - INFO - Epoch [ 37/100] - Batch [  6400/ 29640] (22%) - Loss 0.5756\n",
      "2020-10-20 23:52:39,564 - INFO - Epoch [ 37/100] - Batch [  8000/ 29640] (27%) - Loss 0.3737\n",
      "2020-10-20 23:53:48,792 - INFO - Epoch [ 37/100] - Batch [  9600/ 29640] (32%) - Loss 0.3907\n",
      "2020-10-20 23:54:57,777 - INFO - Epoch [ 37/100] - Batch [ 11200/ 29640] (38%) - Loss 0.6484\n",
      "2020-10-20 23:56:07,198 - INFO - Epoch [ 37/100] - Batch [ 12800/ 29640] (43%) - Loss 0.5067\n",
      "2020-10-20 23:57:16,359 - INFO - Epoch [ 37/100] - Batch [ 14400/ 29640] (49%) - Loss 0.3007\n",
      "2020-10-20 23:58:25,550 - INFO - Epoch [ 37/100] - Batch [ 16000/ 29640] (54%) - Loss 0.5780\n",
      "2020-10-20 23:59:34,590 - INFO - Epoch [ 37/100] - Batch [ 17600/ 29640] (59%) - Loss 0.3858\n",
      "2020-10-21 00:00:43,951 - INFO - Epoch [ 37/100] - Batch [ 19200/ 29640] (65%) - Loss 0.4693\n",
      "2020-10-21 00:01:53,536 - INFO - Epoch [ 37/100] - Batch [ 20800/ 29640] (70%) - Loss 0.3864\n",
      "2020-10-21 00:03:02,731 - INFO - Epoch [ 37/100] - Batch [ 22400/ 29640] (76%) - Loss 0.3766\n",
      "2020-10-21 00:04:11,804 - INFO - Epoch [ 37/100] - Batch [ 24000/ 29640] (81%) - Loss 0.3030\n",
      "2020-10-21 00:05:20,856 - INFO - Epoch [ 37/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4742\n",
      "2020-10-21 00:06:29,353 - INFO - Epoch [ 37/100] - Batch [ 27200/ 29640] (92%) - Loss 0.3156\n",
      "2020-10-21 00:07:36,376 - INFO - Epoch [ 37/100] - Batch [ 28800/ 29640] (97%) - Loss 0.5314\n",
      "2020-10-21 00:08:11,270 - INFO - Current lr: 0.01\n",
      "2020-10-21 00:08:11,272 - INFO - train, Loss: 0.4966 Acc: 0.8000\n",
      "2020-10-21 00:08:19,787 - INFO - Epoch [ 37/100] - Batch [     0/  1483] ( 0%) - Loss 1.2222\n",
      "2020-10-21 00:08:54,666 - INFO - Current lr: 0.01\n",
      "2020-10-21 00:08:54,668 - INFO - valid, Loss: 1.6641 Acc: 0.5280\n",
      "0.527080894016378\n",
      "2020-10-21 00:09:06,314 - INFO - Epoch [ 38/100] - Batch [     0/ 29640] ( 0%) - Loss 0.3858\n",
      "2020-10-21 00:10:18,099 - INFO - Epoch [ 38/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.7525\n",
      "2020-10-21 00:11:27,788 - INFO - Epoch [ 38/100] - Batch [  3200/ 29640] (11%) - Loss 0.3492\n",
      "2020-10-21 00:12:37,398 - INFO - Epoch [ 38/100] - Batch [  4800/ 29640] (16%) - Loss 0.5661\n",
      "2020-10-21 00:13:46,696 - INFO - Epoch [ 38/100] - Batch [  6400/ 29640] (22%) - Loss 0.4564\n",
      "2020-10-21 00:14:55,948 - INFO - Epoch [ 38/100] - Batch [  8000/ 29640] (27%) - Loss 0.4867\n",
      "2020-10-21 00:16:05,236 - INFO - Epoch [ 38/100] - Batch [  9600/ 29640] (32%) - Loss 0.5383\n",
      "2020-10-21 00:17:14,586 - INFO - Epoch [ 38/100] - Batch [ 11200/ 29640] (38%) - Loss 0.7168\n",
      "2020-10-21 00:18:23,859 - INFO - Epoch [ 38/100] - Batch [ 12800/ 29640] (43%) - Loss 0.7073\n",
      "2020-10-21 00:19:33,512 - INFO - Epoch [ 38/100] - Batch [ 14400/ 29640] (49%) - Loss 0.5965\n",
      "2020-10-21 00:20:42,519 - INFO - Epoch [ 38/100] - Batch [ 16000/ 29640] (54%) - Loss 0.4688\n",
      "2020-10-21 00:21:51,587 - INFO - Epoch [ 38/100] - Batch [ 17600/ 29640] (59%) - Loss 0.6862\n",
      "2020-10-21 00:23:00,702 - INFO - Epoch [ 38/100] - Batch [ 19200/ 29640] (65%) - Loss 0.3921\n",
      "2020-10-21 00:24:10,020 - INFO - Epoch [ 38/100] - Batch [ 20800/ 29640] (70%) - Loss 0.2646\n",
      "2020-10-21 00:25:19,336 - INFO - Epoch [ 38/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4727\n",
      "2020-10-21 00:26:28,823 - INFO - Epoch [ 38/100] - Batch [ 24000/ 29640] (81%) - Loss 0.3715\n",
      "2020-10-21 00:27:38,203 - INFO - Epoch [ 38/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4395\n",
      "2020-10-21 00:28:46,629 - INFO - Epoch [ 38/100] - Batch [ 27200/ 29640] (92%) - Loss 0.3682\n",
      "2020-10-21 00:29:53,533 - INFO - Epoch [ 38/100] - Batch [ 28800/ 29640] (97%) - Loss 0.3834\n",
      "2020-10-21 00:30:28,661 - INFO - Current lr: 0.01\n",
      "2020-10-21 00:30:28,662 - INFO - train, Loss: 0.4958 Acc: 0.8000\n",
      "2020-10-21 00:30:36,396 - INFO - Epoch [ 38/100] - Batch [     0/  1483] ( 0%) - Loss 1.1380\n",
      "2020-10-21 00:31:11,038 - INFO - Current lr: 0.01\n",
      "2020-10-21 00:31:11,039 - INFO - valid, Loss: 2.4606 Acc: 0.5226\n",
      "0.5226469766792349\n",
      "2020-10-21 00:31:11,040 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 00:31:21,513 - INFO - Epoch [ 39/100] - Batch [     0/ 29640] ( 0%) - Loss 0.6172\n",
      "2020-10-21 00:32:34,584 - INFO - Epoch [ 39/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.3082\n",
      "2020-10-21 00:33:44,751 - INFO - Epoch [ 39/100] - Batch [  3200/ 29640] (11%) - Loss 0.5773\n",
      "2020-10-21 00:34:54,467 - INFO - Epoch [ 39/100] - Batch [  4800/ 29640] (16%) - Loss 0.3620\n",
      "2020-10-21 00:36:04,026 - INFO - Epoch [ 39/100] - Batch [  6400/ 29640] (22%) - Loss 0.2949\n",
      "2020-10-21 00:37:13,822 - INFO - Epoch [ 39/100] - Batch [  8000/ 29640] (27%) - Loss 0.4757\n",
      "2020-10-21 00:38:23,258 - INFO - Epoch [ 39/100] - Batch [  9600/ 29640] (32%) - Loss 0.7089\n",
      "2020-10-21 00:39:32,480 - INFO - Epoch [ 39/100] - Batch [ 11200/ 29640] (38%) - Loss 0.5209\n",
      "2020-10-21 00:40:42,083 - INFO - Epoch [ 39/100] - Batch [ 12800/ 29640] (43%) - Loss 0.5024\n",
      "2020-10-21 00:41:51,813 - INFO - Epoch [ 39/100] - Batch [ 14400/ 29640] (49%) - Loss 0.5737\n",
      "2020-10-21 00:43:01,160 - INFO - Epoch [ 39/100] - Batch [ 16000/ 29640] (54%) - Loss 0.6360\n",
      "2020-10-21 00:44:11,058 - INFO - Epoch [ 39/100] - Batch [ 17600/ 29640] (59%) - Loss 0.5664\n",
      "2020-10-21 00:45:20,827 - INFO - Epoch [ 39/100] - Batch [ 19200/ 29640] (65%) - Loss 0.6723\n",
      "2020-10-21 00:46:30,919 - INFO - Epoch [ 39/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5672\n",
      "2020-10-21 00:47:40,363 - INFO - Epoch [ 39/100] - Batch [ 22400/ 29640] (76%) - Loss 0.3997\n",
      "2020-10-21 00:48:49,298 - INFO - Epoch [ 39/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4829\n",
      "2020-10-21 00:49:58,313 - INFO - Epoch [ 39/100] - Batch [ 25600/ 29640] (86%) - Loss 0.3268\n",
      "2020-10-21 00:51:07,315 - INFO - Epoch [ 39/100] - Batch [ 27200/ 29640] (92%) - Loss 0.5565\n",
      "2020-10-21 00:52:15,165 - INFO - Epoch [ 39/100] - Batch [ 28800/ 29640] (97%) - Loss 0.5667\n",
      "2020-10-21 00:52:50,531 - INFO - Current lr: 0.01\n",
      "2020-10-21 00:52:50,533 - INFO - train, Loss: 0.4948 Acc: 0.8000\n",
      "2020-10-21 00:52:58,713 - INFO - Epoch [ 39/100] - Batch [     0/  1483] ( 0%) - Loss 0.6559\n",
      "2020-10-21 00:53:32,147 - INFO - Current lr: 0.01\n",
      "2020-10-21 00:53:32,148 - INFO - valid, Loss: 0.9301 Acc: 0.5199\n",
      "0.5182239803207546\n",
      "2020-10-21 00:53:32,148 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 00:53:42,552 - INFO - Epoch [ 40/100] - Batch [     0/ 29640] ( 0%) - Loss 0.6914\n",
      "2020-10-21 00:54:56,319 - INFO - Epoch [ 40/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.5441\n",
      "2020-10-21 00:56:07,537 - INFO - Epoch [ 40/100] - Batch [  3200/ 29640] (11%) - Loss 0.7373\n",
      "2020-10-21 00:57:18,184 - INFO - Epoch [ 40/100] - Batch [  4800/ 29640] (16%) - Loss 0.5494\n",
      "2020-10-21 00:58:28,191 - INFO - Epoch [ 40/100] - Batch [  6400/ 29640] (22%) - Loss 0.5510\n",
      "2020-10-21 00:59:38,114 - INFO - Epoch [ 40/100] - Batch [  8000/ 29640] (27%) - Loss 0.5164\n",
      "2020-10-21 01:00:48,170 - INFO - Epoch [ 40/100] - Batch [  9600/ 29640] (32%) - Loss 0.3330\n",
      "2020-10-21 01:01:57,973 - INFO - Epoch [ 40/100] - Batch [ 11200/ 29640] (38%) - Loss 0.4778\n",
      "2020-10-21 01:03:07,563 - INFO - Epoch [ 40/100] - Batch [ 12800/ 29640] (43%) - Loss 0.3189\n",
      "2020-10-21 01:04:17,426 - INFO - Epoch [ 40/100] - Batch [ 14400/ 29640] (49%) - Loss 0.6314\n",
      "2020-10-21 01:05:27,064 - INFO - Epoch [ 40/100] - Batch [ 16000/ 29640] (54%) - Loss 0.2922\n",
      "2020-10-21 01:06:37,079 - INFO - Epoch [ 40/100] - Batch [ 17600/ 29640] (59%) - Loss 0.4566\n",
      "2020-10-21 01:07:46,568 - INFO - Epoch [ 40/100] - Batch [ 19200/ 29640] (65%) - Loss 0.8005\n",
      "2020-10-21 01:08:55,865 - INFO - Epoch [ 40/100] - Batch [ 20800/ 29640] (70%) - Loss 0.7536\n",
      "2020-10-21 01:10:05,096 - INFO - Epoch [ 40/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4496\n",
      "2020-10-21 01:11:14,197 - INFO - Epoch [ 40/100] - Batch [ 24000/ 29640] (81%) - Loss 0.5322\n",
      "2020-10-21 01:12:23,972 - INFO - Epoch [ 40/100] - Batch [ 25600/ 29640] (86%) - Loss 0.6764\n",
      "2020-10-21 01:13:32,821 - INFO - Epoch [ 40/100] - Batch [ 27200/ 29640] (92%) - Loss 0.4945\n",
      "2020-10-21 01:14:39,745 - INFO - Epoch [ 40/100] - Batch [ 28800/ 29640] (97%) - Loss 0.3682\n",
      "2020-10-21 01:15:14,869 - INFO - Current lr: 0.01\n",
      "2020-10-21 01:15:14,870 - INFO - train, Loss: 0.4957 Acc: 0.8000\n",
      "2020-10-21 01:15:22,885 - INFO - Epoch [ 40/100] - Batch [     0/  1483] ( 0%) - Loss 1.0233\n",
      "2020-10-21 01:15:57,235 - INFO - Current lr: 0.01\n",
      "2020-10-21 01:15:57,236 - INFO - valid, Loss: 1.0409 Acc: 0.5057\n",
      "0.5038541506283442\n",
      "2020-10-21 01:15:57,237 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 01:16:07,729 - INFO - Epoch [ 41/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4478\n",
      "2020-10-21 01:17:19,834 - INFO - Epoch [ 41/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.2580\n",
      "2020-10-21 01:18:29,418 - INFO - Epoch [ 41/100] - Batch [  3200/ 29640] (11%) - Loss 0.3312\n",
      "2020-10-21 01:19:38,971 - INFO - Epoch [ 41/100] - Batch [  4800/ 29640] (16%) - Loss 0.3346\n",
      "2020-10-21 01:20:49,078 - INFO - Epoch [ 41/100] - Batch [  6400/ 29640] (22%) - Loss 0.2941\n",
      "2020-10-21 01:21:58,492 - INFO - Epoch [ 41/100] - Batch [  8000/ 29640] (27%) - Loss 0.3674\n",
      "2020-10-21 01:23:07,541 - INFO - Epoch [ 41/100] - Batch [  9600/ 29640] (32%) - Loss 0.5753\n",
      "2020-10-21 01:24:16,518 - INFO - Epoch [ 41/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3927\n",
      "2020-10-21 01:25:26,195 - INFO - Epoch [ 41/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4427\n",
      "2020-10-21 01:26:36,386 - INFO - Epoch [ 41/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4341\n",
      "2020-10-21 01:27:45,521 - INFO - Epoch [ 41/100] - Batch [ 16000/ 29640] (54%) - Loss 0.5113\n",
      "2020-10-21 01:28:54,555 - INFO - Epoch [ 41/100] - Batch [ 17600/ 29640] (59%) - Loss 0.3947\n",
      "2020-10-21 01:30:04,131 - INFO - Epoch [ 41/100] - Batch [ 19200/ 29640] (65%) - Loss 0.5761\n",
      "2020-10-21 01:31:13,478 - INFO - Epoch [ 41/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5086\n",
      "2020-10-21 01:32:23,307 - INFO - Epoch [ 41/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4589\n",
      "2020-10-21 01:33:32,748 - INFO - Epoch [ 41/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4611\n",
      "2020-10-21 01:34:41,807 - INFO - Epoch [ 41/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4684\n",
      "2020-10-21 01:35:50,656 - INFO - Epoch [ 41/100] - Batch [ 27200/ 29640] (92%) - Loss 0.6519\n",
      "2020-10-21 01:36:58,527 - INFO - Epoch [ 41/100] - Batch [ 28800/ 29640] (97%) - Loss 0.5006\n",
      "2020-10-21 01:37:33,838 - INFO - Current lr: 0.01\n",
      "2020-10-21 01:37:33,840 - INFO - train, Loss: 0.4945 Acc: 0.8000\n",
      "2020-10-21 01:37:43,147 - INFO - Epoch [ 41/100] - Batch [     0/  1483] ( 0%) - Loss 0.5656\n",
      "2020-10-21 01:38:16,308 - INFO - Current lr: 0.01\n",
      "2020-10-21 01:38:16,309 - INFO - valid, Loss: 0.8340 Acc: 0.5239\n",
      "0.5291087347538963\n",
      "2020-10-21 01:38:16,310 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 01:38:28,614 - INFO - Epoch [ 42/100] - Batch [     0/ 29640] ( 0%) - Loss 0.6062\n",
      "2020-10-21 01:39:40,271 - INFO - Epoch [ 42/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.4843\n",
      "2020-10-21 01:40:49,778 - INFO - Epoch [ 42/100] - Batch [  3200/ 29640] (11%) - Loss 0.3854\n",
      "2020-10-21 01:41:59,347 - INFO - Epoch [ 42/100] - Batch [  4800/ 29640] (16%) - Loss 0.4840\n",
      "2020-10-21 01:43:08,642 - INFO - Epoch [ 42/100] - Batch [  6400/ 29640] (22%) - Loss 0.6564\n",
      "2020-10-21 01:44:18,415 - INFO - Epoch [ 42/100] - Batch [  8000/ 29640] (27%) - Loss 0.4599\n",
      "2020-10-21 01:45:27,928 - INFO - Epoch [ 42/100] - Batch [  9600/ 29640] (32%) - Loss 0.5339\n",
      "2020-10-21 01:46:37,296 - INFO - Epoch [ 42/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3030\n",
      "2020-10-21 01:47:46,567 - INFO - Epoch [ 42/100] - Batch [ 12800/ 29640] (43%) - Loss 0.6640\n",
      "2020-10-21 01:48:55,665 - INFO - Epoch [ 42/100] - Batch [ 14400/ 29640] (49%) - Loss 0.5674\n",
      "2020-10-21 01:50:05,048 - INFO - Epoch [ 42/100] - Batch [ 16000/ 29640] (54%) - Loss 0.5795\n",
      "2020-10-21 01:51:14,806 - INFO - Epoch [ 42/100] - Batch [ 17600/ 29640] (59%) - Loss 0.4744\n",
      "2020-10-21 01:52:24,434 - INFO - Epoch [ 42/100] - Batch [ 19200/ 29640] (65%) - Loss 0.3176\n",
      "2020-10-21 01:53:33,490 - INFO - Epoch [ 42/100] - Batch [ 20800/ 29640] (70%) - Loss 0.6395\n",
      "2020-10-21 01:54:42,407 - INFO - Epoch [ 42/100] - Batch [ 22400/ 29640] (76%) - Loss 0.2325\n",
      "2020-10-21 01:55:51,700 - INFO - Epoch [ 42/100] - Batch [ 24000/ 29640] (81%) - Loss 0.6289\n",
      "2020-10-21 01:57:00,964 - INFO - Epoch [ 42/100] - Batch [ 25600/ 29640] (86%) - Loss 0.3500\n",
      "2020-10-21 01:58:08,750 - INFO - Epoch [ 42/100] - Batch [ 27200/ 29640] (92%) - Loss 0.6078\n",
      "2020-10-21 01:59:15,677 - INFO - Epoch [ 42/100] - Batch [ 28800/ 29640] (97%) - Loss 0.4252\n",
      "2020-10-21 01:59:50,590 - INFO - Current lr: 0.01\n",
      "2020-10-21 01:59:50,591 - INFO - train, Loss: 0.4969 Acc: 0.8000\n",
      "2020-10-21 01:59:59,227 - INFO - Epoch [ 42/100] - Batch [     0/  1483] ( 0%) - Loss 0.8675\n",
      "2020-10-21 02:00:32,991 - INFO - Current lr: 0.01\n",
      "2020-10-21 02:00:32,993 - INFO - valid, Loss: 0.8183 Acc: 0.4949\n",
      "0.492612912774203\n",
      "2020-10-21 02:00:32,994 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 02:00:46,953 - INFO - Epoch [ 43/100] - Batch [     0/ 29640] ( 0%) - Loss 0.5836\n",
      "2020-10-21 02:01:58,685 - INFO - Epoch [ 43/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.3199\n",
      "2020-10-21 02:03:08,878 - INFO - Epoch [ 43/100] - Batch [  3200/ 29640] (11%) - Loss 0.4905\n",
      "2020-10-21 02:04:18,522 - INFO - Epoch [ 43/100] - Batch [  4800/ 29640] (16%) - Loss 0.3721\n",
      "2020-10-21 02:05:28,111 - INFO - Epoch [ 43/100] - Batch [  6400/ 29640] (22%) - Loss 0.2952\n",
      "2020-10-21 02:06:38,250 - INFO - Epoch [ 43/100] - Batch [  8000/ 29640] (27%) - Loss 0.5686\n",
      "2020-10-21 02:07:48,468 - INFO - Epoch [ 43/100] - Batch [  9600/ 29640] (32%) - Loss 0.6088\n",
      "2020-10-21 02:08:58,211 - INFO - Epoch [ 43/100] - Batch [ 11200/ 29640] (38%) - Loss 0.4779\n",
      "2020-10-21 02:10:07,345 - INFO - Epoch [ 43/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4166\n",
      "2020-10-21 02:11:16,642 - INFO - Epoch [ 43/100] - Batch [ 14400/ 29640] (49%) - Loss 0.3188\n",
      "2020-10-21 02:12:26,036 - INFO - Epoch [ 43/100] - Batch [ 16000/ 29640] (54%) - Loss 0.6207\n",
      "2020-10-21 02:13:35,537 - INFO - Epoch [ 43/100] - Batch [ 17600/ 29640] (59%) - Loss 0.5208\n",
      "2020-10-21 02:14:45,240 - INFO - Epoch [ 43/100] - Batch [ 19200/ 29640] (65%) - Loss 0.5585\n",
      "2020-10-21 02:15:54,796 - INFO - Epoch [ 43/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5132\n",
      "2020-10-21 02:17:04,429 - INFO - Epoch [ 43/100] - Batch [ 22400/ 29640] (76%) - Loss 0.3788\n",
      "2020-10-21 02:18:14,279 - INFO - Epoch [ 43/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4530\n",
      "2020-10-21 02:19:23,920 - INFO - Epoch [ 43/100] - Batch [ 25600/ 29640] (86%) - Loss 0.3440\n",
      "2020-10-21 02:20:32,826 - INFO - Epoch [ 43/100] - Batch [ 27200/ 29640] (92%) - Loss 0.4875\n",
      "2020-10-21 02:21:40,868 - INFO - Epoch [ 43/100] - Batch [ 28800/ 29640] (97%) - Loss 0.4176\n",
      "2020-10-21 02:22:16,298 - INFO - Current lr: 0.01\n",
      "2020-10-21 02:22:16,300 - INFO - train, Loss: 0.4958 Acc: 0.8000\n",
      "2020-10-21 02:22:24,654 - INFO - Epoch [ 43/100] - Batch [     0/  1483] ( 0%) - Loss 0.6760\n",
      "2020-10-21 02:22:58,331 - INFO - Current lr: 0.01\n",
      "2020-10-21 02:22:58,332 - INFO - valid, Loss: 0.9454 Acc: 0.5003\n",
      "0.5\n",
      "2020-10-21 02:22:58,333 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 02:23:08,559 - INFO - Epoch [ 44/100] - Batch [     0/ 29640] ( 0%) - Loss 0.5055\n",
      "2020-10-21 02:24:22,395 - INFO - Epoch [ 44/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.3065\n",
      "2020-10-21 02:25:33,159 - INFO - Epoch [ 44/100] - Batch [  3200/ 29640] (11%) - Loss 0.7522\n",
      "2020-10-21 02:26:43,780 - INFO - Epoch [ 44/100] - Batch [  4800/ 29640] (16%) - Loss 0.5155\n",
      "2020-10-21 02:27:54,142 - INFO - Epoch [ 44/100] - Batch [  6400/ 29640] (22%) - Loss 0.5350\n",
      "2020-10-21 02:29:03,952 - INFO - Epoch [ 44/100] - Batch [  8000/ 29640] (27%) - Loss 0.5101\n",
      "2020-10-21 02:30:14,255 - INFO - Epoch [ 44/100] - Batch [  9600/ 29640] (32%) - Loss 0.7452\n",
      "2020-10-21 02:31:24,606 - INFO - Epoch [ 44/100] - Batch [ 11200/ 29640] (38%) - Loss 0.4116\n",
      "2020-10-21 02:32:34,627 - INFO - Epoch [ 44/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4418\n",
      "2020-10-21 02:33:44,385 - INFO - Epoch [ 44/100] - Batch [ 14400/ 29640] (49%) - Loss 0.5786\n",
      "2020-10-21 02:34:53,978 - INFO - Epoch [ 44/100] - Batch [ 16000/ 29640] (54%) - Loss 0.4248\n",
      "2020-10-21 02:36:03,851 - INFO - Epoch [ 44/100] - Batch [ 17600/ 29640] (59%) - Loss 0.5640\n",
      "2020-10-21 02:37:13,845 - INFO - Epoch [ 44/100] - Batch [ 19200/ 29640] (65%) - Loss 0.6574\n",
      "2020-10-21 02:38:23,313 - INFO - Epoch [ 44/100] - Batch [ 20800/ 29640] (70%) - Loss 0.4088\n",
      "2020-10-21 02:39:32,959 - INFO - Epoch [ 44/100] - Batch [ 22400/ 29640] (76%) - Loss 0.6324\n",
      "2020-10-21 02:40:42,506 - INFO - Epoch [ 44/100] - Batch [ 24000/ 29640] (81%) - Loss 0.5756\n",
      "2020-10-21 02:41:52,527 - INFO - Epoch [ 44/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4548\n",
      "2020-10-21 02:43:01,165 - INFO - Epoch [ 44/100] - Batch [ 27200/ 29640] (92%) - Loss 0.5362\n",
      "2020-10-21 02:44:08,212 - INFO - Epoch [ 44/100] - Batch [ 28800/ 29640] (97%) - Loss 0.5899\n",
      "2020-10-21 02:44:43,261 - INFO - Current lr: 0.01\n",
      "2020-10-21 02:44:43,263 - INFO - train, Loss: 0.4945 Acc: 0.8000\n",
      "2020-10-21 02:44:51,361 - INFO - Epoch [ 44/100] - Batch [     0/  1483] ( 0%) - Loss 1.0099\n",
      "2020-10-21 02:45:25,437 - INFO - Current lr: 0.01\n",
      "2020-10-21 02:45:25,438 - INFO - valid, Loss: 0.9438 Acc: 0.5017\n",
      "0.5010005973715651\n",
      "2020-10-21 02:45:25,439 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 02:45:36,391 - INFO - Epoch [ 45/100] - Batch [     0/ 29640] ( 0%) - Loss 0.7463\n",
      "2020-10-21 02:46:49,067 - INFO - Epoch [ 45/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.2920\n",
      "2020-10-21 02:47:58,719 - INFO - Epoch [ 45/100] - Batch [  3200/ 29640] (11%) - Loss 0.5669\n",
      "2020-10-21 02:49:08,254 - INFO - Epoch [ 45/100] - Batch [  4800/ 29640] (16%) - Loss 0.5280\n",
      "2020-10-21 02:50:17,678 - INFO - Epoch [ 45/100] - Batch [  6400/ 29640] (22%) - Loss 0.5274\n",
      "2020-10-21 02:51:27,247 - INFO - Epoch [ 45/100] - Batch [  8000/ 29640] (27%) - Loss 0.5691\n",
      "2020-10-21 02:52:37,329 - INFO - Epoch [ 45/100] - Batch [  9600/ 29640] (32%) - Loss 0.6131\n",
      "2020-10-21 02:53:46,785 - INFO - Epoch [ 45/100] - Batch [ 11200/ 29640] (38%) - Loss 0.8441\n",
      "2020-10-21 02:54:56,368 - INFO - Epoch [ 45/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4533\n",
      "2020-10-21 02:56:06,008 - INFO - Epoch [ 45/100] - Batch [ 14400/ 29640] (49%) - Loss 0.3607\n",
      "2020-10-21 02:57:16,240 - INFO - Epoch [ 45/100] - Batch [ 16000/ 29640] (54%) - Loss 0.5593\n",
      "2020-10-21 02:58:25,737 - INFO - Epoch [ 45/100] - Batch [ 17600/ 29640] (59%) - Loss 0.6190\n",
      "2020-10-21 02:59:35,063 - INFO - Epoch [ 45/100] - Batch [ 19200/ 29640] (65%) - Loss 0.3745\n",
      "2020-10-21 03:00:44,737 - INFO - Epoch [ 45/100] - Batch [ 20800/ 29640] (70%) - Loss 0.4205\n",
      "2020-10-21 03:01:54,545 - INFO - Epoch [ 45/100] - Batch [ 22400/ 29640] (76%) - Loss 0.3807\n",
      "2020-10-21 03:03:04,146 - INFO - Epoch [ 45/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4437\n",
      "2020-10-21 03:04:13,506 - INFO - Epoch [ 45/100] - Batch [ 25600/ 29640] (86%) - Loss 0.3055\n",
      "2020-10-21 03:05:22,041 - INFO - Epoch [ 45/100] - Batch [ 27200/ 29640] (92%) - Loss 0.4758\n",
      "2020-10-21 03:06:29,570 - INFO - Epoch [ 45/100] - Batch [ 28800/ 29640] (97%) - Loss 0.3893\n",
      "2020-10-21 03:07:04,954 - INFO - Current lr: 0.01\n",
      "2020-10-21 03:07:04,955 - INFO - train, Loss: 0.4944 Acc: 0.8000\n",
      "2020-10-21 03:07:13,256 - INFO - Epoch [ 45/100] - Batch [     0/  1483] ( 0%) - Loss 0.6846\n",
      "2020-10-21 03:07:47,318 - INFO - Current lr: 0.01\n",
      "2020-10-21 03:07:47,320 - INFO - valid, Loss: 0.8227 Acc: 0.5253\n",
      "0.5254662004662005\n",
      "2020-10-21 03:07:59,009 - INFO - Epoch [ 46/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4565\n",
      "2020-10-21 03:09:11,278 - INFO - Epoch [ 46/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.5551\n",
      "2020-10-21 03:10:20,737 - INFO - Epoch [ 46/100] - Batch [  3200/ 29640] (11%) - Loss 0.5554\n",
      "2020-10-21 03:11:30,051 - INFO - Epoch [ 46/100] - Batch [  4800/ 29640] (16%) - Loss 0.3789\n",
      "2020-10-21 03:12:39,344 - INFO - Epoch [ 46/100] - Batch [  6400/ 29640] (22%) - Loss 0.7306\n",
      "2020-10-21 03:13:48,470 - INFO - Epoch [ 46/100] - Batch [  8000/ 29640] (27%) - Loss 0.4900\n",
      "2020-10-21 03:14:57,401 - INFO - Epoch [ 46/100] - Batch [  9600/ 29640] (32%) - Loss 0.6162\n",
      "2020-10-21 03:16:06,116 - INFO - Epoch [ 46/100] - Batch [ 11200/ 29640] (38%) - Loss 0.5380\n",
      "2020-10-21 03:17:15,280 - INFO - Epoch [ 46/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4006\n",
      "2020-10-21 03:18:24,455 - INFO - Epoch [ 46/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4714\n",
      "2020-10-21 03:19:33,595 - INFO - Epoch [ 46/100] - Batch [ 16000/ 29640] (54%) - Loss 0.2867\n",
      "2020-10-21 03:20:42,482 - INFO - Epoch [ 46/100] - Batch [ 17600/ 29640] (59%) - Loss 0.5579\n",
      "2020-10-21 03:21:51,479 - INFO - Epoch [ 46/100] - Batch [ 19200/ 29640] (65%) - Loss 0.3073\n",
      "2020-10-21 03:23:00,506 - INFO - Epoch [ 46/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5706\n",
      "2020-10-21 03:24:09,471 - INFO - Epoch [ 46/100] - Batch [ 22400/ 29640] (76%) - Loss 0.6185\n",
      "2020-10-21 03:25:18,822 - INFO - Epoch [ 46/100] - Batch [ 24000/ 29640] (81%) - Loss 0.5039\n",
      "2020-10-21 03:26:28,057 - INFO - Epoch [ 46/100] - Batch [ 25600/ 29640] (86%) - Loss 0.3898\n",
      "2020-10-21 03:27:36,599 - INFO - Epoch [ 46/100] - Batch [ 27200/ 29640] (92%) - Loss 0.2373\n",
      "2020-10-21 03:28:44,388 - INFO - Epoch [ 46/100] - Batch [ 28800/ 29640] (97%) - Loss 0.5330\n",
      "2020-10-21 03:29:19,566 - INFO - Current lr: 0.01\n",
      "2020-10-21 03:29:19,568 - INFO - train, Loss: 0.4951 Acc: 0.8000\n",
      "2020-10-21 03:29:28,066 - INFO - Epoch [ 46/100] - Batch [     0/  1483] ( 0%) - Loss 1.8965\n",
      "2020-10-21 03:30:02,744 - INFO - Current lr: 0.01\n",
      "2020-10-21 03:30:02,745 - INFO - valid, Loss: 1.4306 Acc: 0.5003\n",
      "0.5\n",
      "2020-10-21 03:30:02,746 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 03:30:13,508 - INFO - Epoch [ 47/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4869\n",
      "2020-10-21 03:31:25,774 - INFO - Epoch [ 47/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.2314\n",
      "2020-10-21 03:32:35,561 - INFO - Epoch [ 47/100] - Batch [  3200/ 29640] (11%) - Loss 0.4550\n",
      "2020-10-21 03:33:44,872 - INFO - Epoch [ 47/100] - Batch [  4800/ 29640] (16%) - Loss 0.3761\n",
      "2020-10-21 03:34:54,045 - INFO - Epoch [ 47/100] - Batch [  6400/ 29640] (22%) - Loss 0.4459\n",
      "2020-10-21 03:36:03,316 - INFO - Epoch [ 47/100] - Batch [  8000/ 29640] (27%) - Loss 0.6053\n",
      "2020-10-21 03:37:12,498 - INFO - Epoch [ 47/100] - Batch [  9600/ 29640] (32%) - Loss 0.3136\n",
      "2020-10-21 03:38:21,231 - INFO - Epoch [ 47/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3801\n",
      "2020-10-21 03:39:30,123 - INFO - Epoch [ 47/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4874\n",
      "2020-10-21 03:40:39,340 - INFO - Epoch [ 47/100] - Batch [ 14400/ 29640] (49%) - Loss 0.3143\n",
      "2020-10-21 03:41:49,332 - INFO - Epoch [ 47/100] - Batch [ 16000/ 29640] (54%) - Loss 0.2947\n",
      "2020-10-21 03:42:58,645 - INFO - Epoch [ 47/100] - Batch [ 17600/ 29640] (59%) - Loss 0.4371\n",
      "2020-10-21 03:44:07,694 - INFO - Epoch [ 47/100] - Batch [ 19200/ 29640] (65%) - Loss 0.6870\n",
      "2020-10-21 03:45:16,848 - INFO - Epoch [ 47/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5255\n",
      "2020-10-21 03:46:26,357 - INFO - Epoch [ 47/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4907\n",
      "2020-10-21 03:47:35,587 - INFO - Epoch [ 47/100] - Batch [ 24000/ 29640] (81%) - Loss 0.3254\n",
      "2020-10-21 03:48:44,677 - INFO - Epoch [ 47/100] - Batch [ 25600/ 29640] (86%) - Loss 0.6108\n",
      "2020-10-21 03:49:52,788 - INFO - Epoch [ 47/100] - Batch [ 27200/ 29640] (92%) - Loss 0.6909\n",
      "2020-10-21 03:51:00,036 - INFO - Epoch [ 47/100] - Batch [ 28800/ 29640] (97%) - Loss 0.3103\n",
      "2020-10-21 03:51:35,336 - INFO - Current lr: 0.01\n",
      "2020-10-21 03:51:35,338 - INFO - train, Loss: 0.4954 Acc: 0.8000\n",
      "2020-10-21 03:51:44,048 - INFO - Epoch [ 47/100] - Batch [     0/  1483] ( 0%) - Loss 0.6253\n",
      "2020-10-21 03:52:17,400 - INFO - Current lr: 0.01\n",
      "2020-10-21 03:52:17,401 - INFO - valid, Loss: 0.9055 Acc: 0.5172\n",
      "0.5160284906252649\n",
      "2020-10-21 03:52:27,869 - INFO - Epoch [ 48/100] - Batch [     0/ 29640] ( 0%) - Loss 0.5481\n",
      "2020-10-21 03:53:41,666 - INFO - Epoch [ 48/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.5137\n",
      "2020-10-21 03:54:51,682 - INFO - Epoch [ 48/100] - Batch [  3200/ 29640] (11%) - Loss 0.4772\n",
      "2020-10-21 03:56:01,818 - INFO - Epoch [ 48/100] - Batch [  4800/ 29640] (16%) - Loss 0.5111\n",
      "2020-10-21 03:57:12,139 - INFO - Epoch [ 48/100] - Batch [  6400/ 29640] (22%) - Loss 0.7072\n",
      "2020-10-21 03:58:21,803 - INFO - Epoch [ 48/100] - Batch [  8000/ 29640] (27%) - Loss 0.6065\n",
      "2020-10-21 03:59:31,685 - INFO - Epoch [ 48/100] - Batch [  9600/ 29640] (32%) - Loss 0.3367\n",
      "2020-10-21 04:00:41,769 - INFO - Epoch [ 48/100] - Batch [ 11200/ 29640] (38%) - Loss 0.4484\n",
      "2020-10-21 04:01:51,663 - INFO - Epoch [ 48/100] - Batch [ 12800/ 29640] (43%) - Loss 0.6954\n",
      "2020-10-21 04:03:01,441 - INFO - Epoch [ 48/100] - Batch [ 14400/ 29640] (49%) - Loss 0.7452\n",
      "2020-10-21 04:04:11,198 - INFO - Epoch [ 48/100] - Batch [ 16000/ 29640] (54%) - Loss 0.2486\n",
      "2020-10-21 04:05:20,982 - INFO - Epoch [ 48/100] - Batch [ 17600/ 29640] (59%) - Loss 0.6614\n",
      "2020-10-21 04:06:31,153 - INFO - Epoch [ 48/100] - Batch [ 19200/ 29640] (65%) - Loss 0.4083\n",
      "2020-10-21 04:07:40,692 - INFO - Epoch [ 48/100] - Batch [ 20800/ 29640] (70%) - Loss 0.3861\n",
      "2020-10-21 04:08:50,536 - INFO - Epoch [ 48/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4853\n",
      "2020-10-21 04:10:00,057 - INFO - Epoch [ 48/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4241\n",
      "2020-10-21 04:11:09,561 - INFO - Epoch [ 48/100] - Batch [ 25600/ 29640] (86%) - Loss 0.5214\n",
      "2020-10-21 04:12:18,292 - INFO - Epoch [ 48/100] - Batch [ 27200/ 29640] (92%) - Loss 0.5131\n",
      "2020-10-21 04:13:25,680 - INFO - Epoch [ 48/100] - Batch [ 28800/ 29640] (97%) - Loss 0.7923\n",
      "2020-10-21 04:14:00,606 - INFO - Current lr: 0.01\n",
      "2020-10-21 04:14:00,608 - INFO - train, Loss: 0.4950 Acc: 0.8000\n",
      "2020-10-21 04:14:09,107 - INFO - Epoch [ 48/100] - Batch [     0/  1483] ( 0%) - Loss 0.8099\n",
      "2020-10-21 04:14:43,663 - INFO - Current lr: 0.01\n",
      "2020-10-21 04:14:43,664 - INFO - valid, Loss: 0.7644 Acc: 0.5098\n",
      "0.5085147976277008\n",
      "2020-10-21 04:14:43,665 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 04:14:53,460 - INFO - Epoch [ 49/100] - Batch [     0/ 29640] ( 0%) - Loss 0.3630\n",
      "2020-10-21 04:16:06,872 - INFO - Epoch [ 49/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.5814\n",
      "2020-10-21 04:17:15,746 - INFO - Epoch [ 49/100] - Batch [  3200/ 29640] (11%) - Loss 0.5725\n",
      "2020-10-21 04:18:24,631 - INFO - Epoch [ 49/100] - Batch [  4800/ 29640] (16%) - Loss 0.4971\n",
      "2020-10-21 04:19:33,386 - INFO - Epoch [ 49/100] - Batch [  6400/ 29640] (22%) - Loss 0.6678\n",
      "2020-10-21 04:20:42,301 - INFO - Epoch [ 49/100] - Batch [  8000/ 29640] (27%) - Loss 0.4840\n",
      "2020-10-21 04:21:51,186 - INFO - Epoch [ 49/100] - Batch [  9600/ 29640] (32%) - Loss 0.5035\n",
      "2020-10-21 04:23:00,293 - INFO - Epoch [ 49/100] - Batch [ 11200/ 29640] (38%) - Loss 0.4283\n",
      "2020-10-21 04:24:09,137 - INFO - Epoch [ 49/100] - Batch [ 12800/ 29640] (43%) - Loss 0.3019\n",
      "2020-10-21 04:25:17,770 - INFO - Epoch [ 49/100] - Batch [ 14400/ 29640] (49%) - Loss 0.3680\n",
      "2020-10-21 04:26:27,138 - INFO - Epoch [ 49/100] - Batch [ 16000/ 29640] (54%) - Loss 0.7125\n",
      "2020-10-21 04:27:35,966 - INFO - Epoch [ 49/100] - Batch [ 17600/ 29640] (59%) - Loss 0.5134\n",
      "2020-10-21 04:28:44,753 - INFO - Epoch [ 49/100] - Batch [ 19200/ 29640] (65%) - Loss 0.4788\n",
      "2020-10-21 04:29:53,543 - INFO - Epoch [ 49/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5167\n",
      "2020-10-21 04:31:02,461 - INFO - Epoch [ 49/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4473\n",
      "2020-10-21 04:32:11,576 - INFO - Epoch [ 49/100] - Batch [ 24000/ 29640] (81%) - Loss 0.5743\n",
      "2020-10-21 04:33:20,773 - INFO - Epoch [ 49/100] - Batch [ 25600/ 29640] (86%) - Loss 0.6916\n",
      "2020-10-21 04:34:29,155 - INFO - Epoch [ 49/100] - Batch [ 27200/ 29640] (92%) - Loss 0.3396\n",
      "2020-10-21 04:35:36,704 - INFO - Epoch [ 49/100] - Batch [ 28800/ 29640] (97%) - Loss 0.2943\n",
      "2020-10-21 04:36:12,147 - INFO - Current lr: 0.01\n",
      "2020-10-21 04:36:12,149 - INFO - train, Loss: 0.4938 Acc: 0.8000\n",
      "2020-10-21 04:36:20,131 - INFO - Epoch [ 49/100] - Batch [     0/  1483] ( 0%) - Loss 0.7512\n",
      "2020-10-21 04:36:53,957 - INFO - Current lr: 0.01\n",
      "2020-10-21 04:36:53,958 - INFO - valid, Loss: 0.8257 Acc: 0.5563\n",
      "0.556889406889407\n",
      "new best model  with acc = 0.5563047875927175\n",
      "2020-10-21 04:37:04,694 - INFO - Epoch [ 50/100] - Batch [     0/ 29640] ( 0%) - Loss 0.3265\n",
      "2020-10-21 04:38:16,579 - INFO - Epoch [ 50/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.2561\n",
      "2020-10-21 04:39:26,164 - INFO - Epoch [ 50/100] - Batch [  3200/ 29640] (11%) - Loss 0.2927\n",
      "2020-10-21 04:40:35,382 - INFO - Epoch [ 50/100] - Batch [  4800/ 29640] (16%) - Loss 0.4766\n",
      "2020-10-21 04:41:45,050 - INFO - Epoch [ 50/100] - Batch [  6400/ 29640] (22%) - Loss 0.3633\n",
      "2020-10-21 04:42:54,275 - INFO - Epoch [ 50/100] - Batch [  8000/ 29640] (27%) - Loss 0.6516\n",
      "2020-10-21 04:44:03,056 - INFO - Epoch [ 50/100] - Batch [  9600/ 29640] (32%) - Loss 0.4677\n",
      "2020-10-21 04:45:11,816 - INFO - Epoch [ 50/100] - Batch [ 11200/ 29640] (38%) - Loss 0.7374\n",
      "2020-10-21 04:46:20,861 - INFO - Epoch [ 50/100] - Batch [ 12800/ 29640] (43%) - Loss 0.6215\n",
      "2020-10-21 04:47:30,170 - INFO - Epoch [ 50/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4500\n",
      "2020-10-21 04:48:38,875 - INFO - Epoch [ 50/100] - Batch [ 16000/ 29640] (54%) - Loss 0.6387\n",
      "2020-10-21 04:49:47,856 - INFO - Epoch [ 50/100] - Batch [ 17600/ 29640] (59%) - Loss 0.3543\n",
      "2020-10-21 04:50:57,028 - INFO - Epoch [ 50/100] - Batch [ 19200/ 29640] (65%) - Loss 0.2765\n",
      "2020-10-21 04:52:05,971 - INFO - Epoch [ 50/100] - Batch [ 20800/ 29640] (70%) - Loss 0.7359\n",
      "2020-10-21 04:53:15,100 - INFO - Epoch [ 50/100] - Batch [ 22400/ 29640] (76%) - Loss 0.6009\n",
      "2020-10-21 04:54:24,017 - INFO - Epoch [ 50/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4502\n",
      "2020-10-21 04:55:32,981 - INFO - Epoch [ 50/100] - Batch [ 25600/ 29640] (86%) - Loss 0.6618\n",
      "2020-10-21 04:56:41,584 - INFO - Epoch [ 50/100] - Batch [ 27200/ 29640] (92%) - Loss 0.6422\n",
      "2020-10-21 04:57:49,353 - INFO - Epoch [ 50/100] - Batch [ 28800/ 29640] (97%) - Loss 0.4583\n",
      "2020-10-21 04:58:24,680 - INFO - Current lr: 0.01\n",
      "2020-10-21 04:58:24,682 - INFO - train, Loss: 0.4941 Acc: 0.8000\n",
      "2020-10-21 04:58:36,517 - INFO - Epoch [ 50/100] - Batch [     0/  1483] ( 0%) - Loss 1.1510\n",
      "2020-10-21 04:59:08,038 - INFO - Current lr: 0.01\n",
      "2020-10-21 04:59:08,039 - INFO - valid, Loss: 0.9019 Acc: 0.4997\n",
      "0.4992319508448541\n",
      "2020-10-21 04:59:08,040 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 04:59:19,993 - INFO - Epoch [ 51/100] - Batch [     0/ 29640] ( 0%) - Loss 0.6602\n",
      "2020-10-21 05:00:31,863 - INFO - Epoch [ 51/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.7676\n",
      "2020-10-21 05:01:41,937 - INFO - Epoch [ 51/100] - Batch [  3200/ 29640] (11%) - Loss 0.6302\n",
      "2020-10-21 05:02:51,725 - INFO - Epoch [ 51/100] - Batch [  4800/ 29640] (16%) - Loss 0.4293\n",
      "2020-10-21 05:04:01,474 - INFO - Epoch [ 51/100] - Batch [  6400/ 29640] (22%) - Loss 0.3829\n",
      "2020-10-21 05:05:10,839 - INFO - Epoch [ 51/100] - Batch [  8000/ 29640] (27%) - Loss 0.4458\n",
      "2020-10-21 05:06:20,405 - INFO - Epoch [ 51/100] - Batch [  9600/ 29640] (32%) - Loss 0.6966\n",
      "2020-10-21 05:07:30,192 - INFO - Epoch [ 51/100] - Batch [ 11200/ 29640] (38%) - Loss 0.5198\n",
      "2020-10-21 05:08:39,869 - INFO - Epoch [ 51/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4904\n",
      "2020-10-21 05:09:49,703 - INFO - Epoch [ 51/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4557\n",
      "2020-10-21 05:10:59,324 - INFO - Epoch [ 51/100] - Batch [ 16000/ 29640] (54%) - Loss 0.5825\n",
      "2020-10-21 05:12:08,740 - INFO - Epoch [ 51/100] - Batch [ 17600/ 29640] (59%) - Loss 0.5230\n",
      "2020-10-21 05:13:18,319 - INFO - Epoch [ 51/100] - Batch [ 19200/ 29640] (65%) - Loss 0.4609\n",
      "2020-10-21 05:14:27,766 - INFO - Epoch [ 51/100] - Batch [ 20800/ 29640] (70%) - Loss 0.4492\n",
      "2020-10-21 05:15:37,088 - INFO - Epoch [ 51/100] - Batch [ 22400/ 29640] (76%) - Loss 0.3060\n",
      "2020-10-21 05:16:46,579 - INFO - Epoch [ 51/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4337\n",
      "2020-10-21 05:17:56,183 - INFO - Epoch [ 51/100] - Batch [ 25600/ 29640] (86%) - Loss 0.5057\n",
      "2020-10-21 05:19:04,736 - INFO - Epoch [ 51/100] - Batch [ 27200/ 29640] (92%) - Loss 0.5317\n",
      "2020-10-21 05:20:12,218 - INFO - Epoch [ 51/100] - Batch [ 28800/ 29640] (97%) - Loss 0.5109\n",
      "2020-10-21 05:20:47,538 - INFO - Current lr: 0.01\n",
      "2020-10-21 05:20:47,540 - INFO - train, Loss: 0.4936 Acc: 0.8000\n",
      "2020-10-21 05:20:55,517 - INFO - Epoch [ 51/100] - Batch [     0/  1483] ( 0%) - Loss 1.3908\n",
      "2020-10-21 05:21:31,068 - INFO - Current lr: 0.01\n",
      "2020-10-21 05:21:31,069 - INFO - valid, Loss: 0.8308 Acc: 0.5152\n",
      "0.5127506006538266\n",
      "2020-10-21 05:21:31,070 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 05:21:42,829 - INFO - Epoch [ 52/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4491\n",
      "2020-10-21 05:22:54,551 - INFO - Epoch [ 52/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.4207\n",
      "2020-10-21 05:24:04,003 - INFO - Epoch [ 52/100] - Batch [  3200/ 29640] (11%) - Loss 0.4659\n",
      "2020-10-21 05:25:13,367 - INFO - Epoch [ 52/100] - Batch [  4800/ 29640] (16%) - Loss 0.5234\n",
      "2020-10-21 05:26:22,871 - INFO - Epoch [ 52/100] - Batch [  6400/ 29640] (22%) - Loss 0.7067\n",
      "2020-10-21 05:27:32,259 - INFO - Epoch [ 52/100] - Batch [  8000/ 29640] (27%) - Loss 0.7089\n",
      "2020-10-21 05:28:42,027 - INFO - Epoch [ 52/100] - Batch [  9600/ 29640] (32%) - Loss 0.4020\n",
      "2020-10-21 05:29:51,340 - INFO - Epoch [ 52/100] - Batch [ 11200/ 29640] (38%) - Loss 0.5619\n",
      "2020-10-21 05:31:01,035 - INFO - Epoch [ 52/100] - Batch [ 12800/ 29640] (43%) - Loss 0.5083\n",
      "2020-10-21 05:32:10,710 - INFO - Epoch [ 52/100] - Batch [ 14400/ 29640] (49%) - Loss 0.6383\n",
      "2020-10-21 05:33:19,896 - INFO - Epoch [ 52/100] - Batch [ 16000/ 29640] (54%) - Loss 0.5981\n",
      "2020-10-21 05:34:29,126 - INFO - Epoch [ 52/100] - Batch [ 17600/ 29640] (59%) - Loss 0.5291\n",
      "2020-10-21 05:35:38,455 - INFO - Epoch [ 52/100] - Batch [ 19200/ 29640] (65%) - Loss 0.6164\n",
      "2020-10-21 05:36:48,317 - INFO - Epoch [ 52/100] - Batch [ 20800/ 29640] (70%) - Loss 0.3086\n",
      "2020-10-21 05:37:57,802 - INFO - Epoch [ 52/100] - Batch [ 22400/ 29640] (76%) - Loss 0.3733\n",
      "2020-10-21 05:39:07,020 - INFO - Epoch [ 52/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4607\n",
      "2020-10-21 05:40:16,342 - INFO - Epoch [ 52/100] - Batch [ 25600/ 29640] (86%) - Loss 0.5377\n",
      "2020-10-21 05:41:25,199 - INFO - Epoch [ 52/100] - Batch [ 27200/ 29640] (92%) - Loss 0.6142\n",
      "2020-10-21 05:42:32,851 - INFO - Epoch [ 52/100] - Batch [ 28800/ 29640] (97%) - Loss 0.4614\n",
      "2020-10-21 05:43:07,888 - INFO - Current lr: 0.01\n",
      "2020-10-21 05:43:07,890 - INFO - train, Loss: 0.4947 Acc: 0.8000\n",
      "2020-10-21 05:43:19,433 - INFO - Epoch [ 52/100] - Batch [     0/  1483] ( 0%) - Loss 0.7095\n",
      "2020-10-21 05:43:50,605 - INFO - Current lr: 0.01\n",
      "2020-10-21 05:43:50,606 - INFO - valid, Loss: 0.8481 Acc: 0.5037\n",
      "0.5036073096556967\n",
      "2020-10-21 05:43:50,607 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 05:44:00,928 - INFO - Epoch [ 53/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4821\n",
      "2020-10-21 05:45:12,904 - INFO - Epoch [ 53/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.4220\n",
      "2020-10-21 05:46:22,974 - INFO - Epoch [ 53/100] - Batch [  3200/ 29640] (11%) - Loss 0.3245\n",
      "2020-10-21 05:47:33,045 - INFO - Epoch [ 53/100] - Batch [  4800/ 29640] (16%) - Loss 0.5618\n",
      "2020-10-21 05:48:43,335 - INFO - Epoch [ 53/100] - Batch [  6400/ 29640] (22%) - Loss 0.3716\n",
      "2020-10-21 05:49:53,309 - INFO - Epoch [ 53/100] - Batch [  8000/ 29640] (27%) - Loss 0.6198\n",
      "2020-10-21 05:51:03,392 - INFO - Epoch [ 53/100] - Batch [  9600/ 29640] (32%) - Loss 0.4516\n",
      "2020-10-21 05:52:13,125 - INFO - Epoch [ 53/100] - Batch [ 11200/ 29640] (38%) - Loss 0.6186\n",
      "2020-10-21 05:53:22,149 - INFO - Epoch [ 53/100] - Batch [ 12800/ 29640] (43%) - Loss 0.6057\n",
      "2020-10-21 05:54:31,440 - INFO - Epoch [ 53/100] - Batch [ 14400/ 29640] (49%) - Loss 0.5598\n",
      "2020-10-21 05:55:40,444 - INFO - Epoch [ 53/100] - Batch [ 16000/ 29640] (54%) - Loss 0.4864\n",
      "2020-10-21 05:56:50,206 - INFO - Epoch [ 53/100] - Batch [ 17600/ 29640] (59%) - Loss 0.4515\n",
      "2020-10-21 05:57:58,967 - INFO - Epoch [ 53/100] - Batch [ 19200/ 29640] (65%) - Loss 0.5598\n",
      "2020-10-21 05:59:07,999 - INFO - Epoch [ 53/100] - Batch [ 20800/ 29640] (70%) - Loss 0.4647\n",
      "2020-10-21 06:00:17,500 - INFO - Epoch [ 53/100] - Batch [ 22400/ 29640] (76%) - Loss 0.7250\n",
      "2020-10-21 06:01:26,793 - INFO - Epoch [ 53/100] - Batch [ 24000/ 29640] (81%) - Loss 0.7827\n",
      "2020-10-21 06:02:35,673 - INFO - Epoch [ 53/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4457\n",
      "2020-10-21 06:03:43,708 - INFO - Epoch [ 53/100] - Batch [ 27200/ 29640] (92%) - Loss 0.4326\n",
      "2020-10-21 06:04:51,386 - INFO - Epoch [ 53/100] - Batch [ 28800/ 29640] (97%) - Loss 0.5405\n",
      "2020-10-21 06:05:26,548 - INFO - Current lr: 0.01\n",
      "2020-10-21 06:05:26,549 - INFO - train, Loss: 0.4948 Acc: 0.8000\n",
      "2020-10-21 06:05:34,617 - INFO - Epoch [ 53/100] - Batch [     0/  1483] ( 0%) - Loss 0.9931\n",
      "2020-10-21 06:06:09,631 - INFO - Current lr: 0.01\n",
      "2020-10-21 06:06:09,632 - INFO - valid, Loss: 0.9139 Acc: 0.5003\n",
      "0.5\n",
      "2020-10-21 06:06:09,633 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 06:06:20,063 - INFO - Epoch [ 54/100] - Batch [     0/ 29640] ( 0%) - Loss 0.3981\n",
      "2020-10-21 06:07:34,643 - INFO - Epoch [ 54/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.2907\n",
      "2020-10-21 06:08:44,542 - INFO - Epoch [ 54/100] - Batch [  3200/ 29640] (11%) - Loss 0.6654\n",
      "2020-10-21 06:09:54,525 - INFO - Epoch [ 54/100] - Batch [  4800/ 29640] (16%) - Loss 0.5254\n",
      "2020-10-21 06:11:04,294 - INFO - Epoch [ 54/100] - Batch [  6400/ 29640] (22%) - Loss 0.5839\n",
      "2020-10-21 06:12:13,807 - INFO - Epoch [ 54/100] - Batch [  8000/ 29640] (27%) - Loss 0.3068\n",
      "2020-10-21 06:13:23,194 - INFO - Epoch [ 54/100] - Batch [  9600/ 29640] (32%) - Loss 0.2844\n",
      "2020-10-21 06:14:32,218 - INFO - Epoch [ 54/100] - Batch [ 11200/ 29640] (38%) - Loss 0.4172\n",
      "2020-10-21 06:15:41,683 - INFO - Epoch [ 54/100] - Batch [ 12800/ 29640] (43%) - Loss 0.7749\n",
      "2020-10-21 06:16:50,973 - INFO - Epoch [ 54/100] - Batch [ 14400/ 29640] (49%) - Loss 0.5316\n",
      "2020-10-21 06:18:00,530 - INFO - Epoch [ 54/100] - Batch [ 16000/ 29640] (54%) - Loss 0.4878\n",
      "2020-10-21 06:19:10,044 - INFO - Epoch [ 54/100] - Batch [ 17600/ 29640] (59%) - Loss 0.3223\n",
      "2020-10-21 06:20:19,235 - INFO - Epoch [ 54/100] - Batch [ 19200/ 29640] (65%) - Loss 0.5903\n",
      "2020-10-21 06:21:28,582 - INFO - Epoch [ 54/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5508\n",
      "2020-10-21 06:22:37,574 - INFO - Epoch [ 54/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5862\n",
      "2020-10-21 06:23:46,815 - INFO - Epoch [ 54/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4835\n",
      "2020-10-21 06:24:55,996 - INFO - Epoch [ 54/100] - Batch [ 25600/ 29640] (86%) - Loss 0.6374\n",
      "2020-10-21 06:26:04,842 - INFO - Epoch [ 54/100] - Batch [ 27200/ 29640] (92%) - Loss 0.5634\n",
      "2020-10-21 06:27:12,631 - INFO - Epoch [ 54/100] - Batch [ 28800/ 29640] (97%) - Loss 0.4572\n",
      "2020-10-21 06:27:48,092 - INFO - Current lr: 0.01\n",
      "2020-10-21 06:27:48,093 - INFO - train, Loss: 0.4950 Acc: 0.8000\n",
      "2020-10-21 06:27:57,466 - INFO - Epoch [ 54/100] - Batch [     0/  1483] ( 0%) - Loss 0.9013\n",
      "2020-10-21 06:28:30,626 - INFO - Current lr: 0.01\n",
      "2020-10-21 06:28:30,627 - INFO - valid, Loss: 1.0255 Acc: 0.5003\n",
      "0.5\n",
      "2020-10-21 06:28:30,628 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 06:28:42,893 - INFO - Epoch [ 55/100] - Batch [     0/ 29640] ( 0%) - Loss 0.5531\n",
      "2020-10-21 06:29:54,621 - INFO - Epoch [ 55/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.4413\n",
      "2020-10-21 06:31:04,833 - INFO - Epoch [ 55/100] - Batch [  3200/ 29640] (11%) - Loss 0.3538\n",
      "2020-10-21 06:32:14,630 - INFO - Epoch [ 55/100] - Batch [  4800/ 29640] (16%) - Loss 0.4515\n",
      "2020-10-21 06:33:24,126 - INFO - Epoch [ 55/100] - Batch [  6400/ 29640] (22%) - Loss 0.2777\n",
      "2020-10-21 06:34:33,675 - INFO - Epoch [ 55/100] - Batch [  8000/ 29640] (27%) - Loss 0.4553\n",
      "2020-10-21 06:35:43,404 - INFO - Epoch [ 55/100] - Batch [  9600/ 29640] (32%) - Loss 0.2502\n",
      "2020-10-21 06:36:53,421 - INFO - Epoch [ 55/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3516\n",
      "2020-10-21 06:38:02,815 - INFO - Epoch [ 55/100] - Batch [ 12800/ 29640] (43%) - Loss 0.2896\n",
      "2020-10-21 06:39:12,146 - INFO - Epoch [ 55/100] - Batch [ 14400/ 29640] (49%) - Loss 0.6307\n",
      "2020-10-21 06:40:21,844 - INFO - Epoch [ 55/100] - Batch [ 16000/ 29640] (54%) - Loss 0.3107\n",
      "2020-10-21 06:41:31,696 - INFO - Epoch [ 55/100] - Batch [ 17600/ 29640] (59%) - Loss 0.6018\n",
      "2020-10-21 06:42:41,478 - INFO - Epoch [ 55/100] - Batch [ 19200/ 29640] (65%) - Loss 0.4713\n",
      "2020-10-21 06:43:50,975 - INFO - Epoch [ 55/100] - Batch [ 20800/ 29640] (70%) - Loss 0.7543\n",
      "2020-10-21 06:45:00,512 - INFO - Epoch [ 55/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5734\n",
      "2020-10-21 06:46:10,120 - INFO - Epoch [ 55/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4613\n",
      "2020-10-21 06:47:20,027 - INFO - Epoch [ 55/100] - Batch [ 25600/ 29640] (86%) - Loss 0.5249\n",
      "2020-10-21 06:48:28,924 - INFO - Epoch [ 55/100] - Batch [ 27200/ 29640] (92%) - Loss 0.4324\n",
      "2020-10-21 06:49:36,723 - INFO - Epoch [ 55/100] - Batch [ 28800/ 29640] (97%) - Loss 0.5915\n",
      "2020-10-21 06:50:12,205 - INFO - Current lr: 0.01\n",
      "2020-10-21 06:50:12,206 - INFO - train, Loss: 0.4942 Acc: 0.8000\n",
      "2020-10-21 06:50:20,484 - INFO - Epoch [ 55/100] - Batch [     0/  1483] ( 0%) - Loss 1.0723\n",
      "2020-10-21 06:50:54,936 - INFO - Current lr: 0.01\n",
      "2020-10-21 06:50:54,938 - INFO - valid, Loss: 0.8485 Acc: 0.5024\n",
      "0.5018070489844684\n",
      "2020-10-21 06:50:54,939 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 06:51:04,018 - INFO - Epoch [ 56/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4502\n",
      "2020-10-21 06:52:17,731 - INFO - Epoch [ 56/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.4366\n",
      "2020-10-21 06:53:27,217 - INFO - Epoch [ 56/100] - Batch [  3200/ 29640] (11%) - Loss 0.1967\n",
      "2020-10-21 06:54:36,880 - INFO - Epoch [ 56/100] - Batch [  4800/ 29640] (16%) - Loss 0.4833\n",
      "2020-10-21 06:55:46,821 - INFO - Epoch [ 56/100] - Batch [  6400/ 29640] (22%) - Loss 0.3977\n",
      "2020-10-21 06:56:56,711 - INFO - Epoch [ 56/100] - Batch [  8000/ 29640] (27%) - Loss 0.2928\n",
      "2020-10-21 06:58:06,157 - INFO - Epoch [ 56/100] - Batch [  9600/ 29640] (32%) - Loss 0.6889\n",
      "2020-10-21 06:59:15,313 - INFO - Epoch [ 56/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3823\n",
      "2020-10-21 07:00:24,738 - INFO - Epoch [ 56/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4331\n",
      "2020-10-21 07:01:34,333 - INFO - Epoch [ 56/100] - Batch [ 14400/ 29640] (49%) - Loss 0.3924\n",
      "2020-10-21 07:02:44,012 - INFO - Epoch [ 56/100] - Batch [ 16000/ 29640] (54%) - Loss 0.4475\n",
      "2020-10-21 07:03:53,222 - INFO - Epoch [ 56/100] - Batch [ 17600/ 29640] (59%) - Loss 0.8454\n",
      "2020-10-21 07:05:02,642 - INFO - Epoch [ 56/100] - Batch [ 19200/ 29640] (65%) - Loss 0.4599\n",
      "2020-10-21 07:06:12,352 - INFO - Epoch [ 56/100] - Batch [ 20800/ 29640] (70%) - Loss 0.2255\n",
      "2020-10-21 07:07:22,330 - INFO - Epoch [ 56/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4023\n",
      "2020-10-21 07:08:31,489 - INFO - Epoch [ 56/100] - Batch [ 24000/ 29640] (81%) - Loss 0.8724\n",
      "2020-10-21 07:09:40,578 - INFO - Epoch [ 56/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4755\n",
      "2020-10-21 07:10:48,703 - INFO - Epoch [ 56/100] - Batch [ 27200/ 29640] (92%) - Loss 0.4079\n",
      "2020-10-21 07:11:56,248 - INFO - Epoch [ 56/100] - Batch [ 28800/ 29640] (97%) - Loss 0.4736\n",
      "2020-10-21 07:12:31,622 - INFO - Current lr: 0.01\n",
      "2020-10-21 07:12:31,624 - INFO - train, Loss: 0.4938 Acc: 0.8000\n",
      "2020-10-21 07:12:39,107 - INFO - Epoch [ 56/100] - Batch [     0/  1483] ( 0%) - Loss 0.4111\n",
      "2020-10-21 07:13:14,481 - INFO - Current lr: 0.01\n",
      "2020-10-21 07:13:14,482 - INFO - valid, Loss: 1.1009 Acc: 0.5003\n",
      "0.5\n",
      "2020-10-21 07:13:14,482 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 07:13:27,970 - INFO - Epoch [ 57/100] - Batch [     0/ 29640] ( 0%) - Loss 0.3731\n",
      "2020-10-21 07:14:38,850 - INFO - Epoch [ 57/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.3604\n",
      "2020-10-21 07:15:48,282 - INFO - Epoch [ 57/100] - Batch [  3200/ 29640] (11%) - Loss 0.4594\n",
      "2020-10-21 07:16:57,964 - INFO - Epoch [ 57/100] - Batch [  4800/ 29640] (16%) - Loss 0.3773\n",
      "2020-10-21 07:18:07,636 - INFO - Epoch [ 57/100] - Batch [  6400/ 29640] (22%) - Loss 0.5183\n",
      "2020-10-21 07:19:16,638 - INFO - Epoch [ 57/100] - Batch [  8000/ 29640] (27%) - Loss 0.3116\n",
      "2020-10-21 07:20:26,050 - INFO - Epoch [ 57/100] - Batch [  9600/ 29640] (32%) - Loss 0.3898\n",
      "2020-10-21 07:21:35,419 - INFO - Epoch [ 57/100] - Batch [ 11200/ 29640] (38%) - Loss 0.4608\n",
      "2020-10-21 07:22:44,735 - INFO - Epoch [ 57/100] - Batch [ 12800/ 29640] (43%) - Loss 0.3937\n",
      "2020-10-21 07:23:53,792 - INFO - Epoch [ 57/100] - Batch [ 14400/ 29640] (49%) - Loss 0.3778\n",
      "2020-10-21 07:25:03,212 - INFO - Epoch [ 57/100] - Batch [ 16000/ 29640] (54%) - Loss 0.2125\n",
      "2020-10-21 07:26:12,869 - INFO - Epoch [ 57/100] - Batch [ 17600/ 29640] (59%) - Loss 0.5580\n",
      "2020-10-21 07:27:23,005 - INFO - Epoch [ 57/100] - Batch [ 19200/ 29640] (65%) - Loss 0.4821\n",
      "2020-10-21 07:28:32,621 - INFO - Epoch [ 57/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5175\n",
      "2020-10-21 07:29:41,712 - INFO - Epoch [ 57/100] - Batch [ 22400/ 29640] (76%) - Loss 0.2994\n",
      "2020-10-21 07:30:50,923 - INFO - Epoch [ 57/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4522\n",
      "2020-10-21 07:32:00,583 - INFO - Epoch [ 57/100] - Batch [ 25600/ 29640] (86%) - Loss 0.6906\n",
      "2020-10-21 07:33:09,130 - INFO - Epoch [ 57/100] - Batch [ 27200/ 29640] (92%) - Loss 0.4054\n",
      "2020-10-21 07:34:16,715 - INFO - Epoch [ 57/100] - Batch [ 28800/ 29640] (97%) - Loss 0.6310\n",
      "2020-10-21 07:34:52,144 - INFO - Current lr: 0.01\n",
      "2020-10-21 07:34:52,146 - INFO - train, Loss: 0.4937 Acc: 0.8000\n",
      "2020-10-21 07:34:59,816 - INFO - Epoch [ 57/100] - Batch [     0/  1483] ( 0%) - Loss 0.5956\n",
      "2020-10-21 07:35:35,315 - INFO - Current lr: 0.01\n",
      "2020-10-21 07:35:35,316 - INFO - valid, Loss: 0.7688 Acc: 0.5206\n",
      "0.5255247739118706\n",
      "2020-10-21 07:35:46,242 - INFO - Epoch [ 58/100] - Batch [     0/ 29640] ( 0%) - Loss 0.6913\n",
      "2020-10-21 07:36:58,718 - INFO - Epoch [ 58/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.3946\n",
      "2020-10-21 07:38:08,389 - INFO - Epoch [ 58/100] - Batch [  3200/ 29640] (11%) - Loss 0.4903\n",
      "2020-10-21 07:39:18,017 - INFO - Epoch [ 58/100] - Batch [  4800/ 29640] (16%) - Loss 0.6022\n",
      "2020-10-21 07:40:27,396 - INFO - Epoch [ 58/100] - Batch [  6400/ 29640] (22%) - Loss 0.2658\n",
      "2020-10-21 07:41:36,885 - INFO - Epoch [ 58/100] - Batch [  8000/ 29640] (27%) - Loss 0.4543\n",
      "2020-10-21 07:42:45,782 - INFO - Epoch [ 58/100] - Batch [  9600/ 29640] (32%) - Loss 0.2239\n",
      "2020-10-21 07:43:54,564 - INFO - Epoch [ 58/100] - Batch [ 11200/ 29640] (38%) - Loss 0.5787\n",
      "2020-10-21 07:45:03,414 - INFO - Epoch [ 58/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4067\n",
      "2020-10-21 07:46:12,695 - INFO - Epoch [ 58/100] - Batch [ 14400/ 29640] (49%) - Loss 0.5039\n",
      "2020-10-21 07:47:22,129 - INFO - Epoch [ 58/100] - Batch [ 16000/ 29640] (54%) - Loss 0.2703\n",
      "2020-10-21 07:48:30,903 - INFO - Epoch [ 58/100] - Batch [ 17600/ 29640] (59%) - Loss 0.6746\n",
      "2020-10-21 07:49:39,711 - INFO - Epoch [ 58/100] - Batch [ 19200/ 29640] (65%) - Loss 0.3280\n",
      "2020-10-21 07:50:48,892 - INFO - Epoch [ 58/100] - Batch [ 20800/ 29640] (70%) - Loss 0.6103\n",
      "2020-10-21 07:51:58,489 - INFO - Epoch [ 58/100] - Batch [ 22400/ 29640] (76%) - Loss 0.6587\n",
      "2020-10-21 07:53:07,861 - INFO - Epoch [ 58/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4126\n",
      "2020-10-21 07:54:17,436 - INFO - Epoch [ 58/100] - Batch [ 25600/ 29640] (86%) - Loss 0.5517\n",
      "2020-10-21 07:55:25,832 - INFO - Epoch [ 58/100] - Batch [ 27200/ 29640] (92%) - Loss 0.4823\n",
      "2020-10-21 07:56:33,569 - INFO - Epoch [ 58/100] - Batch [ 28800/ 29640] (97%) - Loss 0.4725\n",
      "2020-10-21 07:57:08,862 - INFO - Current lr: 0.01\n",
      "2020-10-21 07:57:08,863 - INFO - train, Loss: 0.4931 Acc: 0.8000\n",
      "2020-10-21 07:57:17,281 - INFO - Epoch [ 58/100] - Batch [     0/  1483] ( 0%) - Loss 0.9421\n",
      "2020-10-21 07:57:52,124 - INFO - Current lr: 0.01\n",
      "2020-10-21 07:57:52,126 - INFO - valid, Loss: 0.8529 Acc: 0.5003\n",
      "0.5\n",
      "2020-10-21 07:57:52,127 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 07:58:02,008 - INFO - Epoch [ 59/100] - Batch [     0/ 29640] ( 0%) - Loss 0.5652\n",
      "2020-10-21 07:59:14,663 - INFO - Epoch [ 59/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.6224\n",
      "2020-10-21 08:00:24,169 - INFO - Epoch [ 59/100] - Batch [  3200/ 29640] (11%) - Loss 0.3754\n",
      "2020-10-21 08:01:33,788 - INFO - Epoch [ 59/100] - Batch [  4800/ 29640] (16%) - Loss 0.5347\n",
      "2020-10-21 08:02:43,450 - INFO - Epoch [ 59/100] - Batch [  6400/ 29640] (22%) - Loss 0.4039\n",
      "2020-10-21 08:03:52,616 - INFO - Epoch [ 59/100] - Batch [  8000/ 29640] (27%) - Loss 0.6850\n",
      "2020-10-21 08:05:02,361 - INFO - Epoch [ 59/100] - Batch [  9600/ 29640] (32%) - Loss 0.4762\n",
      "2020-10-21 08:06:11,958 - INFO - Epoch [ 59/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3269\n",
      "2020-10-21 08:07:21,222 - INFO - Epoch [ 59/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4881\n",
      "2020-10-21 08:08:30,130 - INFO - Epoch [ 59/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4125\n",
      "2020-10-21 08:09:39,124 - INFO - Epoch [ 59/100] - Batch [ 16000/ 29640] (54%) - Loss 0.4244\n",
      "2020-10-21 08:10:48,292 - INFO - Epoch [ 59/100] - Batch [ 17600/ 29640] (59%) - Loss 0.2326\n",
      "2020-10-21 08:11:57,154 - INFO - Epoch [ 59/100] - Batch [ 19200/ 29640] (65%) - Loss 0.6068\n",
      "2020-10-21 08:13:06,515 - INFO - Epoch [ 59/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5506\n",
      "2020-10-21 08:14:15,295 - INFO - Epoch [ 59/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4350\n",
      "2020-10-21 08:15:24,775 - INFO - Epoch [ 59/100] - Batch [ 24000/ 29640] (81%) - Loss 0.6088\n",
      "2020-10-21 08:16:34,037 - INFO - Epoch [ 59/100] - Batch [ 25600/ 29640] (86%) - Loss 0.6456\n",
      "2020-10-21 08:17:42,108 - INFO - Epoch [ 59/100] - Batch [ 27200/ 29640] (92%) - Loss 0.7277\n",
      "2020-10-21 08:18:49,643 - INFO - Epoch [ 59/100] - Batch [ 28800/ 29640] (97%) - Loss 0.5978\n",
      "2020-10-21 08:19:25,036 - INFO - Current lr: 0.01\n",
      "2020-10-21 08:19:25,037 - INFO - train, Loss: 0.4930 Acc: 0.8000\n",
      "2020-10-21 08:19:32,919 - INFO - Epoch [ 59/100] - Batch [     0/  1483] ( 0%) - Loss 0.7692\n",
      "2020-10-21 08:20:09,308 - INFO - Current lr: 0.01\n",
      "2020-10-21 08:20:09,309 - INFO - valid, Loss: 0.8816 Acc: 0.5307\n",
      "0.5291058851542723\n",
      "2020-10-21 08:20:20,784 - INFO - Epoch [ 60/100] - Batch [     0/ 29640] ( 0%) - Loss 0.5635\n",
      "2020-10-21 08:21:32,364 - INFO - Epoch [ 60/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.5347\n",
      "2020-10-21 08:22:41,674 - INFO - Epoch [ 60/100] - Batch [  3200/ 29640] (11%) - Loss 0.4885\n",
      "2020-10-21 08:23:51,134 - INFO - Epoch [ 60/100] - Batch [  4800/ 29640] (16%) - Loss 0.7498\n",
      "2020-10-21 08:25:00,358 - INFO - Epoch [ 60/100] - Batch [  6400/ 29640] (22%) - Loss 0.7418\n",
      "2020-10-21 08:26:09,754 - INFO - Epoch [ 60/100] - Batch [  8000/ 29640] (27%) - Loss 0.3592\n",
      "2020-10-21 08:27:19,090 - INFO - Epoch [ 60/100] - Batch [  9600/ 29640] (32%) - Loss 0.5886\n",
      "2020-10-21 08:28:28,635 - INFO - Epoch [ 60/100] - Batch [ 11200/ 29640] (38%) - Loss 0.8687\n",
      "2020-10-21 08:29:38,243 - INFO - Epoch [ 60/100] - Batch [ 12800/ 29640] (43%) - Loss 0.6180\n",
      "2020-10-21 08:30:47,971 - INFO - Epoch [ 60/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4109\n",
      "2020-10-21 08:31:57,621 - INFO - Epoch [ 60/100] - Batch [ 16000/ 29640] (54%) - Loss 0.5373\n",
      "2020-10-21 08:33:06,793 - INFO - Epoch [ 60/100] - Batch [ 17600/ 29640] (59%) - Loss 0.4648\n",
      "2020-10-21 08:34:16,218 - INFO - Epoch [ 60/100] - Batch [ 19200/ 29640] (65%) - Loss 0.5337\n",
      "2020-10-21 08:35:25,962 - INFO - Epoch [ 60/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5982\n",
      "2020-10-21 08:36:35,883 - INFO - Epoch [ 60/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5735\n",
      "2020-10-21 08:37:45,315 - INFO - Epoch [ 60/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4639\n",
      "2020-10-21 08:38:54,746 - INFO - Epoch [ 60/100] - Batch [ 25600/ 29640] (86%) - Loss 0.5341\n",
      "2020-10-21 08:40:03,363 - INFO - Epoch [ 60/100] - Batch [ 27200/ 29640] (92%) - Loss 0.2690\n",
      "2020-10-21 08:41:11,004 - INFO - Epoch [ 60/100] - Batch [ 28800/ 29640] (97%) - Loss 0.6077\n",
      "2020-10-21 08:41:46,581 - INFO - Current lr: 0.01\n",
      "2020-10-21 08:41:46,583 - INFO - train, Loss: 0.4931 Acc: 0.8000\n",
      "2020-10-21 08:41:55,021 - INFO - Epoch [ 60/100] - Batch [     0/  1483] ( 0%) - Loss 1.5849\n",
      "2020-10-21 08:42:28,719 - INFO - Current lr: 0.01\n",
      "2020-10-21 08:42:28,721 - INFO - valid, Loss: 0.9389 Acc: 0.5003\n",
      "0.5004630972372908\n",
      "2020-10-21 08:42:28,722 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 08:42:38,818 - INFO - Epoch [ 61/100] - Batch [     0/ 29640] ( 0%) - Loss 0.5298\n",
      "2020-10-21 08:43:52,373 - INFO - Epoch [ 61/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.6801\n",
      "2020-10-21 08:45:01,842 - INFO - Epoch [ 61/100] - Batch [  3200/ 29640] (11%) - Loss 0.3916\n",
      "2020-10-21 08:46:11,513 - INFO - Epoch [ 61/100] - Batch [  4800/ 29640] (16%) - Loss 0.3496\n",
      "2020-10-21 08:47:20,818 - INFO - Epoch [ 61/100] - Batch [  6400/ 29640] (22%) - Loss 0.5295\n",
      "2020-10-21 08:48:29,701 - INFO - Epoch [ 61/100] - Batch [  8000/ 29640] (27%) - Loss 0.6418\n",
      "2020-10-21 08:49:38,925 - INFO - Epoch [ 61/100] - Batch [  9600/ 29640] (32%) - Loss 0.4630\n",
      "2020-10-21 08:50:47,801 - INFO - Epoch [ 61/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3745\n",
      "2020-10-21 08:51:57,124 - INFO - Epoch [ 61/100] - Batch [ 12800/ 29640] (43%) - Loss 0.5685\n",
      "2020-10-21 08:53:05,955 - INFO - Epoch [ 61/100] - Batch [ 14400/ 29640] (49%) - Loss 0.6254\n",
      "2020-10-21 08:54:14,900 - INFO - Epoch [ 61/100] - Batch [ 16000/ 29640] (54%) - Loss 0.5133\n",
      "2020-10-21 08:55:24,143 - INFO - Epoch [ 61/100] - Batch [ 17600/ 29640] (59%) - Loss 0.4429\n",
      "2020-10-21 08:56:33,681 - INFO - Epoch [ 61/100] - Batch [ 19200/ 29640] (65%) - Loss 0.1917\n",
      "2020-10-21 08:57:42,869 - INFO - Epoch [ 61/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5270\n",
      "2020-10-21 08:58:52,356 - INFO - Epoch [ 61/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5989\n",
      "2020-10-21 09:00:01,572 - INFO - Epoch [ 61/100] - Batch [ 24000/ 29640] (81%) - Loss 0.5112\n",
      "2020-10-21 09:01:10,657 - INFO - Epoch [ 61/100] - Batch [ 25600/ 29640] (86%) - Loss 0.6569\n",
      "2020-10-21 09:02:18,706 - INFO - Epoch [ 61/100] - Batch [ 27200/ 29640] (92%) - Loss 0.6080\n",
      "2020-10-21 09:03:25,332 - INFO - Epoch [ 61/100] - Batch [ 28800/ 29640] (97%) - Loss 0.3577\n",
      "2020-10-21 09:04:00,246 - INFO - Current lr: 0.01\n",
      "2020-10-21 09:04:00,247 - INFO - train, Loss: 0.4921 Acc: 0.8000\n",
      "2020-10-21 09:04:08,749 - INFO - Epoch [ 61/100] - Batch [     0/  1483] ( 0%) - Loss 1.3702\n",
      "2020-10-21 09:04:42,839 - INFO - Current lr: 0.01\n",
      "2020-10-21 09:04:42,840 - INFO - valid, Loss: 0.9414 Acc: 0.5064\n",
      "0.5051383055415313\n",
      "2020-10-21 09:04:42,841 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 09:04:54,329 - INFO - Epoch [ 62/100] - Batch [     0/ 29640] ( 0%) - Loss 0.5516\n",
      "2020-10-21 09:06:06,520 - INFO - Epoch [ 62/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.3784\n",
      "2020-10-21 09:07:16,609 - INFO - Epoch [ 62/100] - Batch [  3200/ 29640] (11%) - Loss 0.9976\n",
      "2020-10-21 09:08:26,251 - INFO - Epoch [ 62/100] - Batch [  4800/ 29640] (16%) - Loss 0.4264\n",
      "2020-10-21 09:09:35,946 - INFO - Epoch [ 62/100] - Batch [  6400/ 29640] (22%) - Loss 0.4586\n",
      "2020-10-21 09:10:45,929 - INFO - Epoch [ 62/100] - Batch [  8000/ 29640] (27%) - Loss 0.3632\n",
      "2020-10-21 09:11:55,967 - INFO - Epoch [ 62/100] - Batch [  9600/ 29640] (32%) - Loss 0.4399\n",
      "2020-10-21 09:13:06,148 - INFO - Epoch [ 62/100] - Batch [ 11200/ 29640] (38%) - Loss 0.4721\n",
      "2020-10-21 09:14:15,889 - INFO - Epoch [ 62/100] - Batch [ 12800/ 29640] (43%) - Loss 0.3735\n",
      "2020-10-21 09:15:25,331 - INFO - Epoch [ 62/100] - Batch [ 14400/ 29640] (49%) - Loss 0.2708\n",
      "2020-10-21 09:16:35,014 - INFO - Epoch [ 62/100] - Batch [ 16000/ 29640] (54%) - Loss 0.4570\n",
      "2020-10-21 09:17:44,935 - INFO - Epoch [ 62/100] - Batch [ 17600/ 29640] (59%) - Loss 0.6513\n",
      "2020-10-21 09:18:54,671 - INFO - Epoch [ 62/100] - Batch [ 19200/ 29640] (65%) - Loss 0.3033\n",
      "2020-10-21 09:20:04,052 - INFO - Epoch [ 62/100] - Batch [ 20800/ 29640] (70%) - Loss 0.4862\n",
      "2020-10-21 09:21:13,666 - INFO - Epoch [ 62/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5305\n",
      "2020-10-21 09:22:22,946 - INFO - Epoch [ 62/100] - Batch [ 24000/ 29640] (81%) - Loss 0.6556\n",
      "2020-10-21 09:23:32,420 - INFO - Epoch [ 62/100] - Batch [ 25600/ 29640] (86%) - Loss 0.7592\n",
      "2020-10-21 09:24:41,200 - INFO - Epoch [ 62/100] - Batch [ 27200/ 29640] (92%) - Loss 0.6827\n",
      "2020-10-21 09:25:49,152 - INFO - Epoch [ 62/100] - Batch [ 28800/ 29640] (97%) - Loss 0.3297\n",
      "2020-10-21 09:26:24,644 - INFO - Current lr: 0.01\n",
      "2020-10-21 09:26:24,645 - INFO - train, Loss: 0.4914 Acc: 0.7999\n",
      "2020-10-21 09:26:32,807 - INFO - Epoch [ 62/100] - Batch [     0/  1483] ( 0%) - Loss 0.6852\n",
      "2020-10-21 09:27:07,198 - INFO - Current lr: 0.01\n",
      "2020-10-21 09:27:07,199 - INFO - valid, Loss: 0.7994 Acc: 0.5253\n",
      "0.5250301818850207\n",
      "2020-10-21 09:27:20,251 - INFO - Epoch [ 63/100] - Batch [     0/ 29640] ( 0%) - Loss 0.2822\n",
      "2020-10-21 09:28:31,957 - INFO - Epoch [ 63/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.3612\n",
      "2020-10-21 09:29:41,628 - INFO - Epoch [ 63/100] - Batch [  3200/ 29640] (11%) - Loss 0.7360\n",
      "2020-10-21 09:30:51,719 - INFO - Epoch [ 63/100] - Batch [  4800/ 29640] (16%) - Loss 0.3892\n",
      "2020-10-21 09:32:01,641 - INFO - Epoch [ 63/100] - Batch [  6400/ 29640] (22%) - Loss 0.5271\n",
      "2020-10-21 09:33:11,200 - INFO - Epoch [ 63/100] - Batch [  8000/ 29640] (27%) - Loss 0.3267\n",
      "2020-10-21 09:34:20,902 - INFO - Epoch [ 63/100] - Batch [  9600/ 29640] (32%) - Loss 0.3128\n",
      "2020-10-21 09:35:30,638 - INFO - Epoch [ 63/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3284\n",
      "2020-10-21 09:36:40,581 - INFO - Epoch [ 63/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4826\n",
      "2020-10-21 09:37:49,835 - INFO - Epoch [ 63/100] - Batch [ 14400/ 29640] (49%) - Loss 0.6052\n",
      "2020-10-21 09:38:59,250 - INFO - Epoch [ 63/100] - Batch [ 16000/ 29640] (54%) - Loss 0.3174\n",
      "2020-10-21 09:40:08,591 - INFO - Epoch [ 63/100] - Batch [ 17600/ 29640] (59%) - Loss 0.3878\n",
      "2020-10-21 09:41:18,205 - INFO - Epoch [ 63/100] - Batch [ 19200/ 29640] (65%) - Loss 0.3600\n",
      "2020-10-21 09:42:27,999 - INFO - Epoch [ 63/100] - Batch [ 20800/ 29640] (70%) - Loss 0.6979\n",
      "2020-10-21 09:43:37,558 - INFO - Epoch [ 63/100] - Batch [ 22400/ 29640] (76%) - Loss 0.6152\n",
      "2020-10-21 09:44:46,898 - INFO - Epoch [ 63/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4004\n",
      "2020-10-21 09:45:56,417 - INFO - Epoch [ 63/100] - Batch [ 25600/ 29640] (86%) - Loss 0.3570\n",
      "2020-10-21 09:47:05,063 - INFO - Epoch [ 63/100] - Batch [ 27200/ 29640] (92%) - Loss 0.3916\n",
      "2020-10-21 09:48:12,259 - INFO - Epoch [ 63/100] - Batch [ 28800/ 29640] (97%) - Loss 0.5845\n",
      "2020-10-21 09:48:47,522 - INFO - Current lr: 0.01\n",
      "2020-10-21 09:48:47,523 - INFO - train, Loss: 0.4914 Acc: 0.8000\n",
      "2020-10-21 09:48:54,739 - INFO - Epoch [ 63/100] - Batch [     0/  1483] ( 0%) - Loss 0.9095\n",
      "2020-10-21 09:49:30,475 - INFO - Current lr: 0.01\n",
      "2020-10-21 09:49:30,476 - INFO - valid, Loss: 0.7658 Acc: 0.5212\n",
      "0.5188402845660913\n",
      "2020-10-21 09:49:30,477 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 09:49:40,124 - INFO - Epoch [ 64/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4645\n",
      "2020-10-21 09:50:52,228 - INFO - Epoch [ 64/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.5955\n",
      "2020-10-21 09:52:02,201 - INFO - Epoch [ 64/100] - Batch [  3200/ 29640] (11%) - Loss 0.3374\n",
      "2020-10-21 09:53:11,381 - INFO - Epoch [ 64/100] - Batch [  4800/ 29640] (16%) - Loss 0.2947\n",
      "2020-10-21 09:54:20,578 - INFO - Epoch [ 64/100] - Batch [  6400/ 29640] (22%) - Loss 0.4366\n",
      "2020-10-21 09:55:29,942 - INFO - Epoch [ 64/100] - Batch [  8000/ 29640] (27%) - Loss 0.4019\n",
      "2020-10-21 09:56:39,748 - INFO - Epoch [ 64/100] - Batch [  9600/ 29640] (32%) - Loss 0.2880\n",
      "2020-10-21 09:57:48,921 - INFO - Epoch [ 64/100] - Batch [ 11200/ 29640] (38%) - Loss 0.6587\n",
      "2020-10-21 09:58:57,856 - INFO - Epoch [ 64/100] - Batch [ 12800/ 29640] (43%) - Loss 0.2870\n",
      "2020-10-21 10:00:06,978 - INFO - Epoch [ 64/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4843\n",
      "2020-10-21 10:01:16,304 - INFO - Epoch [ 64/100] - Batch [ 16000/ 29640] (54%) - Loss 0.7850\n",
      "2020-10-21 10:02:25,583 - INFO - Epoch [ 64/100] - Batch [ 17600/ 29640] (59%) - Loss 0.4487\n",
      "2020-10-21 10:03:34,670 - INFO - Epoch [ 64/100] - Batch [ 19200/ 29640] (65%) - Loss 0.4715\n",
      "2020-10-21 10:04:44,144 - INFO - Epoch [ 64/100] - Batch [ 20800/ 29640] (70%) - Loss 0.3857\n",
      "2020-10-21 10:05:53,630 - INFO - Epoch [ 64/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4955\n",
      "2020-10-21 10:07:03,319 - INFO - Epoch [ 64/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4960\n",
      "2020-10-21 10:08:12,750 - INFO - Epoch [ 64/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4497\n",
      "2020-10-21 10:09:21,067 - INFO - Epoch [ 64/100] - Batch [ 27200/ 29640] (92%) - Loss 0.4056\n",
      "2020-10-21 10:10:28,300 - INFO - Epoch [ 64/100] - Batch [ 28800/ 29640] (97%) - Loss 0.3476\n",
      "2020-10-21 10:11:03,616 - INFO - Current lr: 0.01\n",
      "2020-10-21 10:11:03,618 - INFO - train, Loss: 0.4922 Acc: 0.8000\n",
      "2020-10-21 10:11:11,851 - INFO - Epoch [ 64/100] - Batch [     0/  1483] ( 0%) - Loss 0.8473\n",
      "2020-10-21 10:11:46,722 - INFO - Current lr: 0.01\n",
      "2020-10-21 10:11:46,723 - INFO - valid, Loss: 0.9195 Acc: 0.5341\n",
      "0.5375900533158597\n",
      "2020-10-21 10:11:57,766 - INFO - Epoch [ 65/100] - Batch [     0/ 29640] ( 0%) - Loss 0.6775\n",
      "2020-10-21 10:13:11,039 - INFO - Epoch [ 65/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.3639\n",
      "2020-10-21 10:14:21,158 - INFO - Epoch [ 65/100] - Batch [  3200/ 29640] (11%) - Loss 0.3885\n",
      "2020-10-21 10:15:30,885 - INFO - Epoch [ 65/100] - Batch [  4800/ 29640] (16%) - Loss 0.5571\n",
      "2020-10-21 10:16:40,228 - INFO - Epoch [ 65/100] - Batch [  6400/ 29640] (22%) - Loss 0.2502\n",
      "2020-10-21 10:17:49,719 - INFO - Epoch [ 65/100] - Batch [  8000/ 29640] (27%) - Loss 0.6936\n",
      "2020-10-21 10:18:59,555 - INFO - Epoch [ 65/100] - Batch [  9600/ 29640] (32%) - Loss 0.4458\n",
      "2020-10-21 10:20:09,288 - INFO - Epoch [ 65/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3465\n",
      "2020-10-21 10:21:19,188 - INFO - Epoch [ 65/100] - Batch [ 12800/ 29640] (43%) - Loss 0.2519\n",
      "2020-10-21 10:22:28,931 - INFO - Epoch [ 65/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4268\n",
      "2020-10-21 10:23:38,723 - INFO - Epoch [ 65/100] - Batch [ 16000/ 29640] (54%) - Loss 0.4101\n",
      "2020-10-21 10:24:48,217 - INFO - Epoch [ 65/100] - Batch [ 17600/ 29640] (59%) - Loss 0.4952\n",
      "2020-10-21 10:25:58,053 - INFO - Epoch [ 65/100] - Batch [ 19200/ 29640] (65%) - Loss 0.3338\n",
      "2020-10-21 10:27:07,880 - INFO - Epoch [ 65/100] - Batch [ 20800/ 29640] (70%) - Loss 0.4051\n",
      "2020-10-21 10:28:17,381 - INFO - Epoch [ 65/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5739\n",
      "2020-10-21 10:29:26,523 - INFO - Epoch [ 65/100] - Batch [ 24000/ 29640] (81%) - Loss 0.2848\n",
      "2020-10-21 10:30:35,811 - INFO - Epoch [ 65/100] - Batch [ 25600/ 29640] (86%) - Loss 0.7391\n",
      "2020-10-21 10:31:44,450 - INFO - Epoch [ 65/100] - Batch [ 27200/ 29640] (92%) - Loss 0.7150\n",
      "2020-10-21 10:32:51,502 - INFO - Epoch [ 65/100] - Batch [ 28800/ 29640] (97%) - Loss 0.6195\n",
      "2020-10-21 10:33:26,726 - INFO - Current lr: 0.01\n",
      "2020-10-21 10:33:26,728 - INFO - train, Loss: 0.4915 Acc: 0.8000\n",
      "2020-10-21 10:33:35,038 - INFO - Epoch [ 65/100] - Batch [     0/  1483] ( 0%) - Loss 0.6134\n",
      "2020-10-21 10:34:08,901 - INFO - Current lr: 0.01\n",
      "2020-10-21 10:34:08,902 - INFO - valid, Loss: 0.7860 Acc: 0.5118\n",
      "0.5119328252392769\n",
      "2020-10-21 10:34:08,902 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 10:34:18,964 - INFO - Epoch [ 66/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4388\n",
      "2020-10-21 10:35:30,674 - INFO - Epoch [ 66/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.5794\n",
      "2020-10-21 10:36:39,784 - INFO - Epoch [ 66/100] - Batch [  3200/ 29640] (11%) - Loss 0.6147\n",
      "2020-10-21 10:37:48,991 - INFO - Epoch [ 66/100] - Batch [  4800/ 29640] (16%) - Loss 0.3068\n",
      "2020-10-21 10:38:57,913 - INFO - Epoch [ 66/100] - Batch [  6400/ 29640] (22%) - Loss 0.5635\n",
      "2020-10-21 10:40:07,340 - INFO - Epoch [ 66/100] - Batch [  8000/ 29640] (27%) - Loss 0.5472\n",
      "2020-10-21 10:41:16,806 - INFO - Epoch [ 66/100] - Batch [  9600/ 29640] (32%) - Loss 0.7168\n",
      "2020-10-21 10:42:26,414 - INFO - Epoch [ 66/100] - Batch [ 11200/ 29640] (38%) - Loss 0.6541\n",
      "2020-10-21 10:43:35,758 - INFO - Epoch [ 66/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4368\n",
      "2020-10-21 10:44:44,897 - INFO - Epoch [ 66/100] - Batch [ 14400/ 29640] (49%) - Loss 0.3198\n",
      "2020-10-21 10:45:53,855 - INFO - Epoch [ 66/100] - Batch [ 16000/ 29640] (54%) - Loss 0.5688\n",
      "2020-10-21 10:47:03,138 - INFO - Epoch [ 66/100] - Batch [ 17600/ 29640] (59%) - Loss 0.5248\n",
      "2020-10-21 10:48:12,554 - INFO - Epoch [ 66/100] - Batch [ 19200/ 29640] (65%) - Loss 0.3618\n",
      "2020-10-21 10:49:21,545 - INFO - Epoch [ 66/100] - Batch [ 20800/ 29640] (70%) - Loss 0.3350\n",
      "2020-10-21 10:50:30,599 - INFO - Epoch [ 66/100] - Batch [ 22400/ 29640] (76%) - Loss 0.6586\n",
      "2020-10-21 10:51:40,090 - INFO - Epoch [ 66/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4010\n",
      "2020-10-21 10:52:49,586 - INFO - Epoch [ 66/100] - Batch [ 25600/ 29640] (86%) - Loss 0.3937\n",
      "2020-10-21 10:53:58,087 - INFO - Epoch [ 66/100] - Batch [ 27200/ 29640] (92%) - Loss 0.6334\n",
      "2020-10-21 10:55:05,587 - INFO - Epoch [ 66/100] - Batch [ 28800/ 29640] (97%) - Loss 0.5506\n",
      "2020-10-21 10:55:41,200 - INFO - Current lr: 0.01\n",
      "2020-10-21 10:55:41,201 - INFO - train, Loss: 0.4926 Acc: 0.8000\n",
      "2020-10-21 10:55:52,843 - INFO - Epoch [ 66/100] - Batch [     0/  1483] ( 0%) - Loss 0.6118\n",
      "2020-10-21 10:56:24,889 - INFO - Current lr: 0.01\n",
      "2020-10-21 10:56:24,890 - INFO - valid, Loss: 0.7965 Acc: 0.5145\n",
      "0.5147389796583345\n",
      "2020-10-21 10:56:24,891 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 10:56:34,443 - INFO - Epoch [ 67/100] - Batch [     0/ 29640] ( 0%) - Loss 0.5269\n",
      "2020-10-21 10:57:48,970 - INFO - Epoch [ 67/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.4664\n",
      "2020-10-21 10:58:58,586 - INFO - Epoch [ 67/100] - Batch [  3200/ 29640] (11%) - Loss 0.5278\n",
      "2020-10-21 11:00:08,310 - INFO - Epoch [ 67/100] - Batch [  4800/ 29640] (16%) - Loss 0.5936\n",
      "2020-10-21 11:01:18,358 - INFO - Epoch [ 67/100] - Batch [  6400/ 29640] (22%) - Loss 0.5636\n",
      "2020-10-21 11:02:28,088 - INFO - Epoch [ 67/100] - Batch [  8000/ 29640] (27%) - Loss 0.5151\n",
      "2020-10-21 11:03:37,427 - INFO - Epoch [ 67/100] - Batch [  9600/ 29640] (32%) - Loss 0.4621\n",
      "2020-10-21 11:04:46,711 - INFO - Epoch [ 67/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3156\n",
      "2020-10-21 11:05:56,159 - INFO - Epoch [ 67/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4434\n",
      "2020-10-21 11:07:05,713 - INFO - Epoch [ 67/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4936\n",
      "2020-10-21 11:08:14,998 - INFO - Epoch [ 67/100] - Batch [ 16000/ 29640] (54%) - Loss 0.5271\n",
      "2020-10-21 11:09:24,338 - INFO - Epoch [ 67/100] - Batch [ 17600/ 29640] (59%) - Loss 0.3965\n",
      "2020-10-21 11:10:34,061 - INFO - Epoch [ 67/100] - Batch [ 19200/ 29640] (65%) - Loss 0.4519\n",
      "2020-10-21 11:11:43,717 - INFO - Epoch [ 67/100] - Batch [ 20800/ 29640] (70%) - Loss 0.4509\n",
      "2020-10-21 11:12:53,298 - INFO - Epoch [ 67/100] - Batch [ 22400/ 29640] (76%) - Loss 0.3965\n",
      "2020-10-21 11:14:02,702 - INFO - Epoch [ 67/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4078\n",
      "2020-10-21 11:15:12,206 - INFO - Epoch [ 67/100] - Batch [ 25600/ 29640] (86%) - Loss 0.6238\n",
      "2020-10-21 11:16:20,927 - INFO - Epoch [ 67/100] - Batch [ 27200/ 29640] (92%) - Loss 0.2541\n",
      "2020-10-21 11:17:28,617 - INFO - Epoch [ 67/100] - Batch [ 28800/ 29640] (97%) - Loss 0.5812\n",
      "2020-10-21 11:18:04,212 - INFO - Current lr: 0.01\n",
      "2020-10-21 11:18:04,214 - INFO - train, Loss: 0.4910 Acc: 0.8000\n",
      "2020-10-21 11:18:12,324 - INFO - Epoch [ 67/100] - Batch [     0/  1483] ( 0%) - Loss 0.7537\n",
      "2020-10-21 11:18:46,520 - INFO - Current lr: 0.01\n",
      "2020-10-21 11:18:46,521 - INFO - valid, Loss: 0.7948 Acc: 0.5017\n",
      "0.5013716271780788\n",
      "2020-10-21 11:18:46,522 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 11:18:58,939 - INFO - Epoch [ 68/100] - Batch [     0/ 29640] ( 0%) - Loss 0.8871\n",
      "2020-10-21 11:20:10,530 - INFO - Epoch [ 68/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.7938\n",
      "2020-10-21 11:21:20,453 - INFO - Epoch [ 68/100] - Batch [  3200/ 29640] (11%) - Loss 0.5525\n",
      "2020-10-21 11:22:30,149 - INFO - Epoch [ 68/100] - Batch [  4800/ 29640] (16%) - Loss 0.5422\n",
      "2020-10-21 11:23:39,470 - INFO - Epoch [ 68/100] - Batch [  6400/ 29640] (22%) - Loss 0.4606\n",
      "2020-10-21 11:24:48,309 - INFO - Epoch [ 68/100] - Batch [  8000/ 29640] (27%) - Loss 0.5957\n",
      "2020-10-21 11:25:57,327 - INFO - Epoch [ 68/100] - Batch [  9600/ 29640] (32%) - Loss 0.6723\n",
      "2020-10-21 11:27:06,588 - INFO - Epoch [ 68/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3528\n",
      "2020-10-21 11:28:15,344 - INFO - Epoch [ 68/100] - Batch [ 12800/ 29640] (43%) - Loss 0.2397\n",
      "2020-10-21 11:29:24,580 - INFO - Epoch [ 68/100] - Batch [ 14400/ 29640] (49%) - Loss 0.5910\n",
      "2020-10-21 11:30:33,981 - INFO - Epoch [ 68/100] - Batch [ 16000/ 29640] (54%) - Loss 0.3334\n",
      "2020-10-21 11:31:43,589 - INFO - Epoch [ 68/100] - Batch [ 17600/ 29640] (59%) - Loss 0.2939\n",
      "2020-10-21 11:32:52,684 - INFO - Epoch [ 68/100] - Batch [ 19200/ 29640] (65%) - Loss 0.3741\n",
      "2020-10-21 11:34:01,828 - INFO - Epoch [ 68/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5299\n",
      "2020-10-21 11:35:11,008 - INFO - Epoch [ 68/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4331\n",
      "2020-10-21 11:36:20,641 - INFO - Epoch [ 68/100] - Batch [ 24000/ 29640] (81%) - Loss 0.3729\n",
      "2020-10-21 11:37:30,179 - INFO - Epoch [ 68/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4425\n",
      "2020-10-21 11:38:38,675 - INFO - Epoch [ 68/100] - Batch [ 27200/ 29640] (92%) - Loss 0.6385\n",
      "2020-10-21 11:39:45,927 - INFO - Epoch [ 68/100] - Batch [ 28800/ 29640] (97%) - Loss 0.3639\n",
      "2020-10-21 11:40:20,988 - INFO - Current lr: 0.01\n",
      "2020-10-21 11:40:20,990 - INFO - train, Loss: 0.4913 Acc: 0.8000\n",
      "2020-10-21 11:40:28,161 - INFO - Epoch [ 68/100] - Batch [     0/  1483] ( 0%) - Loss 0.5106\n",
      "2020-10-21 11:41:04,437 - INFO - Current lr: 0.01\n",
      "2020-10-21 11:41:04,438 - INFO - valid, Loss: 0.7691 Acc: 0.5853\n",
      "0.5862142636336183\n",
      "new best model  with acc = 0.5853000674308834\n",
      "2020-10-21 11:41:16,063 - INFO - Epoch [ 69/100] - Batch [     0/ 29640] ( 0%) - Loss 0.3471\n",
      "2020-10-21 11:42:29,321 - INFO - Epoch [ 69/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.5232\n",
      "2020-10-21 11:43:39,547 - INFO - Epoch [ 69/100] - Batch [  3200/ 29640] (11%) - Loss 0.5110\n",
      "2020-10-21 11:44:49,511 - INFO - Epoch [ 69/100] - Batch [  4800/ 29640] (16%) - Loss 0.3776\n",
      "2020-10-21 11:45:59,175 - INFO - Epoch [ 69/100] - Batch [  6400/ 29640] (22%) - Loss 0.4137\n",
      "2020-10-21 11:47:08,898 - INFO - Epoch [ 69/100] - Batch [  8000/ 29640] (27%) - Loss 0.6103\n",
      "2020-10-21 11:48:18,365 - INFO - Epoch [ 69/100] - Batch [  9600/ 29640] (32%) - Loss 0.2960\n",
      "2020-10-21 11:49:27,492 - INFO - Epoch [ 69/100] - Batch [ 11200/ 29640] (38%) - Loss 0.4617\n",
      "2020-10-21 11:50:36,839 - INFO - Epoch [ 69/100] - Batch [ 12800/ 29640] (43%) - Loss 0.5969\n",
      "2020-10-21 11:51:46,739 - INFO - Epoch [ 69/100] - Batch [ 14400/ 29640] (49%) - Loss 0.2609\n",
      "2020-10-21 11:52:56,228 - INFO - Epoch [ 69/100] - Batch [ 16000/ 29640] (54%) - Loss 0.4677\n",
      "2020-10-21 11:54:05,472 - INFO - Epoch [ 69/100] - Batch [ 17600/ 29640] (59%) - Loss 0.4596\n",
      "2020-10-21 11:55:14,769 - INFO - Epoch [ 69/100] - Batch [ 19200/ 29640] (65%) - Loss 0.4404\n",
      "2020-10-21 11:56:24,508 - INFO - Epoch [ 69/100] - Batch [ 20800/ 29640] (70%) - Loss 0.6858\n",
      "2020-10-21 11:57:33,996 - INFO - Epoch [ 69/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5247\n",
      "2020-10-21 11:58:43,350 - INFO - Epoch [ 69/100] - Batch [ 24000/ 29640] (81%) - Loss 0.8248\n",
      "2020-10-21 11:59:52,773 - INFO - Epoch [ 69/100] - Batch [ 25600/ 29640] (86%) - Loss 0.5106\n",
      "2020-10-21 12:01:01,235 - INFO - Epoch [ 69/100] - Batch [ 27200/ 29640] (92%) - Loss 0.3175\n",
      "2020-10-21 12:02:08,756 - INFO - Epoch [ 69/100] - Batch [ 28800/ 29640] (97%) - Loss 0.4997\n",
      "2020-10-21 12:02:43,768 - INFO - Current lr: 0.01\n",
      "2020-10-21 12:02:43,769 - INFO - train, Loss: 0.4918 Acc: 0.8000\n",
      "2020-10-21 12:02:54,948 - INFO - Epoch [ 69/100] - Batch [     0/  1483] ( 0%) - Loss 0.8486\n",
      "2020-10-21 12:03:27,077 - INFO - Current lr: 0.01\n",
      "2020-10-21 12:03:27,078 - INFO - valid, Loss: 0.8246 Acc: 0.4990\n",
      "0.4988799283154121\n",
      "2020-10-21 12:03:27,079 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 12:03:36,485 - INFO - Epoch [ 70/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4611\n",
      "2020-10-21 12:04:51,244 - INFO - Epoch [ 70/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.4559\n",
      "2020-10-21 12:06:00,909 - INFO - Epoch [ 70/100] - Batch [  3200/ 29640] (11%) - Loss 0.5581\n",
      "2020-10-21 12:07:10,870 - INFO - Epoch [ 70/100] - Batch [  4800/ 29640] (16%) - Loss 0.5425\n",
      "2020-10-21 12:08:20,203 - INFO - Epoch [ 70/100] - Batch [  6400/ 29640] (22%) - Loss 0.3755\n",
      "2020-10-21 12:09:29,385 - INFO - Epoch [ 70/100] - Batch [  8000/ 29640] (27%) - Loss 0.4026\n",
      "2020-10-21 12:10:38,475 - INFO - Epoch [ 70/100] - Batch [  9600/ 29640] (32%) - Loss 0.6073\n",
      "2020-10-21 12:11:48,077 - INFO - Epoch [ 70/100] - Batch [ 11200/ 29640] (38%) - Loss 0.4220\n",
      "2020-10-21 12:12:57,199 - INFO - Epoch [ 70/100] - Batch [ 12800/ 29640] (43%) - Loss 0.6469\n",
      "2020-10-21 12:14:06,800 - INFO - Epoch [ 70/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4879\n",
      "2020-10-21 12:15:16,164 - INFO - Epoch [ 70/100] - Batch [ 16000/ 29640] (54%) - Loss 0.4455\n",
      "2020-10-21 12:16:25,400 - INFO - Epoch [ 70/100] - Batch [ 17600/ 29640] (59%) - Loss 0.6123\n",
      "2020-10-21 12:17:35,000 - INFO - Epoch [ 70/100] - Batch [ 19200/ 29640] (65%) - Loss 0.6963\n",
      "2020-10-21 12:18:43,994 - INFO - Epoch [ 70/100] - Batch [ 20800/ 29640] (70%) - Loss 0.6702\n",
      "2020-10-21 12:19:53,376 - INFO - Epoch [ 70/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4752\n",
      "2020-10-21 12:21:03,023 - INFO - Epoch [ 70/100] - Batch [ 24000/ 29640] (81%) - Loss 0.3625\n",
      "2020-10-21 12:22:12,682 - INFO - Epoch [ 70/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4703\n",
      "2020-10-21 12:23:21,366 - INFO - Epoch [ 70/100] - Batch [ 27200/ 29640] (92%) - Loss 0.3272\n",
      "2020-10-21 12:24:28,748 - INFO - Epoch [ 70/100] - Batch [ 28800/ 29640] (97%) - Loss 0.3997\n",
      "2020-10-21 12:25:04,059 - INFO - Current lr: 0.01\n",
      "2020-10-21 12:25:04,060 - INFO - train, Loss: 0.4911 Acc: 0.8000\n",
      "2020-10-21 12:25:12,512 - INFO - Epoch [ 70/100] - Batch [     0/  1483] ( 0%) - Loss 0.9351\n",
      "2020-10-21 12:25:48,026 - INFO - Current lr: 0.01\n",
      "2020-10-21 12:25:48,027 - INFO - valid, Loss: 0.8446 Acc: 0.5003\n",
      "0.5\n",
      "2020-10-21 12:25:48,028 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 12:26:01,743 - INFO - Epoch [ 71/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4540\n",
      "2020-10-21 12:27:13,725 - INFO - Epoch [ 71/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.9224\n",
      "2020-10-21 12:28:24,036 - INFO - Epoch [ 71/100] - Batch [  3200/ 29640] (11%) - Loss 0.2151\n",
      "2020-10-21 12:29:33,573 - INFO - Epoch [ 71/100] - Batch [  4800/ 29640] (16%) - Loss 0.3624\n",
      "2020-10-21 12:30:43,380 - INFO - Epoch [ 71/100] - Batch [  6400/ 29640] (22%) - Loss 0.3954\n",
      "2020-10-21 12:31:53,074 - INFO - Epoch [ 71/100] - Batch [  8000/ 29640] (27%) - Loss 0.2524\n",
      "2020-10-21 12:33:02,609 - INFO - Epoch [ 71/100] - Batch [  9600/ 29640] (32%) - Loss 0.3730\n",
      "2020-10-21 12:34:11,917 - INFO - Epoch [ 71/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3569\n",
      "2020-10-21 12:35:21,961 - INFO - Epoch [ 71/100] - Batch [ 12800/ 29640] (43%) - Loss 0.8738\n",
      "2020-10-21 12:36:31,780 - INFO - Epoch [ 71/100] - Batch [ 14400/ 29640] (49%) - Loss 0.2285\n",
      "2020-10-21 12:37:41,405 - INFO - Epoch [ 71/100] - Batch [ 16000/ 29640] (54%) - Loss 0.6523\n",
      "2020-10-21 12:38:51,046 - INFO - Epoch [ 71/100] - Batch [ 17600/ 29640] (59%) - Loss 0.4333\n",
      "2020-10-21 12:40:00,535 - INFO - Epoch [ 71/100] - Batch [ 19200/ 29640] (65%) - Loss 0.3868\n",
      "2020-10-21 12:41:10,460 - INFO - Epoch [ 71/100] - Batch [ 20800/ 29640] (70%) - Loss 0.4464\n",
      "2020-10-21 12:42:20,300 - INFO - Epoch [ 71/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4491\n",
      "2020-10-21 12:43:29,456 - INFO - Epoch [ 71/100] - Batch [ 24000/ 29640] (81%) - Loss 0.5871\n",
      "2020-10-21 12:44:38,954 - INFO - Epoch [ 71/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4911\n",
      "2020-10-21 12:45:48,050 - INFO - Epoch [ 71/100] - Batch [ 27200/ 29640] (92%) - Loss 0.7642\n",
      "2020-10-21 12:46:55,466 - INFO - Epoch [ 71/100] - Batch [ 28800/ 29640] (97%) - Loss 0.4494\n",
      "2020-10-21 12:47:30,573 - INFO - Current lr: 0.01\n",
      "2020-10-21 12:47:30,574 - INFO - train, Loss: 0.4897 Acc: 0.8000\n",
      "2020-10-21 12:47:39,776 - INFO - Epoch [ 71/100] - Batch [     0/  1483] ( 0%) - Loss 0.7355\n",
      "2020-10-21 12:48:14,012 - INFO - Current lr: 0.01\n",
      "2020-10-21 12:48:14,014 - INFO - valid, Loss: 0.7295 Acc: 0.5664\n",
      "0.5630253706866613\n",
      "2020-10-21 12:48:27,454 - INFO - Epoch [ 72/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4151\n",
      "2020-10-21 12:49:39,476 - INFO - Epoch [ 72/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.3309\n",
      "2020-10-21 12:50:50,004 - INFO - Epoch [ 72/100] - Batch [  3200/ 29640] (11%) - Loss 0.5436\n",
      "2020-10-21 12:52:00,478 - INFO - Epoch [ 72/100] - Batch [  4800/ 29640] (16%) - Loss 0.3302\n",
      "2020-10-21 12:53:10,157 - INFO - Epoch [ 72/100] - Batch [  6400/ 29640] (22%) - Loss 0.3891\n",
      "2020-10-21 12:54:19,809 - INFO - Epoch [ 72/100] - Batch [  8000/ 29640] (27%) - Loss 0.7384\n",
      "2020-10-21 12:55:29,714 - INFO - Epoch [ 72/100] - Batch [  9600/ 29640] (32%) - Loss 0.6746\n",
      "2020-10-21 12:56:39,873 - INFO - Epoch [ 72/100] - Batch [ 11200/ 29640] (38%) - Loss 0.6288\n",
      "2020-10-21 12:57:49,688 - INFO - Epoch [ 72/100] - Batch [ 12800/ 29640] (43%) - Loss 0.3543\n",
      "2020-10-21 12:58:59,159 - INFO - Epoch [ 72/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4362\n",
      "2020-10-21 13:00:09,098 - INFO - Epoch [ 72/100] - Batch [ 16000/ 29640] (54%) - Loss 0.4235\n",
      "2020-10-21 13:01:19,693 - INFO - Epoch [ 72/100] - Batch [ 17600/ 29640] (59%) - Loss 0.2965\n",
      "2020-10-21 13:02:29,631 - INFO - Epoch [ 72/100] - Batch [ 19200/ 29640] (65%) - Loss 0.4598\n",
      "2020-10-21 13:03:39,115 - INFO - Epoch [ 72/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5848\n",
      "2020-10-21 13:04:48,639 - INFO - Epoch [ 72/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5019\n",
      "2020-10-21 13:05:58,538 - INFO - Epoch [ 72/100] - Batch [ 24000/ 29640] (81%) - Loss 0.3739\n",
      "2020-10-21 13:07:08,447 - INFO - Epoch [ 72/100] - Batch [ 25600/ 29640] (86%) - Loss 0.3654\n",
      "2020-10-21 13:08:17,215 - INFO - Epoch [ 72/100] - Batch [ 27200/ 29640] (92%) - Loss 0.2984\n",
      "2020-10-21 13:09:24,709 - INFO - Epoch [ 72/100] - Batch [ 28800/ 29640] (97%) - Loss 0.7135\n",
      "2020-10-21 13:10:00,160 - INFO - Current lr: 0.01\n",
      "2020-10-21 13:10:00,161 - INFO - train, Loss: 0.4896 Acc: 0.8000\n",
      "2020-10-21 13:10:07,479 - INFO - Epoch [ 72/100] - Batch [     0/  1483] ( 0%) - Loss 1.0818\n",
      "2020-10-21 13:10:44,358 - INFO - Current lr: 0.01\n",
      "2020-10-21 13:10:44,360 - INFO - valid, Loss: 1.0498 Acc: 0.5024\n",
      "0.5021229964778352\n",
      "2020-10-21 13:10:44,361 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 13:10:56,665 - INFO - Epoch [ 73/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4711\n",
      "2020-10-21 13:12:08,332 - INFO - Epoch [ 73/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.7370\n",
      "2020-10-21 13:13:18,046 - INFO - Epoch [ 73/100] - Batch [  3200/ 29640] (11%) - Loss 0.5585\n",
      "2020-10-21 13:14:27,978 - INFO - Epoch [ 73/100] - Batch [  4800/ 29640] (16%) - Loss 0.3295\n",
      "2020-10-21 13:15:37,725 - INFO - Epoch [ 73/100] - Batch [  6400/ 29640] (22%) - Loss 0.3099\n",
      "2020-10-21 13:16:47,356 - INFO - Epoch [ 73/100] - Batch [  8000/ 29640] (27%) - Loss 0.5724\n",
      "2020-10-21 13:17:56,512 - INFO - Epoch [ 73/100] - Batch [  9600/ 29640] (32%) - Loss 0.7551\n",
      "2020-10-21 13:19:05,526 - INFO - Epoch [ 73/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3545\n",
      "2020-10-21 13:20:15,384 - INFO - Epoch [ 73/100] - Batch [ 12800/ 29640] (43%) - Loss 0.2966\n",
      "2020-10-21 13:21:24,991 - INFO - Epoch [ 73/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4732\n",
      "2020-10-21 13:22:34,191 - INFO - Epoch [ 73/100] - Batch [ 16000/ 29640] (54%) - Loss 0.6571\n",
      "2020-10-21 13:23:43,432 - INFO - Epoch [ 73/100] - Batch [ 17600/ 29640] (59%) - Loss 0.3914\n",
      "2020-10-21 13:24:52,671 - INFO - Epoch [ 73/100] - Batch [ 19200/ 29640] (65%) - Loss 0.5057\n",
      "2020-10-21 13:26:02,190 - INFO - Epoch [ 73/100] - Batch [ 20800/ 29640] (70%) - Loss 0.4626\n",
      "2020-10-21 13:27:11,750 - INFO - Epoch [ 73/100] - Batch [ 22400/ 29640] (76%) - Loss 0.3696\n",
      "2020-10-21 13:28:20,560 - INFO - Epoch [ 73/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4772\n",
      "2020-10-21 13:29:29,477 - INFO - Epoch [ 73/100] - Batch [ 25600/ 29640] (86%) - Loss 0.7423\n",
      "2020-10-21 13:30:37,839 - INFO - Epoch [ 73/100] - Batch [ 27200/ 29640] (92%) - Loss 0.3123\n",
      "2020-10-21 13:31:45,008 - INFO - Epoch [ 73/100] - Batch [ 28800/ 29640] (97%) - Loss 0.9799\n",
      "2020-10-21 13:32:19,954 - INFO - Current lr: 0.01\n",
      "2020-10-21 13:32:19,955 - INFO - train, Loss: 0.4899 Acc: 0.8000\n",
      "2020-10-21 13:32:28,399 - INFO - Epoch [ 73/100] - Batch [     0/  1483] ( 0%) - Loss 1.3360\n",
      "2020-10-21 13:33:02,276 - INFO - Current lr: 0.01\n",
      "2020-10-21 13:33:02,277 - INFO - valid, Loss: 0.9801 Acc: 0.5334\n",
      "0.5378719697268085\n",
      "2020-10-21 13:33:13,435 - INFO - Epoch [ 74/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4281\n",
      "2020-10-21 13:34:25,879 - INFO - Epoch [ 74/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.9351\n",
      "2020-10-21 13:35:35,636 - INFO - Epoch [ 74/100] - Batch [  3200/ 29640] (11%) - Loss 0.5371\n",
      "2020-10-21 13:36:46,250 - INFO - Epoch [ 74/100] - Batch [  4800/ 29640] (16%) - Loss 0.2756\n",
      "2020-10-21 13:37:56,386 - INFO - Epoch [ 74/100] - Batch [  6400/ 29640] (22%) - Loss 0.5431\n",
      "2020-10-21 13:39:06,367 - INFO - Epoch [ 74/100] - Batch [  8000/ 29640] (27%) - Loss 0.4243\n",
      "2020-10-21 13:40:15,723 - INFO - Epoch [ 74/100] - Batch [  9600/ 29640] (32%) - Loss 0.6527\n",
      "2020-10-21 13:41:25,751 - INFO - Epoch [ 74/100] - Batch [ 11200/ 29640] (38%) - Loss 0.4391\n",
      "2020-10-21 13:42:35,866 - INFO - Epoch [ 74/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4895\n",
      "2020-10-21 13:43:45,455 - INFO - Epoch [ 74/100] - Batch [ 14400/ 29640] (49%) - Loss 0.3989\n",
      "2020-10-21 13:44:55,193 - INFO - Epoch [ 74/100] - Batch [ 16000/ 29640] (54%) - Loss 0.3964\n",
      "2020-10-21 13:46:05,346 - INFO - Epoch [ 74/100] - Batch [ 17600/ 29640] (59%) - Loss 0.7192\n",
      "2020-10-21 13:47:14,881 - INFO - Epoch [ 74/100] - Batch [ 19200/ 29640] (65%) - Loss 0.5163\n",
      "2020-10-21 13:48:24,188 - INFO - Epoch [ 74/100] - Batch [ 20800/ 29640] (70%) - Loss 0.3047\n",
      "2020-10-21 13:49:33,530 - INFO - Epoch [ 74/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4092\n",
      "2020-10-21 13:50:42,810 - INFO - Epoch [ 74/100] - Batch [ 24000/ 29640] (81%) - Loss 0.5417\n",
      "2020-10-21 13:51:52,726 - INFO - Epoch [ 74/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4301\n",
      "2020-10-21 13:53:01,131 - INFO - Epoch [ 74/100] - Batch [ 27200/ 29640] (92%) - Loss 0.6155\n",
      "2020-10-21 13:54:08,458 - INFO - Epoch [ 74/100] - Batch [ 28800/ 29640] (97%) - Loss 0.6832\n",
      "2020-10-21 13:54:43,657 - INFO - Current lr: 0.01\n",
      "2020-10-21 13:54:43,659 - INFO - train, Loss: 0.4893 Acc: 0.8000\n",
      "2020-10-21 13:54:51,725 - INFO - Epoch [ 74/100] - Batch [     0/  1483] ( 0%) - Loss 0.7164\n",
      "2020-10-21 13:55:26,501 - INFO - Current lr: 0.01\n",
      "2020-10-21 13:55:26,502 - INFO - valid, Loss: 0.8572 Acc: 0.5044\n",
      "0.5037232331587171\n",
      "2020-10-21 13:55:26,503 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 13:55:39,025 - INFO - Epoch [ 75/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4969\n",
      "2020-10-21 13:56:50,404 - INFO - Epoch [ 75/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.9314\n",
      "2020-10-21 13:57:59,341 - INFO - Epoch [ 75/100] - Batch [  3200/ 29640] (11%) - Loss 0.1607\n",
      "2020-10-21 13:59:08,263 - INFO - Epoch [ 75/100] - Batch [  4800/ 29640] (16%) - Loss 0.5123\n",
      "2020-10-21 14:00:17,364 - INFO - Epoch [ 75/100] - Batch [  6400/ 29640] (22%) - Loss 0.7495\n",
      "2020-10-21 14:01:26,376 - INFO - Epoch [ 75/100] - Batch [  8000/ 29640] (27%) - Loss 0.5122\n",
      "2020-10-21 14:02:35,140 - INFO - Epoch [ 75/100] - Batch [  9600/ 29640] (32%) - Loss 0.6257\n",
      "2020-10-21 14:03:43,920 - INFO - Epoch [ 75/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3777\n",
      "2020-10-21 14:04:52,906 - INFO - Epoch [ 75/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4845\n",
      "2020-10-21 14:06:02,208 - INFO - Epoch [ 75/100] - Batch [ 14400/ 29640] (49%) - Loss 0.3637\n",
      "2020-10-21 14:07:11,585 - INFO - Epoch [ 75/100] - Batch [ 16000/ 29640] (54%) - Loss 0.3818\n",
      "2020-10-21 14:08:20,584 - INFO - Epoch [ 75/100] - Batch [ 17600/ 29640] (59%) - Loss 0.5164\n",
      "2020-10-21 14:09:29,349 - INFO - Epoch [ 75/100] - Batch [ 19200/ 29640] (65%) - Loss 0.6306\n",
      "2020-10-21 14:10:38,541 - INFO - Epoch [ 75/100] - Batch [ 20800/ 29640] (70%) - Loss 0.4448\n",
      "2020-10-21 14:11:47,832 - INFO - Epoch [ 75/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5981\n",
      "2020-10-21 14:12:56,800 - INFO - Epoch [ 75/100] - Batch [ 24000/ 29640] (81%) - Loss 0.5269\n",
      "2020-10-21 14:14:05,633 - INFO - Epoch [ 75/100] - Batch [ 25600/ 29640] (86%) - Loss 0.3622\n",
      "2020-10-21 14:15:14,010 - INFO - Epoch [ 75/100] - Batch [ 27200/ 29640] (92%) - Loss 0.4920\n",
      "2020-10-21 14:16:21,614 - INFO - Epoch [ 75/100] - Batch [ 28800/ 29640] (97%) - Loss 0.4715\n",
      "2020-10-21 14:16:56,887 - INFO - Current lr: 0.01\n",
      "2020-10-21 14:16:56,888 - INFO - train, Loss: 0.4885 Acc: 0.8000\n",
      "2020-10-21 14:17:04,998 - INFO - Epoch [ 75/100] - Batch [     0/  1483] ( 0%) - Loss 0.6475\n",
      "2020-10-21 14:17:38,787 - INFO - Current lr: 0.01\n",
      "2020-10-21 14:17:38,788 - INFO - valid, Loss: 0.7652 Acc: 0.5145\n",
      "0.5162549069807133\n",
      "2020-10-21 14:17:38,789 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 14:17:49,984 - INFO - Epoch [ 76/100] - Batch [     0/ 29640] ( 0%) - Loss 0.2263\n",
      "2020-10-21 14:19:02,426 - INFO - Epoch [ 76/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.6435\n",
      "2020-10-21 14:20:12,408 - INFO - Epoch [ 76/100] - Batch [  3200/ 29640] (11%) - Loss 0.4743\n",
      "2020-10-21 14:21:22,788 - INFO - Epoch [ 76/100] - Batch [  4800/ 29640] (16%) - Loss 0.6871\n",
      "2020-10-21 14:22:32,766 - INFO - Epoch [ 76/100] - Batch [  6400/ 29640] (22%) - Loss 0.3423\n",
      "2020-10-21 14:23:42,657 - INFO - Epoch [ 76/100] - Batch [  8000/ 29640] (27%) - Loss 0.7090\n",
      "2020-10-21 14:24:52,423 - INFO - Epoch [ 76/100] - Batch [  9600/ 29640] (32%) - Loss 0.6412\n",
      "2020-10-21 14:26:02,056 - INFO - Epoch [ 76/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3545\n",
      "2020-10-21 14:27:12,067 - INFO - Epoch [ 76/100] - Batch [ 12800/ 29640] (43%) - Loss 0.2995\n",
      "2020-10-21 14:28:21,487 - INFO - Epoch [ 76/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4059\n",
      "2020-10-21 14:29:31,268 - INFO - Epoch [ 76/100] - Batch [ 16000/ 29640] (54%) - Loss 0.5177\n",
      "2020-10-21 14:30:40,696 - INFO - Epoch [ 76/100] - Batch [ 17600/ 29640] (59%) - Loss 0.4773\n",
      "2020-10-21 14:31:50,881 - INFO - Epoch [ 76/100] - Batch [ 19200/ 29640] (65%) - Loss 0.3486\n",
      "2020-10-21 14:33:00,588 - INFO - Epoch [ 76/100] - Batch [ 20800/ 29640] (70%) - Loss 0.3031\n",
      "2020-10-21 14:34:10,118 - INFO - Epoch [ 76/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4115\n",
      "2020-10-21 14:35:19,861 - INFO - Epoch [ 76/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4427\n",
      "2020-10-21 14:36:29,827 - INFO - Epoch [ 76/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4566\n",
      "2020-10-21 14:37:38,897 - INFO - Epoch [ 76/100] - Batch [ 27200/ 29640] (92%) - Loss 0.2303\n",
      "2020-10-21 14:38:46,188 - INFO - Epoch [ 76/100] - Batch [ 28800/ 29640] (97%) - Loss 0.3430\n",
      "2020-10-21 14:39:21,174 - INFO - Current lr: 0.01\n",
      "2020-10-21 14:39:21,176 - INFO - train, Loss: 0.4903 Acc: 0.8000\n",
      "2020-10-21 14:39:29,560 - INFO - Epoch [ 76/100] - Batch [     0/  1483] ( 0%) - Loss 0.9307\n",
      "2020-10-21 14:40:04,216 - INFO - Current lr: 0.01\n",
      "2020-10-21 14:40:04,217 - INFO - valid, Loss: 0.9459 Acc: 0.5010\n",
      "0.5005376344086021\n",
      "2020-10-21 14:40:04,218 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 14:40:13,536 - INFO - Epoch [ 77/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4580\n",
      "2020-10-21 14:41:26,731 - INFO - Epoch [ 77/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.6833\n",
      "2020-10-21 14:42:36,447 - INFO - Epoch [ 77/100] - Batch [  3200/ 29640] (11%) - Loss 0.5324\n",
      "2020-10-21 14:43:45,693 - INFO - Epoch [ 77/100] - Batch [  4800/ 29640] (16%) - Loss 0.2142\n",
      "2020-10-21 14:44:55,016 - INFO - Epoch [ 77/100] - Batch [  6400/ 29640] (22%) - Loss 0.2837\n",
      "2020-10-21 14:46:04,412 - INFO - Epoch [ 77/100] - Batch [  8000/ 29640] (27%) - Loss 0.4861\n",
      "2020-10-21 14:47:13,853 - INFO - Epoch [ 77/100] - Batch [  9600/ 29640] (32%) - Loss 0.3758\n",
      "2020-10-21 14:48:23,214 - INFO - Epoch [ 77/100] - Batch [ 11200/ 29640] (38%) - Loss 0.4197\n",
      "2020-10-21 14:49:32,423 - INFO - Epoch [ 77/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4538\n",
      "2020-10-21 14:50:41,226 - INFO - Epoch [ 77/100] - Batch [ 14400/ 29640] (49%) - Loss 0.2599\n",
      "2020-10-21 14:51:50,140 - INFO - Epoch [ 77/100] - Batch [ 16000/ 29640] (54%) - Loss 0.4159\n",
      "2020-10-21 14:52:59,428 - INFO - Epoch [ 77/100] - Batch [ 17600/ 29640] (59%) - Loss 0.3859\n",
      "2020-10-21 14:54:08,854 - INFO - Epoch [ 77/100] - Batch [ 19200/ 29640] (65%) - Loss 0.8252\n",
      "2020-10-21 14:55:18,435 - INFO - Epoch [ 77/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5253\n",
      "2020-10-21 14:56:27,708 - INFO - Epoch [ 77/100] - Batch [ 22400/ 29640] (76%) - Loss 0.7964\n",
      "2020-10-21 14:57:36,920 - INFO - Epoch [ 77/100] - Batch [ 24000/ 29640] (81%) - Loss 0.5046\n",
      "2020-10-21 14:58:46,107 - INFO - Epoch [ 77/100] - Batch [ 25600/ 29640] (86%) - Loss 0.3679\n",
      "2020-10-21 14:59:54,602 - INFO - Epoch [ 77/100] - Batch [ 27200/ 29640] (92%) - Loss 0.5776\n",
      "2020-10-21 15:01:01,613 - INFO - Epoch [ 77/100] - Batch [ 28800/ 29640] (97%) - Loss 0.4782\n",
      "2020-10-21 15:01:36,770 - INFO - Current lr: 0.01\n",
      "2020-10-21 15:01:36,772 - INFO - train, Loss: 0.4889 Acc: 0.8000\n",
      "2020-10-21 15:01:48,722 - INFO - Epoch [ 77/100] - Batch [     0/  1483] ( 0%) - Loss 1.0802\n",
      "2020-10-21 15:02:19,935 - INFO - Current lr: 0.01\n",
      "2020-10-21 15:02:19,936 - INFO - valid, Loss: 0.8031 Acc: 0.4997\n",
      "0.4994986345792797\n",
      "2020-10-21 15:02:19,937 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 15:02:32,423 - INFO - Epoch [ 78/100] - Batch [     0/ 29640] ( 0%) - Loss 0.6419\n",
      "2020-10-21 15:03:44,281 - INFO - Epoch [ 78/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.4268\n",
      "2020-10-21 15:04:54,061 - INFO - Epoch [ 78/100] - Batch [  3200/ 29640] (11%) - Loss 0.6268\n",
      "2020-10-21 15:06:03,750 - INFO - Epoch [ 78/100] - Batch [  4800/ 29640] (16%) - Loss 0.4560\n",
      "2020-10-21 15:07:13,417 - INFO - Epoch [ 78/100] - Batch [  6400/ 29640] (22%) - Loss 0.6102\n",
      "2020-10-21 15:08:22,878 - INFO - Epoch [ 78/100] - Batch [  8000/ 29640] (27%) - Loss 0.3903\n",
      "2020-10-21 15:09:32,484 - INFO - Epoch [ 78/100] - Batch [  9600/ 29640] (32%) - Loss 0.5217\n",
      "2020-10-21 15:10:41,823 - INFO - Epoch [ 78/100] - Batch [ 11200/ 29640] (38%) - Loss 0.6843\n",
      "2020-10-21 15:11:51,300 - INFO - Epoch [ 78/100] - Batch [ 12800/ 29640] (43%) - Loss 0.5551\n",
      "2020-10-21 15:13:00,330 - INFO - Epoch [ 78/100] - Batch [ 14400/ 29640] (49%) - Loss 0.3890\n",
      "2020-10-21 15:14:09,256 - INFO - Epoch [ 78/100] - Batch [ 16000/ 29640] (54%) - Loss 0.5564\n",
      "2020-10-21 15:15:18,424 - INFO - Epoch [ 78/100] - Batch [ 17600/ 29640] (59%) - Loss 0.6174\n",
      "2020-10-21 15:16:27,609 - INFO - Epoch [ 78/100] - Batch [ 19200/ 29640] (65%) - Loss 0.5453\n",
      "2020-10-21 15:17:36,929 - INFO - Epoch [ 78/100] - Batch [ 20800/ 29640] (70%) - Loss 0.6351\n",
      "2020-10-21 15:18:45,734 - INFO - Epoch [ 78/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5860\n",
      "2020-10-21 15:19:54,557 - INFO - Epoch [ 78/100] - Batch [ 24000/ 29640] (81%) - Loss 0.5320\n",
      "2020-10-21 15:21:03,864 - INFO - Epoch [ 78/100] - Batch [ 25600/ 29640] (86%) - Loss 0.7300\n",
      "2020-10-21 15:22:12,605 - INFO - Epoch [ 78/100] - Batch [ 27200/ 29640] (92%) - Loss 0.9099\n",
      "2020-10-21 15:23:19,756 - INFO - Epoch [ 78/100] - Batch [ 28800/ 29640] (97%) - Loss 0.2815\n",
      "2020-10-21 15:23:55,000 - INFO - Current lr: 0.01\n",
      "2020-10-21 15:23:55,001 - INFO - train, Loss: 0.4887 Acc: 0.8000\n",
      "2020-10-21 15:24:03,318 - INFO - Epoch [ 78/100] - Batch [     0/  1483] ( 0%) - Loss 0.8749\n",
      "2020-10-21 15:24:38,406 - INFO - Current lr: 0.01\n",
      "2020-10-21 15:24:38,408 - INFO - valid, Loss: 0.9525 Acc: 0.5118\n",
      "0.5130349787607852\n",
      "2020-10-21 15:24:49,788 - INFO - Epoch [ 79/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4899\n",
      "2020-10-21 15:26:02,474 - INFO - Epoch [ 79/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.5210\n",
      "2020-10-21 15:27:12,623 - INFO - Epoch [ 79/100] - Batch [  3200/ 29640] (11%) - Loss 0.5038\n",
      "2020-10-21 15:28:22,270 - INFO - Epoch [ 79/100] - Batch [  4800/ 29640] (16%) - Loss 0.7662\n",
      "2020-10-21 15:29:32,045 - INFO - Epoch [ 79/100] - Batch [  6400/ 29640] (22%) - Loss 0.3774\n",
      "2020-10-21 15:30:41,710 - INFO - Epoch [ 79/100] - Batch [  8000/ 29640] (27%) - Loss 0.4317\n",
      "2020-10-21 15:31:51,422 - INFO - Epoch [ 79/100] - Batch [  9600/ 29640] (32%) - Loss 0.6075\n",
      "2020-10-21 15:33:01,200 - INFO - Epoch [ 79/100] - Batch [ 11200/ 29640] (38%) - Loss 0.5513\n",
      "2020-10-21 15:34:10,642 - INFO - Epoch [ 79/100] - Batch [ 12800/ 29640] (43%) - Loss 0.3876\n",
      "2020-10-21 15:35:20,449 - INFO - Epoch [ 79/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4314\n",
      "2020-10-21 15:36:30,528 - INFO - Epoch [ 79/100] - Batch [ 16000/ 29640] (54%) - Loss 0.5479\n",
      "2020-10-21 15:37:40,015 - INFO - Epoch [ 79/100] - Batch [ 17600/ 29640] (59%) - Loss 0.4215\n",
      "2020-10-21 15:38:49,334 - INFO - Epoch [ 79/100] - Batch [ 19200/ 29640] (65%) - Loss 0.7156\n",
      "2020-10-21 15:39:59,172 - INFO - Epoch [ 79/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5497\n",
      "2020-10-21 15:41:09,131 - INFO - Epoch [ 79/100] - Batch [ 22400/ 29640] (76%) - Loss 0.7347\n",
      "2020-10-21 15:42:19,275 - INFO - Epoch [ 79/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4939\n",
      "2020-10-21 15:43:28,543 - INFO - Epoch [ 79/100] - Batch [ 25600/ 29640] (86%) - Loss 0.6210\n",
      "2020-10-21 15:44:37,165 - INFO - Epoch [ 79/100] - Batch [ 27200/ 29640] (92%) - Loss 0.5522\n",
      "2020-10-21 15:45:45,010 - INFO - Epoch [ 79/100] - Batch [ 28800/ 29640] (97%) - Loss 0.3845\n",
      "2020-10-21 15:46:20,424 - INFO - Current lr: 0.01\n",
      "2020-10-21 15:46:20,425 - INFO - train, Loss: 0.4884 Acc: 0.8000\n",
      "2020-10-21 15:46:28,578 - INFO - Epoch [ 79/100] - Batch [     0/  1483] ( 0%) - Loss 0.7793\n",
      "2020-10-21 15:47:03,368 - INFO - Current lr: 0.01\n",
      "2020-10-21 15:47:03,369 - INFO - valid, Loss: 0.9040 Acc: 0.5044\n",
      "0.5041241912209655\n",
      "2020-10-21 15:47:03,370 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 15:47:17,038 - INFO - Epoch [ 80/100] - Batch [     0/ 29640] ( 0%) - Loss 0.5374\n",
      "2020-10-21 15:48:27,679 - INFO - Epoch [ 80/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.4911\n",
      "2020-10-21 15:49:36,937 - INFO - Epoch [ 80/100] - Batch [  3200/ 29640] (11%) - Loss 0.4194\n",
      "2020-10-21 15:50:46,609 - INFO - Epoch [ 80/100] - Batch [  4800/ 29640] (16%) - Loss 0.3693\n",
      "2020-10-21 15:51:55,822 - INFO - Epoch [ 80/100] - Batch [  6400/ 29640] (22%) - Loss 0.7559\n",
      "2020-10-21 15:53:04,628 - INFO - Epoch [ 80/100] - Batch [  8000/ 29640] (27%) - Loss 0.6986\n",
      "2020-10-21 15:54:13,694 - INFO - Epoch [ 80/100] - Batch [  9600/ 29640] (32%) - Loss 0.4997\n",
      "2020-10-21 15:55:22,463 - INFO - Epoch [ 80/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3900\n",
      "2020-10-21 15:56:31,510 - INFO - Epoch [ 80/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4507\n",
      "2020-10-21 15:57:40,525 - INFO - Epoch [ 80/100] - Batch [ 14400/ 29640] (49%) - Loss 0.2082\n",
      "2020-10-21 15:58:49,223 - INFO - Epoch [ 80/100] - Batch [ 16000/ 29640] (54%) - Loss 0.6503\n",
      "2020-10-21 15:59:57,784 - INFO - Epoch [ 80/100] - Batch [ 17600/ 29640] (59%) - Loss 0.3728\n",
      "2020-10-21 16:01:06,787 - INFO - Epoch [ 80/100] - Batch [ 19200/ 29640] (65%) - Loss 0.6822\n",
      "2020-10-21 16:02:15,645 - INFO - Epoch [ 80/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5458\n",
      "2020-10-21 16:03:23,977 - INFO - Epoch [ 80/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4061\n",
      "2020-10-21 16:04:32,384 - INFO - Epoch [ 80/100] - Batch [ 24000/ 29640] (81%) - Loss 0.3558\n",
      "2020-10-21 16:05:41,077 - INFO - Epoch [ 80/100] - Batch [ 25600/ 29640] (86%) - Loss 0.3314\n",
      "2020-10-21 16:06:49,417 - INFO - Epoch [ 80/100] - Batch [ 27200/ 29640] (92%) - Loss 0.4912\n",
      "2020-10-21 16:07:56,004 - INFO - Epoch [ 80/100] - Batch [ 28800/ 29640] (97%) - Loss 0.7835\n",
      "2020-10-21 16:08:30,741 - INFO - Current lr: 0.01\n",
      "2020-10-21 16:08:30,742 - INFO - train, Loss: 0.4883 Acc: 0.8000\n",
      "2020-10-21 16:08:39,249 - INFO - Epoch [ 80/100] - Batch [     0/  1483] ( 0%) - Loss 1.1232\n",
      "2020-10-21 16:09:13,669 - INFO - Current lr: 0.01\n",
      "2020-10-21 16:09:13,670 - INFO - valid, Loss: 0.9858 Acc: 0.5158\n",
      "0.5147108566463404\n",
      "2020-10-21 16:09:24,228 - INFO - Epoch [ 81/100] - Batch [     0/ 29640] ( 0%) - Loss 0.3724\n",
      "2020-10-21 16:10:37,494 - INFO - Epoch [ 81/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.4384\n",
      "2020-10-21 16:11:48,549 - INFO - Epoch [ 81/100] - Batch [  3200/ 29640] (11%) - Loss 0.8415\n",
      "2020-10-21 16:12:58,223 - INFO - Epoch [ 81/100] - Batch [  4800/ 29640] (16%) - Loss 0.4919\n",
      "2020-10-21 16:14:07,445 - INFO - Epoch [ 81/100] - Batch [  6400/ 29640] (22%) - Loss 0.4360\n",
      "2020-10-21 16:15:17,128 - INFO - Epoch [ 81/100] - Batch [  8000/ 29640] (27%) - Loss 0.5464\n",
      "2020-10-21 16:16:26,698 - INFO - Epoch [ 81/100] - Batch [  9600/ 29640] (32%) - Loss 0.3361\n",
      "2020-10-21 16:17:36,168 - INFO - Epoch [ 81/100] - Batch [ 11200/ 29640] (38%) - Loss 0.4169\n",
      "2020-10-21 16:18:45,467 - INFO - Epoch [ 81/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4616\n",
      "2020-10-21 16:19:55,057 - INFO - Epoch [ 81/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4803\n",
      "2020-10-21 16:21:04,926 - INFO - Epoch [ 81/100] - Batch [ 16000/ 29640] (54%) - Loss 0.3728\n",
      "2020-10-21 16:22:14,903 - INFO - Epoch [ 81/100] - Batch [ 17600/ 29640] (59%) - Loss 0.5459\n",
      "2020-10-21 16:23:24,532 - INFO - Epoch [ 81/100] - Batch [ 19200/ 29640] (65%) - Loss 0.3960\n",
      "2020-10-21 16:24:34,000 - INFO - Epoch [ 81/100] - Batch [ 20800/ 29640] (70%) - Loss 0.6517\n",
      "2020-10-21 16:25:43,888 - INFO - Epoch [ 81/100] - Batch [ 22400/ 29640] (76%) - Loss 0.6003\n",
      "2020-10-21 16:26:53,628 - INFO - Epoch [ 81/100] - Batch [ 24000/ 29640] (81%) - Loss 0.7296\n",
      "2020-10-21 16:28:03,157 - INFO - Epoch [ 81/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4867\n",
      "2020-10-21 16:29:11,706 - INFO - Epoch [ 81/100] - Batch [ 27200/ 29640] (92%) - Loss 0.4174\n",
      "2020-10-21 16:30:19,016 - INFO - Epoch [ 81/100] - Batch [ 28800/ 29640] (97%) - Loss 0.4625\n",
      "2020-10-21 16:30:54,383 - INFO - Current lr: 0.01\n",
      "2020-10-21 16:30:54,384 - INFO - train, Loss: 0.4874 Acc: 0.8000\n",
      "2020-10-21 16:31:02,680 - INFO - Epoch [ 81/100] - Batch [     0/  1483] ( 0%) - Loss 3.2666\n",
      "2020-10-21 16:31:37,856 - INFO - Current lr: 0.01\n",
      "2020-10-21 16:31:37,858 - INFO - valid, Loss: 2.3378 Acc: 0.5152\n",
      "0.5140986552276874\n",
      "2020-10-21 16:31:50,389 - INFO - Epoch [ 82/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4501\n",
      "2020-10-21 16:33:01,178 - INFO - Epoch [ 82/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.4065\n",
      "2020-10-21 16:34:10,408 - INFO - Epoch [ 82/100] - Batch [  3200/ 29640] (11%) - Loss 0.4163\n",
      "2020-10-21 16:35:19,474 - INFO - Epoch [ 82/100] - Batch [  4800/ 29640] (16%) - Loss 0.8125\n",
      "2020-10-21 16:36:28,473 - INFO - Epoch [ 82/100] - Batch [  6400/ 29640] (22%) - Loss 0.6007\n",
      "2020-10-21 16:37:37,685 - INFO - Epoch [ 82/100] - Batch [  8000/ 29640] (27%) - Loss 0.2238\n",
      "2020-10-21 16:38:46,552 - INFO - Epoch [ 82/100] - Batch [  9600/ 29640] (32%) - Loss 0.2772\n",
      "2020-10-21 16:39:55,148 - INFO - Epoch [ 82/100] - Batch [ 11200/ 29640] (38%) - Loss 0.4686\n",
      "2020-10-21 16:41:04,225 - INFO - Epoch [ 82/100] - Batch [ 12800/ 29640] (43%) - Loss 0.2981\n",
      "2020-10-21 16:42:13,404 - INFO - Epoch [ 82/100] - Batch [ 14400/ 29640] (49%) - Loss 0.2762\n",
      "2020-10-21 16:43:22,335 - INFO - Epoch [ 82/100] - Batch [ 16000/ 29640] (54%) - Loss 0.3704\n",
      "2020-10-21 16:44:31,228 - INFO - Epoch [ 82/100] - Batch [ 17600/ 29640] (59%) - Loss 0.4032\n",
      "2020-10-21 16:45:40,282 - INFO - Epoch [ 82/100] - Batch [ 19200/ 29640] (65%) - Loss 0.3887\n",
      "2020-10-21 16:46:49,482 - INFO - Epoch [ 82/100] - Batch [ 20800/ 29640] (70%) - Loss 0.6807\n",
      "2020-10-21 16:47:58,317 - INFO - Epoch [ 82/100] - Batch [ 22400/ 29640] (76%) - Loss 0.7067\n",
      "2020-10-21 16:49:06,963 - INFO - Epoch [ 82/100] - Batch [ 24000/ 29640] (81%) - Loss 0.3077\n",
      "2020-10-21 16:50:15,915 - INFO - Epoch [ 82/100] - Batch [ 25600/ 29640] (86%) - Loss 0.5303\n",
      "2020-10-21 16:51:24,447 - INFO - Epoch [ 82/100] - Batch [ 27200/ 29640] (92%) - Loss 0.6989\n",
      "2020-10-21 16:52:31,418 - INFO - Epoch [ 82/100] - Batch [ 28800/ 29640] (97%) - Loss 0.7422\n",
      "2020-10-21 16:53:06,224 - INFO - Current lr: 0.01\n",
      "2020-10-21 16:53:06,226 - INFO - train, Loss: 0.4885 Acc: 0.8000\n",
      "2020-10-21 16:53:13,713 - INFO - Epoch [ 82/100] - Batch [     0/  1483] ( 0%) - Loss 0.7966\n",
      "2020-10-21 16:53:48,906 - INFO - Current lr: 0.01\n",
      "2020-10-21 16:53:48,907 - INFO - valid, Loss: 0.7804 Acc: 0.5185\n",
      "0.5189818544657258\n",
      "2020-10-21 16:54:02,929 - INFO - Epoch [ 83/100] - Batch [     0/ 29640] ( 0%) - Loss 0.6330\n",
      "2020-10-21 16:55:14,639 - INFO - Epoch [ 83/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.5735\n",
      "2020-10-21 16:56:25,074 - INFO - Epoch [ 83/100] - Batch [  3200/ 29640] (11%) - Loss 0.5135\n",
      "2020-10-21 16:57:34,881 - INFO - Epoch [ 83/100] - Batch [  4800/ 29640] (16%) - Loss 0.7663\n",
      "2020-10-21 16:58:44,319 - INFO - Epoch [ 83/100] - Batch [  6400/ 29640] (22%) - Loss 0.6378\n",
      "2020-10-21 16:59:54,444 - INFO - Epoch [ 83/100] - Batch [  8000/ 29640] (27%) - Loss 0.3017\n",
      "2020-10-21 17:01:04,562 - INFO - Epoch [ 83/100] - Batch [  9600/ 29640] (32%) - Loss 0.2108\n",
      "2020-10-21 17:02:14,874 - INFO - Epoch [ 83/100] - Batch [ 11200/ 29640] (38%) - Loss 0.2886\n",
      "2020-10-21 17:03:24,635 - INFO - Epoch [ 83/100] - Batch [ 12800/ 29640] (43%) - Loss 0.3469\n",
      "2020-10-21 17:04:34,157 - INFO - Epoch [ 83/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4326\n",
      "2020-10-21 17:05:43,900 - INFO - Epoch [ 83/100] - Batch [ 16000/ 29640] (54%) - Loss 0.4139\n",
      "2020-10-21 17:06:53,956 - INFO - Epoch [ 83/100] - Batch [ 17600/ 29640] (59%) - Loss 0.7767\n",
      "2020-10-21 17:08:04,040 - INFO - Epoch [ 83/100] - Batch [ 19200/ 29640] (65%) - Loss 0.6558\n",
      "2020-10-21 17:09:13,815 - INFO - Epoch [ 83/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5236\n",
      "2020-10-21 17:10:23,802 - INFO - Epoch [ 83/100] - Batch [ 22400/ 29640] (76%) - Loss 0.7290\n",
      "2020-10-21 17:11:33,842 - INFO - Epoch [ 83/100] - Batch [ 24000/ 29640] (81%) - Loss 0.3919\n",
      "2020-10-21 17:12:43,837 - INFO - Epoch [ 83/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4677\n",
      "2020-10-21 17:13:52,703 - INFO - Epoch [ 83/100] - Batch [ 27200/ 29640] (92%) - Loss 0.4949\n",
      "2020-10-21 17:15:00,199 - INFO - Epoch [ 83/100] - Batch [ 28800/ 29640] (97%) - Loss 0.5477\n",
      "2020-10-21 17:15:35,619 - INFO - Current lr: 0.01\n",
      "2020-10-21 17:15:35,621 - INFO - train, Loss: 0.4885 Acc: 0.8000\n",
      "2020-10-21 17:15:43,903 - INFO - Epoch [ 83/100] - Batch [     0/  1483] ( 0%) - Loss 0.6500\n",
      "2020-10-21 17:16:18,668 - INFO - Current lr: 0.01\n",
      "2020-10-21 17:16:18,670 - INFO - valid, Loss: 0.7896 Acc: 0.5307\n",
      "0.5311482722773045\n",
      "2020-10-21 17:16:29,740 - INFO - Epoch [ 84/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4905\n",
      "2020-10-21 17:17:43,130 - INFO - Epoch [ 84/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.4638\n",
      "2020-10-21 17:18:53,535 - INFO - Epoch [ 84/100] - Batch [  3200/ 29640] (11%) - Loss 0.2380\n",
      "2020-10-21 17:20:03,814 - INFO - Epoch [ 84/100] - Batch [  4800/ 29640] (16%) - Loss 0.3165\n",
      "2020-10-21 17:21:14,139 - INFO - Epoch [ 84/100] - Batch [  6400/ 29640] (22%) - Loss 0.5518\n",
      "2020-10-21 17:22:24,506 - INFO - Epoch [ 84/100] - Batch [  8000/ 29640] (27%) - Loss 0.4226\n",
      "2020-10-21 17:23:34,576 - INFO - Epoch [ 84/100] - Batch [  9600/ 29640] (32%) - Loss 0.5276\n",
      "2020-10-21 17:24:44,353 - INFO - Epoch [ 84/100] - Batch [ 11200/ 29640] (38%) - Loss 0.7663\n",
      "2020-10-21 17:25:54,555 - INFO - Epoch [ 84/100] - Batch [ 12800/ 29640] (43%) - Loss 0.6483\n",
      "2020-10-21 17:27:04,689 - INFO - Epoch [ 84/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4686\n",
      "2020-10-21 17:28:14,620 - INFO - Epoch [ 84/100] - Batch [ 16000/ 29640] (54%) - Loss 0.2424\n",
      "2020-10-21 17:29:24,502 - INFO - Epoch [ 84/100] - Batch [ 17600/ 29640] (59%) - Loss 0.9346\n",
      "2020-10-21 17:30:34,515 - INFO - Epoch [ 84/100] - Batch [ 19200/ 29640] (65%) - Loss 0.6423\n",
      "2020-10-21 17:31:44,638 - INFO - Epoch [ 84/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5039\n",
      "2020-10-21 17:32:54,274 - INFO - Epoch [ 84/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5425\n",
      "2020-10-21 17:34:03,837 - INFO - Epoch [ 84/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4670\n",
      "2020-10-21 17:35:13,624 - INFO - Epoch [ 84/100] - Batch [ 25600/ 29640] (86%) - Loss 0.5859\n",
      "2020-10-21 17:36:22,753 - INFO - Epoch [ 84/100] - Batch [ 27200/ 29640] (92%) - Loss 0.6794\n",
      "2020-10-21 17:37:29,971 - INFO - Epoch [ 84/100] - Batch [ 28800/ 29640] (97%) - Loss 0.3399\n",
      "2020-10-21 17:38:04,816 - INFO - Current lr: 0.01\n",
      "2020-10-21 17:38:04,817 - INFO - train, Loss: 0.4873 Acc: 0.8000\n",
      "2020-10-21 17:38:12,592 - INFO - Epoch [ 84/100] - Batch [     0/  1483] ( 0%) - Loss 1.1547\n",
      "2020-10-21 17:38:46,943 - INFO - Current lr: 0.01\n",
      "2020-10-21 17:38:46,944 - INFO - valid, Loss: 1.0080 Acc: 0.5152\n",
      "0.5157000108613012\n",
      "2020-10-21 17:38:46,945 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 17:38:57,610 - INFO - Epoch [ 85/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4171\n",
      "2020-10-21 17:40:10,263 - INFO - Epoch [ 85/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.7176\n",
      "2020-10-21 17:41:20,476 - INFO - Epoch [ 85/100] - Batch [  3200/ 29640] (11%) - Loss 0.5655\n",
      "2020-10-21 17:42:30,736 - INFO - Epoch [ 85/100] - Batch [  4800/ 29640] (16%) - Loss 0.5817\n",
      "2020-10-21 17:43:40,807 - INFO - Epoch [ 85/100] - Batch [  6400/ 29640] (22%) - Loss 0.5343\n",
      "2020-10-21 17:44:50,383 - INFO - Epoch [ 85/100] - Batch [  8000/ 29640] (27%) - Loss 0.4979\n",
      "2020-10-21 17:46:00,641 - INFO - Epoch [ 85/100] - Batch [  9600/ 29640] (32%) - Loss 0.6339\n",
      "2020-10-21 17:47:10,898 - INFO - Epoch [ 85/100] - Batch [ 11200/ 29640] (38%) - Loss 0.6896\n",
      "2020-10-21 17:48:20,449 - INFO - Epoch [ 85/100] - Batch [ 12800/ 29640] (43%) - Loss 0.2808\n",
      "2020-10-21 17:49:29,862 - INFO - Epoch [ 85/100] - Batch [ 14400/ 29640] (49%) - Loss 0.3789\n",
      "2020-10-21 17:50:39,253 - INFO - Epoch [ 85/100] - Batch [ 16000/ 29640] (54%) - Loss 0.5682\n",
      "2020-10-21 17:51:49,191 - INFO - Epoch [ 85/100] - Batch [ 17600/ 29640] (59%) - Loss 0.5210\n",
      "2020-10-21 17:52:58,531 - INFO - Epoch [ 85/100] - Batch [ 19200/ 29640] (65%) - Loss 0.2943\n",
      "2020-10-21 17:54:07,927 - INFO - Epoch [ 85/100] - Batch [ 20800/ 29640] (70%) - Loss 0.3325\n",
      "2020-10-21 17:55:17,680 - INFO - Epoch [ 85/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5681\n",
      "2020-10-21 17:56:27,300 - INFO - Epoch [ 85/100] - Batch [ 24000/ 29640] (81%) - Loss 0.2642\n",
      "2020-10-21 17:57:36,961 - INFO - Epoch [ 85/100] - Batch [ 25600/ 29640] (86%) - Loss 0.8052\n",
      "2020-10-21 17:58:45,952 - INFO - Epoch [ 85/100] - Batch [ 27200/ 29640] (92%) - Loss 0.5481\n",
      "2020-10-21 17:59:53,265 - INFO - Epoch [ 85/100] - Batch [ 28800/ 29640] (97%) - Loss 0.4526\n",
      "2020-10-21 18:00:28,438 - INFO - Current lr: 0.01\n",
      "2020-10-21 18:00:28,439 - INFO - train, Loss: 0.4882 Acc: 0.8000\n",
      "2020-10-21 18:00:39,363 - INFO - Epoch [ 85/100] - Batch [     0/  1483] ( 0%) - Loss 0.7895\n",
      "2020-10-21 18:01:11,139 - INFO - Current lr: 0.01\n",
      "2020-10-21 18:01:11,140 - INFO - valid, Loss: 0.9214 Acc: 0.5084\n",
      "0.5086058952994437\n",
      "2020-10-21 18:01:11,141 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 18:01:24,494 - INFO - Epoch [ 86/100] - Batch [     0/ 29640] ( 0%) - Loss 0.7088\n",
      "2020-10-21 18:02:36,707 - INFO - Epoch [ 86/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.3926\n",
      "2020-10-21 18:03:46,517 - INFO - Epoch [ 86/100] - Batch [  3200/ 29640] (11%) - Loss 0.3957\n",
      "2020-10-21 18:04:56,284 - INFO - Epoch [ 86/100] - Batch [  4800/ 29640] (16%) - Loss 0.7702\n",
      "2020-10-21 18:06:05,980 - INFO - Epoch [ 86/100] - Batch [  6400/ 29640] (22%) - Loss 0.4673\n",
      "2020-10-21 18:07:15,968 - INFO - Epoch [ 86/100] - Batch [  8000/ 29640] (27%) - Loss 0.4301\n",
      "2020-10-21 18:08:25,758 - INFO - Epoch [ 86/100] - Batch [  9600/ 29640] (32%) - Loss 0.5494\n",
      "2020-10-21 18:09:35,414 - INFO - Epoch [ 86/100] - Batch [ 11200/ 29640] (38%) - Loss 0.6815\n",
      "2020-10-21 18:10:44,944 - INFO - Epoch [ 86/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4029\n",
      "2020-10-21 18:11:55,106 - INFO - Epoch [ 86/100] - Batch [ 14400/ 29640] (49%) - Loss 0.3940\n",
      "2020-10-21 18:13:04,800 - INFO - Epoch [ 86/100] - Batch [ 16000/ 29640] (54%) - Loss 0.4508\n",
      "2020-10-21 18:14:14,575 - INFO - Epoch [ 86/100] - Batch [ 17600/ 29640] (59%) - Loss 0.6004\n",
      "2020-10-21 18:15:24,095 - INFO - Epoch [ 86/100] - Batch [ 19200/ 29640] (65%) - Loss 0.3401\n",
      "2020-10-21 18:16:33,897 - INFO - Epoch [ 86/100] - Batch [ 20800/ 29640] (70%) - Loss 0.4841\n",
      "2020-10-21 18:17:43,573 - INFO - Epoch [ 86/100] - Batch [ 22400/ 29640] (76%) - Loss 0.3079\n",
      "2020-10-21 18:18:52,981 - INFO - Epoch [ 86/100] - Batch [ 24000/ 29640] (81%) - Loss 0.3232\n",
      "2020-10-21 18:20:02,266 - INFO - Epoch [ 86/100] - Batch [ 25600/ 29640] (86%) - Loss 0.5959\n",
      "2020-10-21 18:21:11,034 - INFO - Epoch [ 86/100] - Batch [ 27200/ 29640] (92%) - Loss 0.6411\n",
      "2020-10-21 18:22:19,023 - INFO - Epoch [ 86/100] - Batch [ 28800/ 29640] (97%) - Loss 0.3402\n",
      "2020-10-21 18:22:54,096 - INFO - Current lr: 0.01\n",
      "2020-10-21 18:22:54,097 - INFO - train, Loss: 0.4877 Acc: 0.8000\n",
      "2020-10-21 18:23:02,139 - INFO - Epoch [ 86/100] - Batch [     0/  1483] ( 0%) - Loss 1.0141\n",
      "2020-10-21 18:23:37,059 - INFO - Current lr: 0.01\n",
      "2020-10-21 18:23:37,061 - INFO - valid, Loss: 1.3773 Acc: 0.5017\n",
      "0.5009856630824373\n",
      "2020-10-21 18:23:37,062 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 18:23:49,404 - INFO - Epoch [ 87/100] - Batch [     0/ 29640] ( 0%) - Loss 0.3867\n",
      "2020-10-21 18:25:00,008 - INFO - Epoch [ 87/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.6475\n",
      "2020-10-21 18:26:09,399 - INFO - Epoch [ 87/100] - Batch [  3200/ 29640] (11%) - Loss 0.4095\n",
      "2020-10-21 18:27:18,466 - INFO - Epoch [ 87/100] - Batch [  4800/ 29640] (16%) - Loss 0.1694\n",
      "2020-10-21 18:28:27,503 - INFO - Epoch [ 87/100] - Batch [  6400/ 29640] (22%) - Loss 0.4447\n",
      "2020-10-21 18:29:36,418 - INFO - Epoch [ 87/100] - Batch [  8000/ 29640] (27%) - Loss 0.5744\n",
      "2020-10-21 18:30:45,408 - INFO - Epoch [ 87/100] - Batch [  9600/ 29640] (32%) - Loss 0.4495\n",
      "2020-10-21 18:31:54,923 - INFO - Epoch [ 87/100] - Batch [ 11200/ 29640] (38%) - Loss 0.4566\n",
      "2020-10-21 18:33:03,409 - INFO - Epoch [ 87/100] - Batch [ 12800/ 29640] (43%) - Loss 0.5388\n",
      "2020-10-21 18:34:11,712 - INFO - Epoch [ 87/100] - Batch [ 14400/ 29640] (49%) - Loss 0.6151\n",
      "2020-10-21 18:35:20,383 - INFO - Epoch [ 87/100] - Batch [ 16000/ 29640] (54%) - Loss 0.4455\n",
      "2020-10-21 18:36:29,616 - INFO - Epoch [ 87/100] - Batch [ 17600/ 29640] (59%) - Loss 0.2450\n",
      "2020-10-21 18:37:38,823 - INFO - Epoch [ 87/100] - Batch [ 19200/ 29640] (65%) - Loss 0.4341\n",
      "2020-10-21 18:38:47,996 - INFO - Epoch [ 87/100] - Batch [ 20800/ 29640] (70%) - Loss 0.1905\n",
      "2020-10-21 18:39:56,641 - INFO - Epoch [ 87/100] - Batch [ 22400/ 29640] (76%) - Loss 0.6501\n",
      "2020-10-21 18:41:05,727 - INFO - Epoch [ 87/100] - Batch [ 24000/ 29640] (81%) - Loss 0.5535\n",
      "2020-10-21 18:42:14,639 - INFO - Epoch [ 87/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4603\n",
      "2020-10-21 18:43:22,783 - INFO - Epoch [ 87/100] - Batch [ 27200/ 29640] (92%) - Loss 0.2719\n",
      "2020-10-21 18:44:29,943 - INFO - Epoch [ 87/100] - Batch [ 28800/ 29640] (97%) - Loss 0.4044\n",
      "2020-10-21 18:45:05,014 - INFO - Current lr: 0.01\n",
      "2020-10-21 18:45:05,016 - INFO - train, Loss: 0.4876 Acc: 0.8000\n",
      "2020-10-21 18:45:12,848 - INFO - Epoch [ 87/100] - Batch [     0/  1483] ( 0%) - Loss 0.8928\n",
      "2020-10-21 18:45:47,447 - INFO - Current lr: 0.01\n",
      "2020-10-21 18:45:47,449 - INFO - valid, Loss: 1.5686 Acc: 0.5030\n",
      "0.5026307623081817\n",
      "2020-10-21 18:45:47,450 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 18:45:58,384 - INFO - Epoch [ 88/100] - Batch [     0/ 29640] ( 0%) - Loss 0.6618\n",
      "2020-10-21 18:47:12,412 - INFO - Epoch [ 88/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.6948\n",
      "2020-10-21 18:48:23,874 - INFO - Epoch [ 88/100] - Batch [  3200/ 29640] (11%) - Loss 0.3768\n",
      "2020-10-21 18:49:35,230 - INFO - Epoch [ 88/100] - Batch [  4800/ 29640] (16%) - Loss 0.5050\n",
      "2020-10-21 18:50:46,829 - INFO - Epoch [ 88/100] - Batch [  6400/ 29640] (22%) - Loss 0.2599\n",
      "2020-10-21 18:51:57,832 - INFO - Epoch [ 88/100] - Batch [  8000/ 29640] (27%) - Loss 0.4502\n",
      "2020-10-21 18:53:07,797 - INFO - Epoch [ 88/100] - Batch [  9600/ 29640] (32%) - Loss 0.4372\n",
      "2020-10-21 18:54:18,160 - INFO - Epoch [ 88/100] - Batch [ 11200/ 29640] (38%) - Loss 0.4861\n",
      "2020-10-21 18:55:28,132 - INFO - Epoch [ 88/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4254\n",
      "2020-10-21 18:56:38,172 - INFO - Epoch [ 88/100] - Batch [ 14400/ 29640] (49%) - Loss 0.6200\n",
      "2020-10-21 18:57:48,096 - INFO - Epoch [ 88/100] - Batch [ 16000/ 29640] (54%) - Loss 0.7478\n",
      "2020-10-21 18:58:57,829 - INFO - Epoch [ 88/100] - Batch [ 17600/ 29640] (59%) - Loss 0.4201\n",
      "2020-10-21 19:00:07,866 - INFO - Epoch [ 88/100] - Batch [ 19200/ 29640] (65%) - Loss 0.4199\n",
      "2020-10-21 19:01:18,059 - INFO - Epoch [ 88/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5416\n",
      "2020-10-21 19:02:27,761 - INFO - Epoch [ 88/100] - Batch [ 22400/ 29640] (76%) - Loss 0.6156\n",
      "2020-10-21 19:03:37,415 - INFO - Epoch [ 88/100] - Batch [ 24000/ 29640] (81%) - Loss 0.3607\n",
      "2020-10-21 19:04:46,907 - INFO - Epoch [ 88/100] - Batch [ 25600/ 29640] (86%) - Loss 0.5451\n",
      "2020-10-21 19:05:55,716 - INFO - Epoch [ 88/100] - Batch [ 27200/ 29640] (92%) - Loss 0.5979\n",
      "2020-10-21 19:07:03,818 - INFO - Epoch [ 88/100] - Batch [ 28800/ 29640] (97%) - Loss 0.4929\n",
      "2020-10-21 19:07:39,039 - INFO - Current lr: 0.01\n",
      "2020-10-21 19:07:39,040 - INFO - train, Loss: 0.4858 Acc: 0.8000\n",
      "2020-10-21 19:07:47,400 - INFO - Epoch [ 88/100] - Batch [     0/  1483] ( 0%) - Loss 1.0769\n",
      "2020-10-21 19:08:21,830 - INFO - Current lr: 0.01\n",
      "2020-10-21 19:08:21,831 - INFO - valid, Loss: 1.0345 Acc: 0.5010\n",
      "0.5003580350354545\n",
      "2020-10-21 19:08:21,832 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 19:08:35,632 - INFO - Epoch [ 89/100] - Batch [     0/ 29640] ( 0%) - Loss 0.5062\n",
      "2020-10-21 19:09:47,221 - INFO - Epoch [ 89/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.2906\n",
      "2020-10-21 19:10:57,373 - INFO - Epoch [ 89/100] - Batch [  3200/ 29640] (11%) - Loss 0.9640\n",
      "2020-10-21 19:12:07,690 - INFO - Epoch [ 89/100] - Batch [  4800/ 29640] (16%) - Loss 0.5887\n",
      "2020-10-21 19:13:17,366 - INFO - Epoch [ 89/100] - Batch [  6400/ 29640] (22%) - Loss 0.4554\n",
      "2020-10-21 19:14:27,353 - INFO - Epoch [ 89/100] - Batch [  8000/ 29640] (27%) - Loss 0.5083\n",
      "2020-10-21 19:15:37,109 - INFO - Epoch [ 89/100] - Batch [  9600/ 29640] (32%) - Loss 0.5411\n",
      "2020-10-21 19:16:46,807 - INFO - Epoch [ 89/100] - Batch [ 11200/ 29640] (38%) - Loss 0.6194\n",
      "2020-10-21 19:17:56,264 - INFO - Epoch [ 89/100] - Batch [ 12800/ 29640] (43%) - Loss 0.7138\n",
      "2020-10-21 19:19:05,889 - INFO - Epoch [ 89/100] - Batch [ 14400/ 29640] (49%) - Loss 0.6131\n",
      "2020-10-21 19:20:15,512 - INFO - Epoch [ 89/100] - Batch [ 16000/ 29640] (54%) - Loss 0.4081\n",
      "2020-10-21 19:21:25,484 - INFO - Epoch [ 89/100] - Batch [ 17600/ 29640] (59%) - Loss 0.7307\n",
      "2020-10-21 19:22:35,281 - INFO - Epoch [ 89/100] - Batch [ 19200/ 29640] (65%) - Loss 0.7441\n",
      "2020-10-21 19:23:44,912 - INFO - Epoch [ 89/100] - Batch [ 20800/ 29640] (70%) - Loss 0.4079\n",
      "2020-10-21 19:24:54,312 - INFO - Epoch [ 89/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4723\n",
      "2020-10-21 19:26:04,260 - INFO - Epoch [ 89/100] - Batch [ 24000/ 29640] (81%) - Loss 0.5372\n",
      "2020-10-21 19:27:14,046 - INFO - Epoch [ 89/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4130\n",
      "2020-10-21 19:28:22,754 - INFO - Epoch [ 89/100] - Batch [ 27200/ 29640] (92%) - Loss 0.6707\n",
      "2020-10-21 19:29:30,149 - INFO - Epoch [ 89/100] - Batch [ 28800/ 29640] (97%) - Loss 0.6344\n",
      "2020-10-21 19:30:05,403 - INFO - Current lr: 0.01\n",
      "2020-10-21 19:30:05,405 - INFO - train, Loss: 0.4860 Acc: 0.8000\n",
      "2020-10-21 19:30:13,749 - INFO - Epoch [ 89/100] - Batch [     0/  1483] ( 0%) - Loss 0.6857\n",
      "2020-10-21 19:30:48,382 - INFO - Current lr: 0.01\n",
      "2020-10-21 19:30:48,383 - INFO - valid, Loss: 0.9439 Acc: 0.5192\n",
      "0.5184234224556807\n",
      "2020-10-21 19:30:59,388 - INFO - Epoch [ 90/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4522\n",
      "2020-10-21 19:32:11,994 - INFO - Epoch [ 90/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.5153\n",
      "2020-10-21 19:33:21,431 - INFO - Epoch [ 90/100] - Batch [  3200/ 29640] (11%) - Loss 0.6320\n",
      "2020-10-21 19:34:31,134 - INFO - Epoch [ 90/100] - Batch [  4800/ 29640] (16%) - Loss 0.2919\n",
      "2020-10-21 19:35:41,002 - INFO - Epoch [ 90/100] - Batch [  6400/ 29640] (22%) - Loss 0.2875\n",
      "2020-10-21 19:36:50,804 - INFO - Epoch [ 90/100] - Batch [  8000/ 29640] (27%) - Loss 0.5097\n",
      "2020-10-21 19:38:00,703 - INFO - Epoch [ 90/100] - Batch [  9600/ 29640] (32%) - Loss 0.5127\n",
      "2020-10-21 19:39:10,456 - INFO - Epoch [ 90/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3177\n",
      "2020-10-21 19:40:20,197 - INFO - Epoch [ 90/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4894\n",
      "2020-10-21 19:41:29,962 - INFO - Epoch [ 90/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4122\n",
      "2020-10-21 19:42:39,355 - INFO - Epoch [ 90/100] - Batch [ 16000/ 29640] (54%) - Loss 0.5852\n",
      "2020-10-21 19:43:48,404 - INFO - Epoch [ 90/100] - Batch [ 17600/ 29640] (59%) - Loss 0.4389\n",
      "2020-10-21 19:44:57,879 - INFO - Epoch [ 90/100] - Batch [ 19200/ 29640] (65%) - Loss 0.5469\n",
      "2020-10-21 19:46:07,397 - INFO - Epoch [ 90/100] - Batch [ 20800/ 29640] (70%) - Loss 0.2890\n",
      "2020-10-21 19:47:17,133 - INFO - Epoch [ 90/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5456\n",
      "2020-10-21 19:48:26,280 - INFO - Epoch [ 90/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4665\n",
      "2020-10-21 19:49:35,561 - INFO - Epoch [ 90/100] - Batch [ 25600/ 29640] (86%) - Loss 0.5402\n",
      "2020-10-21 19:50:43,783 - INFO - Epoch [ 90/100] - Batch [ 27200/ 29640] (92%) - Loss 0.3494\n",
      "2020-10-21 19:51:51,222 - INFO - Epoch [ 90/100] - Batch [ 28800/ 29640] (97%) - Loss 0.5702\n",
      "2020-10-21 19:52:26,278 - INFO - Current lr: 0.01\n",
      "2020-10-21 19:52:26,280 - INFO - train, Loss: 0.4859 Acc: 0.8000\n",
      "2020-10-21 19:52:34,566 - INFO - Epoch [ 90/100] - Batch [     0/  1483] ( 0%) - Loss 0.9179\n",
      "2020-10-21 19:53:08,078 - INFO - Current lr: 0.01\n",
      "2020-10-21 19:53:08,084 - INFO - valid, Loss: 0.8772 Acc: 0.5044\n",
      "0.5037620235200881\n",
      "2020-10-21 19:53:08,085 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 19:53:18,672 - INFO - Epoch [ 91/100] - Batch [     0/ 29640] ( 0%) - Loss 0.3927\n",
      "2020-10-21 19:54:31,718 - INFO - Epoch [ 91/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.4728\n",
      "2020-10-21 19:55:41,526 - INFO - Epoch [ 91/100] - Batch [  3200/ 29640] (11%) - Loss 0.4760\n",
      "2020-10-21 19:56:51,838 - INFO - Epoch [ 91/100] - Batch [  4800/ 29640] (16%) - Loss 0.6208\n",
      "2020-10-21 19:58:01,715 - INFO - Epoch [ 91/100] - Batch [  6400/ 29640] (22%) - Loss 0.2299\n",
      "2020-10-21 19:59:11,674 - INFO - Epoch [ 91/100] - Batch [  8000/ 29640] (27%) - Loss 0.2832\n",
      "2020-10-21 20:00:21,461 - INFO - Epoch [ 91/100] - Batch [  9600/ 29640] (32%) - Loss 0.4083\n",
      "2020-10-21 20:01:31,430 - INFO - Epoch [ 91/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3676\n",
      "2020-10-21 20:02:41,203 - INFO - Epoch [ 91/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4446\n",
      "2020-10-21 20:03:50,747 - INFO - Epoch [ 91/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4973\n",
      "2020-10-21 20:05:00,423 - INFO - Epoch [ 91/100] - Batch [ 16000/ 29640] (54%) - Loss 0.5073\n",
      "2020-10-21 20:06:10,744 - INFO - Epoch [ 91/100] - Batch [ 17600/ 29640] (59%) - Loss 0.5016\n",
      "2020-10-21 20:07:20,370 - INFO - Epoch [ 91/100] - Batch [ 19200/ 29640] (65%) - Loss 0.4549\n",
      "2020-10-21 20:08:29,497 - INFO - Epoch [ 91/100] - Batch [ 20800/ 29640] (70%) - Loss 0.3903\n",
      "2020-10-21 20:09:38,965 - INFO - Epoch [ 91/100] - Batch [ 22400/ 29640] (76%) - Loss 0.8202\n",
      "2020-10-21 20:10:48,646 - INFO - Epoch [ 91/100] - Batch [ 24000/ 29640] (81%) - Loss 0.4744\n",
      "2020-10-21 20:11:58,267 - INFO - Epoch [ 91/100] - Batch [ 25600/ 29640] (86%) - Loss 0.3345\n",
      "2020-10-21 20:13:07,072 - INFO - Epoch [ 91/100] - Batch [ 27200/ 29640] (92%) - Loss 0.4652\n",
      "2020-10-21 20:14:14,418 - INFO - Epoch [ 91/100] - Batch [ 28800/ 29640] (97%) - Loss 0.3675\n",
      "2020-10-21 20:14:49,506 - INFO - Current lr: 0.01\n",
      "2020-10-21 20:14:49,508 - INFO - train, Loss: 0.4870 Acc: 0.8000\n",
      "2020-10-21 20:14:57,640 - INFO - Epoch [ 91/100] - Batch [     0/  1483] ( 0%) - Loss 2.1546\n",
      "2020-10-21 20:15:33,508 - INFO - Current lr: 0.01\n",
      "2020-10-21 20:15:33,509 - INFO - valid, Loss: 1.0935 Acc: 0.5071\n",
      "0.5059696426631911\n",
      "2020-10-21 20:15:33,510 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 20:15:44,456 - INFO - Epoch [ 92/100] - Batch [     0/ 29640] ( 0%) - Loss 0.6061\n",
      "2020-10-21 20:16:57,704 - INFO - Epoch [ 92/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.2465\n",
      "2020-10-21 20:18:08,040 - INFO - Epoch [ 92/100] - Batch [  3200/ 29640] (11%) - Loss 0.4124\n",
      "2020-10-21 20:19:17,604 - INFO - Epoch [ 92/100] - Batch [  4800/ 29640] (16%) - Loss 0.3676\n",
      "2020-10-21 20:20:27,461 - INFO - Epoch [ 92/100] - Batch [  6400/ 29640] (22%) - Loss 0.2591\n",
      "2020-10-21 20:21:37,269 - INFO - Epoch [ 92/100] - Batch [  8000/ 29640] (27%) - Loss 0.2579\n",
      "2020-10-21 20:22:47,189 - INFO - Epoch [ 92/100] - Batch [  9600/ 29640] (32%) - Loss 0.5042\n",
      "2020-10-21 20:23:56,552 - INFO - Epoch [ 92/100] - Batch [ 11200/ 29640] (38%) - Loss 0.5451\n",
      "2020-10-21 20:25:05,953 - INFO - Epoch [ 92/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4896\n",
      "2020-10-21 20:26:15,264 - INFO - Epoch [ 92/100] - Batch [ 14400/ 29640] (49%) - Loss 0.5620\n",
      "2020-10-21 20:27:24,799 - INFO - Epoch [ 92/100] - Batch [ 16000/ 29640] (54%) - Loss 0.2809\n",
      "2020-10-21 20:28:34,115 - INFO - Epoch [ 92/100] - Batch [ 17600/ 29640] (59%) - Loss 0.4565\n",
      "2020-10-21 20:29:43,278 - INFO - Epoch [ 92/100] - Batch [ 19200/ 29640] (65%) - Loss 0.5174\n",
      "2020-10-21 20:30:52,816 - INFO - Epoch [ 92/100] - Batch [ 20800/ 29640] (70%) - Loss 0.2744\n",
      "2020-10-21 20:32:03,042 - INFO - Epoch [ 92/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4559\n",
      "2020-10-21 20:33:12,887 - INFO - Epoch [ 92/100] - Batch [ 24000/ 29640] (81%) - Loss 0.2590\n",
      "2020-10-21 20:34:22,445 - INFO - Epoch [ 92/100] - Batch [ 25600/ 29640] (86%) - Loss 0.5741\n",
      "2020-10-21 20:35:31,520 - INFO - Epoch [ 92/100] - Batch [ 27200/ 29640] (92%) - Loss 0.4961\n",
      "2020-10-21 20:36:39,189 - INFO - Epoch [ 92/100] - Batch [ 28800/ 29640] (97%) - Loss 0.6114\n",
      "2020-10-21 20:37:14,562 - INFO - Current lr: 0.01\n",
      "2020-10-21 20:37:14,563 - INFO - train, Loss: 0.4845 Acc: 0.8000\n",
      "2020-10-21 20:37:22,899 - INFO - Epoch [ 92/100] - Batch [     0/  1483] ( 0%) - Loss 0.6246\n",
      "2020-10-21 20:37:58,032 - INFO - Current lr: 0.01\n",
      "2020-10-21 20:37:58,033 - INFO - valid, Loss: 0.8753 Acc: 0.5536\n",
      "0.5555634926602667\n",
      "2020-10-21 20:38:08,890 - INFO - Epoch [ 93/100] - Batch [     0/ 29640] ( 0%) - Loss 0.3866\n",
      "2020-10-21 20:39:20,918 - INFO - Epoch [ 93/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.5558\n",
      "2020-10-21 20:40:30,719 - INFO - Epoch [ 93/100] - Batch [  3200/ 29640] (11%) - Loss 0.6488\n",
      "2020-10-21 20:41:40,504 - INFO - Epoch [ 93/100] - Batch [  4800/ 29640] (16%) - Loss 0.6755\n",
      "2020-10-21 20:42:50,039 - INFO - Epoch [ 93/100] - Batch [  6400/ 29640] (22%) - Loss 0.2692\n",
      "2020-10-21 20:43:59,113 - INFO - Epoch [ 93/100] - Batch [  8000/ 29640] (27%) - Loss 0.6171\n",
      "2020-10-21 20:45:08,037 - INFO - Epoch [ 93/100] - Batch [  9600/ 29640] (32%) - Loss 0.6409\n",
      "2020-10-21 20:46:17,538 - INFO - Epoch [ 93/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3971\n",
      "2020-10-21 20:47:27,175 - INFO - Epoch [ 93/100] - Batch [ 12800/ 29640] (43%) - Loss 0.3024\n",
      "2020-10-21 20:48:36,291 - INFO - Epoch [ 93/100] - Batch [ 14400/ 29640] (49%) - Loss 0.2930\n",
      "2020-10-21 20:49:46,000 - INFO - Epoch [ 93/100] - Batch [ 16000/ 29640] (54%) - Loss 0.3225\n",
      "2020-10-21 20:50:55,551 - INFO - Epoch [ 93/100] - Batch [ 17600/ 29640] (59%) - Loss 0.3756\n",
      "2020-10-21 20:52:04,850 - INFO - Epoch [ 93/100] - Batch [ 19200/ 29640] (65%) - Loss 0.3227\n",
      "2020-10-21 20:53:13,987 - INFO - Epoch [ 93/100] - Batch [ 20800/ 29640] (70%) - Loss 0.4638\n",
      "2020-10-21 20:54:22,978 - INFO - Epoch [ 93/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4181\n",
      "2020-10-21 20:55:32,162 - INFO - Epoch [ 93/100] - Batch [ 24000/ 29640] (81%) - Loss 0.5208\n",
      "2020-10-21 20:56:41,208 - INFO - Epoch [ 93/100] - Batch [ 25600/ 29640] (86%) - Loss 0.5268\n",
      "2020-10-21 20:57:49,567 - INFO - Epoch [ 93/100] - Batch [ 27200/ 29640] (92%) - Loss 0.6506\n",
      "2020-10-21 20:58:56,389 - INFO - Epoch [ 93/100] - Batch [ 28800/ 29640] (97%) - Loss 0.4451\n",
      "2020-10-21 20:59:31,462 - INFO - Current lr: 0.01\n",
      "2020-10-21 20:59:31,464 - INFO - train, Loss: 0.4849 Acc: 0.8000\n",
      "2020-10-21 20:59:39,600 - INFO - Epoch [ 93/100] - Batch [     0/  1483] ( 0%) - Loss 4.9175\n",
      "2020-10-21 21:00:13,509 - INFO - Current lr: 0.01\n",
      "2020-10-21 21:00:13,510 - INFO - valid, Loss: 5.4049 Acc: 0.5003\n",
      "0.5\n",
      "2020-10-21 21:00:13,511 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 21:00:24,064 - INFO - Epoch [ 94/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4807\n",
      "2020-10-21 21:01:36,856 - INFO - Epoch [ 94/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.4417\n",
      "2020-10-21 21:02:46,100 - INFO - Epoch [ 94/100] - Batch [  3200/ 29640] (11%) - Loss 0.6023\n",
      "2020-10-21 21:03:55,477 - INFO - Epoch [ 94/100] - Batch [  4800/ 29640] (16%) - Loss 0.2982\n",
      "2020-10-21 21:05:04,792 - INFO - Epoch [ 94/100] - Batch [  6400/ 29640] (22%) - Loss 0.5238\n",
      "2020-10-21 21:06:13,921 - INFO - Epoch [ 94/100] - Batch [  8000/ 29640] (27%) - Loss 0.5041\n",
      "2020-10-21 21:07:22,744 - INFO - Epoch [ 94/100] - Batch [  9600/ 29640] (32%) - Loss 0.4742\n",
      "2020-10-21 21:08:31,169 - INFO - Epoch [ 94/100] - Batch [ 11200/ 29640] (38%) - Loss 0.5824\n",
      "2020-10-21 21:09:39,979 - INFO - Epoch [ 94/100] - Batch [ 12800/ 29640] (43%) - Loss 0.4576\n",
      "2020-10-21 21:10:49,118 - INFO - Epoch [ 94/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4280\n",
      "2020-10-21 21:11:58,268 - INFO - Epoch [ 94/100] - Batch [ 16000/ 29640] (54%) - Loss 0.2601\n",
      "2020-10-21 21:13:07,207 - INFO - Epoch [ 94/100] - Batch [ 17600/ 29640] (59%) - Loss 0.6558\n",
      "2020-10-21 21:14:15,415 - INFO - Epoch [ 94/100] - Batch [ 19200/ 29640] (65%) - Loss 0.3264\n",
      "2020-10-21 21:15:24,117 - INFO - Epoch [ 94/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5639\n",
      "2020-10-21 21:16:33,232 - INFO - Epoch [ 94/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5607\n",
      "2020-10-21 21:17:42,936 - INFO - Epoch [ 94/100] - Batch [ 24000/ 29640] (81%) - Loss 0.5064\n",
      "2020-10-21 21:18:52,612 - INFO - Epoch [ 94/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4157\n",
      "2020-10-21 21:20:02,119 - INFO - Epoch [ 94/100] - Batch [ 27200/ 29640] (92%) - Loss 0.5738\n",
      "2020-10-21 21:21:10,106 - INFO - Epoch [ 94/100] - Batch [ 28800/ 29640] (97%) - Loss 0.5479\n",
      "2020-10-21 21:21:45,640 - INFO - Current lr: 0.01\n",
      "2020-10-21 21:21:45,642 - INFO - train, Loss: 0.4857 Acc: 0.8000\n",
      "2020-10-21 21:21:54,259 - INFO - Epoch [ 94/100] - Batch [     0/  1483] ( 0%) - Loss 0.9842\n",
      "2020-10-21 21:22:28,254 - INFO - Current lr: 0.01\n",
      "2020-10-21 21:22:28,256 - INFO - valid, Loss: 0.9173 Acc: 0.5091\n",
      "0.5083438664083826\n",
      "2020-10-21 21:22:28,256 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 21:22:42,757 - INFO - Epoch [ 95/100] - Batch [     0/ 29640] ( 0%) - Loss 0.1921\n",
      "2020-10-21 21:23:54,003 - INFO - Epoch [ 95/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.5703\n",
      "2020-10-21 21:25:03,486 - INFO - Epoch [ 95/100] - Batch [  3200/ 29640] (11%) - Loss 0.5783\n",
      "2020-10-21 21:26:13,495 - INFO - Epoch [ 95/100] - Batch [  4800/ 29640] (16%) - Loss 0.3867\n",
      "2020-10-21 21:27:23,373 - INFO - Epoch [ 95/100] - Batch [  6400/ 29640] (22%) - Loss 0.5827\n",
      "2020-10-21 21:28:32,780 - INFO - Epoch [ 95/100] - Batch [  8000/ 29640] (27%) - Loss 0.3511\n",
      "2020-10-21 21:29:42,440 - INFO - Epoch [ 95/100] - Batch [  9600/ 29640] (32%) - Loss 0.4594\n",
      "2020-10-21 21:30:52,200 - INFO - Epoch [ 95/100] - Batch [ 11200/ 29640] (38%) - Loss 0.4319\n",
      "2020-10-21 21:32:01,904 - INFO - Epoch [ 95/100] - Batch [ 12800/ 29640] (43%) - Loss 0.6320\n",
      "2020-10-21 21:33:11,434 - INFO - Epoch [ 95/100] - Batch [ 14400/ 29640] (49%) - Loss 0.5697\n",
      "2020-10-21 21:34:21,030 - INFO - Epoch [ 95/100] - Batch [ 16000/ 29640] (54%) - Loss 0.5001\n",
      "2020-10-21 21:35:30,677 - INFO - Epoch [ 95/100] - Batch [ 17600/ 29640] (59%) - Loss 0.4477\n",
      "2020-10-21 21:36:40,392 - INFO - Epoch [ 95/100] - Batch [ 19200/ 29640] (65%) - Loss 0.5371\n",
      "2020-10-21 21:37:49,909 - INFO - Epoch [ 95/100] - Batch [ 20800/ 29640] (70%) - Loss 0.3800\n",
      "2020-10-21 21:38:59,235 - INFO - Epoch [ 95/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4439\n",
      "2020-10-21 21:40:08,550 - INFO - Epoch [ 95/100] - Batch [ 24000/ 29640] (81%) - Loss 0.3636\n",
      "2020-10-21 21:41:18,132 - INFO - Epoch [ 95/100] - Batch [ 25600/ 29640] (86%) - Loss 0.3855\n",
      "2020-10-21 21:42:26,486 - INFO - Epoch [ 95/100] - Batch [ 27200/ 29640] (92%) - Loss 0.4734\n",
      "2020-10-21 21:43:33,339 - INFO - Epoch [ 95/100] - Batch [ 28800/ 29640] (97%) - Loss 0.3980\n",
      "2020-10-21 21:44:08,289 - INFO - Current lr: 0.01\n",
      "2020-10-21 21:44:08,291 - INFO - train, Loss: 0.4851 Acc: 0.8000\n",
      "2020-10-21 21:44:16,755 - INFO - Epoch [ 95/100] - Batch [     0/  1483] ( 0%) - Loss 3.0582\n",
      "2020-10-21 21:44:51,786 - INFO - Current lr: 0.01\n",
      "2020-10-21 21:44:51,788 - INFO - valid, Loss: 2.0505 Acc: 0.5017\n",
      "0.5018433179723503\n",
      "2020-10-21 21:44:51,789 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 21:45:02,124 - INFO - Epoch [ 96/100] - Batch [     0/ 29640] ( 0%) - Loss 0.6795\n",
      "2020-10-21 21:46:15,523 - INFO - Epoch [ 96/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.6904\n",
      "2020-10-21 21:47:24,981 - INFO - Epoch [ 96/100] - Batch [  3200/ 29640] (11%) - Loss 0.4561\n",
      "2020-10-21 21:48:34,054 - INFO - Epoch [ 96/100] - Batch [  4800/ 29640] (16%) - Loss 0.4841\n",
      "2020-10-21 21:49:43,035 - INFO - Epoch [ 96/100] - Batch [  6400/ 29640] (22%) - Loss 0.4933\n",
      "2020-10-21 21:50:52,137 - INFO - Epoch [ 96/100] - Batch [  8000/ 29640] (27%) - Loss 0.5542\n",
      "2020-10-21 21:52:01,951 - INFO - Epoch [ 96/100] - Batch [  9600/ 29640] (32%) - Loss 0.5438\n",
      "2020-10-21 21:53:11,900 - INFO - Epoch [ 96/100] - Batch [ 11200/ 29640] (38%) - Loss 0.2592\n",
      "2020-10-21 21:54:21,921 - INFO - Epoch [ 96/100] - Batch [ 12800/ 29640] (43%) - Loss 0.5957\n",
      "2020-10-21 21:55:32,135 - INFO - Epoch [ 96/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4918\n",
      "2020-10-21 21:56:42,760 - INFO - Epoch [ 96/100] - Batch [ 16000/ 29640] (54%) - Loss 0.6568\n",
      "2020-10-21 21:57:52,099 - INFO - Epoch [ 96/100] - Batch [ 17600/ 29640] (59%) - Loss 0.5597\n",
      "2020-10-21 21:59:00,718 - INFO - Epoch [ 96/100] - Batch [ 19200/ 29640] (65%) - Loss 0.5601\n",
      "2020-10-21 22:00:09,662 - INFO - Epoch [ 96/100] - Batch [ 20800/ 29640] (70%) - Loss 0.2669\n",
      "2020-10-21 22:01:19,159 - INFO - Epoch [ 96/100] - Batch [ 22400/ 29640] (76%) - Loss 0.4975\n",
      "2020-10-21 22:02:29,038 - INFO - Epoch [ 96/100] - Batch [ 24000/ 29640] (81%) - Loss 0.1330\n",
      "2020-10-21 22:03:38,825 - INFO - Epoch [ 96/100] - Batch [ 25600/ 29640] (86%) - Loss 0.5375\n",
      "2020-10-21 22:04:48,119 - INFO - Epoch [ 96/100] - Batch [ 27200/ 29640] (92%) - Loss 0.7581\n",
      "2020-10-21 22:05:56,287 - INFO - Epoch [ 96/100] - Batch [ 28800/ 29640] (97%) - Loss 0.3237\n",
      "2020-10-21 22:06:31,967 - INFO - Current lr: 0.01\n",
      "2020-10-21 22:06:31,969 - INFO - train, Loss: 0.4848 Acc: 0.8000\n",
      "2020-10-21 22:06:40,660 - INFO - Epoch [ 96/100] - Batch [     0/  1483] ( 0%) - Loss 2.2699\n",
      "2020-10-21 22:07:15,406 - INFO - Current lr: 0.01\n",
      "2020-10-21 22:07:15,407 - INFO - valid, Loss: 4.6676 Acc: 0.5003\n",
      "0.5\n",
      "2020-10-21 22:07:15,408 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 22:07:26,075 - INFO - Epoch [ 97/100] - Batch [     0/ 29640] ( 0%) - Loss 0.5126\n",
      "2020-10-21 22:08:41,062 - INFO - Epoch [ 97/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.3126\n",
      "2020-10-21 22:09:52,662 - INFO - Epoch [ 97/100] - Batch [  3200/ 29640] (11%) - Loss 0.6455\n",
      "2020-10-21 22:11:04,925 - INFO - Epoch [ 97/100] - Batch [  4800/ 29640] (16%) - Loss 0.2398\n",
      "2020-10-21 22:12:15,888 - INFO - Epoch [ 97/100] - Batch [  6400/ 29640] (22%) - Loss 0.4597\n",
      "2020-10-21 22:13:25,706 - INFO - Epoch [ 97/100] - Batch [  8000/ 29640] (27%) - Loss 0.4454\n",
      "2020-10-21 22:14:35,333 - INFO - Epoch [ 97/100] - Batch [  9600/ 29640] (32%) - Loss 0.4313\n",
      "2020-10-21 22:15:44,875 - INFO - Epoch [ 97/100] - Batch [ 11200/ 29640] (38%) - Loss 0.5348\n",
      "2020-10-21 22:16:54,733 - INFO - Epoch [ 97/100] - Batch [ 12800/ 29640] (43%) - Loss 0.2998\n",
      "2020-10-21 22:18:04,099 - INFO - Epoch [ 97/100] - Batch [ 14400/ 29640] (49%) - Loss 0.6282\n",
      "2020-10-21 22:19:13,260 - INFO - Epoch [ 97/100] - Batch [ 16000/ 29640] (54%) - Loss 0.6136\n",
      "2020-10-21 22:20:22,527 - INFO - Epoch [ 97/100] - Batch [ 17600/ 29640] (59%) - Loss 0.3184\n",
      "2020-10-21 22:21:32,159 - INFO - Epoch [ 97/100] - Batch [ 19200/ 29640] (65%) - Loss 0.3318\n",
      "2020-10-21 22:22:41,341 - INFO - Epoch [ 97/100] - Batch [ 20800/ 29640] (70%) - Loss 0.7494\n",
      "2020-10-21 22:23:50,346 - INFO - Epoch [ 97/100] - Batch [ 22400/ 29640] (76%) - Loss 0.2975\n",
      "2020-10-21 22:24:59,027 - INFO - Epoch [ 97/100] - Batch [ 24000/ 29640] (81%) - Loss 0.2916\n",
      "2020-10-21 22:26:08,238 - INFO - Epoch [ 97/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4341\n",
      "2020-10-21 22:27:16,661 - INFO - Epoch [ 97/100] - Batch [ 27200/ 29640] (92%) - Loss 0.5011\n",
      "2020-10-21 22:28:23,759 - INFO - Epoch [ 97/100] - Batch [ 28800/ 29640] (97%) - Loss 0.6442\n",
      "2020-10-21 22:28:58,755 - INFO - Current lr: 0.01\n",
      "2020-10-21 22:28:58,756 - INFO - train, Loss: 0.4824 Acc: 0.8000\n",
      "2020-10-21 22:29:07,029 - INFO - Epoch [ 97/100] - Batch [     0/  1483] ( 0%) - Loss 3.5979\n",
      "2020-10-21 22:29:41,748 - INFO - Current lr: 0.01\n",
      "2020-10-21 22:29:41,750 - INFO - valid, Loss: 6.9753 Acc: 0.5003\n",
      "0.5\n",
      "2020-10-21 22:29:41,751 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 22:29:52,153 - INFO - Epoch [ 98/100] - Batch [     0/ 29640] ( 0%) - Loss 0.3194\n",
      "2020-10-21 22:31:04,110 - INFO - Epoch [ 98/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.5087\n",
      "2020-10-21 22:32:13,197 - INFO - Epoch [ 98/100] - Batch [  3200/ 29640] (11%) - Loss 0.4563\n",
      "2020-10-21 22:33:22,246 - INFO - Epoch [ 98/100] - Batch [  4800/ 29640] (16%) - Loss 0.4820\n",
      "2020-10-21 22:34:31,265 - INFO - Epoch [ 98/100] - Batch [  6400/ 29640] (22%) - Loss 0.2752\n",
      "2020-10-21 22:35:40,153 - INFO - Epoch [ 98/100] - Batch [  8000/ 29640] (27%) - Loss 0.4153\n",
      "2020-10-21 22:36:49,244 - INFO - Epoch [ 98/100] - Batch [  9600/ 29640] (32%) - Loss 0.4424\n",
      "2020-10-21 22:37:57,743 - INFO - Epoch [ 98/100] - Batch [ 11200/ 29640] (38%) - Loss 0.5937\n",
      "2020-10-21 22:39:06,265 - INFO - Epoch [ 98/100] - Batch [ 12800/ 29640] (43%) - Loss 0.5170\n",
      "2020-10-21 22:40:15,214 - INFO - Epoch [ 98/100] - Batch [ 14400/ 29640] (49%) - Loss 0.4988\n",
      "2020-10-21 22:41:23,533 - INFO - Epoch [ 98/100] - Batch [ 16000/ 29640] (54%) - Loss 0.4722\n",
      "2020-10-21 22:42:32,437 - INFO - Epoch [ 98/100] - Batch [ 17600/ 29640] (59%) - Loss 0.6149\n",
      "2020-10-21 22:43:40,779 - INFO - Epoch [ 98/100] - Batch [ 19200/ 29640] (65%) - Loss 0.5442\n",
      "2020-10-21 22:44:49,368 - INFO - Epoch [ 98/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5893\n",
      "2020-10-21 22:45:58,209 - INFO - Epoch [ 98/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5036\n",
      "2020-10-21 22:47:06,815 - INFO - Epoch [ 98/100] - Batch [ 24000/ 29640] (81%) - Loss 0.3900\n",
      "2020-10-21 22:48:15,803 - INFO - Epoch [ 98/100] - Batch [ 25600/ 29640] (86%) - Loss 0.4300\n",
      "2020-10-21 22:49:23,648 - INFO - Epoch [ 98/100] - Batch [ 27200/ 29640] (92%) - Loss 0.4163\n",
      "2020-10-21 22:50:30,476 - INFO - Epoch [ 98/100] - Batch [ 28800/ 29640] (97%) - Loss 0.6765\n",
      "2020-10-21 22:51:05,535 - INFO - Current lr: 0.01\n",
      "2020-10-21 22:51:05,537 - INFO - train, Loss: 0.4845 Acc: 0.8000\n",
      "2020-10-21 22:51:14,137 - INFO - Epoch [ 98/100] - Batch [     0/  1483] ( 0%) - Loss 1.1997\n",
      "2020-10-21 22:51:48,354 - INFO - Current lr: 0.01\n",
      "2020-10-21 22:51:48,355 - INFO - valid, Loss: 2.9677 Acc: 0.5084\n",
      "0.515292130211485\n",
      "2020-10-21 22:51:48,356 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 22:51:58,470 - INFO - Epoch [ 99/100] - Batch [     0/ 29640] ( 0%) - Loss 0.4627\n",
      "2020-10-21 22:53:12,614 - INFO - Epoch [ 99/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.7614\n",
      "2020-10-21 22:54:22,422 - INFO - Epoch [ 99/100] - Batch [  3200/ 29640] (11%) - Loss 0.5503\n",
      "2020-10-21 22:55:32,031 - INFO - Epoch [ 99/100] - Batch [  4800/ 29640] (16%) - Loss 0.4011\n",
      "2020-10-21 22:56:41,777 - INFO - Epoch [ 99/100] - Batch [  6400/ 29640] (22%) - Loss 0.6251\n",
      "2020-10-21 22:57:51,201 - INFO - Epoch [ 99/100] - Batch [  8000/ 29640] (27%) - Loss 0.2156\n",
      "2020-10-21 22:59:00,551 - INFO - Epoch [ 99/100] - Batch [  9600/ 29640] (32%) - Loss 0.2842\n",
      "2020-10-21 23:00:09,819 - INFO - Epoch [ 99/100] - Batch [ 11200/ 29640] (38%) - Loss 0.3823\n",
      "2020-10-21 23:01:18,963 - INFO - Epoch [ 99/100] - Batch [ 12800/ 29640] (43%) - Loss 0.5906\n",
      "2020-10-21 23:02:28,152 - INFO - Epoch [ 99/100] - Batch [ 14400/ 29640] (49%) - Loss 0.3815\n",
      "2020-10-21 23:03:37,043 - INFO - Epoch [ 99/100] - Batch [ 16000/ 29640] (54%) - Loss 0.7043\n",
      "2020-10-21 23:04:45,919 - INFO - Epoch [ 99/100] - Batch [ 17600/ 29640] (59%) - Loss 0.7259\n",
      "2020-10-21 23:05:55,102 - INFO - Epoch [ 99/100] - Batch [ 19200/ 29640] (65%) - Loss 0.3673\n",
      "2020-10-21 23:07:04,526 - INFO - Epoch [ 99/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5331\n",
      "2020-10-21 23:08:13,870 - INFO - Epoch [ 99/100] - Batch [ 22400/ 29640] (76%) - Loss 0.5198\n",
      "2020-10-21 23:09:23,203 - INFO - Epoch [ 99/100] - Batch [ 24000/ 29640] (81%) - Loss 0.5799\n",
      "2020-10-21 23:10:32,660 - INFO - Epoch [ 99/100] - Batch [ 25600/ 29640] (86%) - Loss 0.6764\n",
      "2020-10-21 23:11:41,503 - INFO - Epoch [ 99/100] - Batch [ 27200/ 29640] (92%) - Loss 0.3090\n",
      "2020-10-21 23:12:48,680 - INFO - Epoch [ 99/100] - Batch [ 28800/ 29640] (97%) - Loss 0.6087\n",
      "2020-10-21 23:13:23,789 - INFO - Current lr: 0.01\n",
      "2020-10-21 23:13:23,792 - INFO - train, Loss: 0.4844 Acc: 0.8000\n",
      "2020-10-21 23:13:32,764 - INFO - Epoch [ 99/100] - Batch [     0/  1483] ( 0%) - Loss 1.5038\n",
      "2020-10-21 23:14:07,393 - INFO - Current lr: 0.01\n",
      "2020-10-21 23:14:07,395 - INFO - valid, Loss: 2.4201 Acc: 0.4997\n",
      "0.4994026284348865\n",
      "2020-10-21 23:14:07,396 - INFO - Fine-tune accuracy has not improved by 0.5% in the last 5 epochs\n",
      "2020-10-21 23:14:17,977 - INFO - Epoch [100/100] - Batch [     0/ 29640] ( 0%) - Loss 0.7175\n",
      "2020-10-21 23:15:31,618 - INFO - Epoch [100/100] - Batch [  1600/ 29640] ( 5%) - Loss 0.4850\n",
      "2020-10-21 23:16:41,978 - INFO - Epoch [100/100] - Batch [  3200/ 29640] (11%) - Loss 0.5185\n",
      "2020-10-21 23:17:52,298 - INFO - Epoch [100/100] - Batch [  4800/ 29640] (16%) - Loss 0.7315\n",
      "2020-10-21 23:19:02,470 - INFO - Epoch [100/100] - Batch [  6400/ 29640] (22%) - Loss 0.7465\n",
      "2020-10-21 23:20:12,494 - INFO - Epoch [100/100] - Batch [  8000/ 29640] (27%) - Loss 0.4882\n",
      "2020-10-21 23:21:22,556 - INFO - Epoch [100/100] - Batch [  9600/ 29640] (32%) - Loss 0.3937\n",
      "2020-10-21 23:22:32,446 - INFO - Epoch [100/100] - Batch [ 11200/ 29640] (38%) - Loss 0.5792\n",
      "2020-10-21 23:23:42,225 - INFO - Epoch [100/100] - Batch [ 12800/ 29640] (43%) - Loss 0.6967\n",
      "2020-10-21 23:24:52,127 - INFO - Epoch [100/100] - Batch [ 14400/ 29640] (49%) - Loss 0.5182\n",
      "2020-10-21 23:26:01,967 - INFO - Epoch [100/100] - Batch [ 16000/ 29640] (54%) - Loss 0.5128\n",
      "2020-10-21 23:27:11,925 - INFO - Epoch [100/100] - Batch [ 17600/ 29640] (59%) - Loss 0.6778\n",
      "2020-10-21 23:28:21,361 - INFO - Epoch [100/100] - Batch [ 19200/ 29640] (65%) - Loss 0.4101\n",
      "2020-10-21 23:29:31,188 - INFO - Epoch [100/100] - Batch [ 20800/ 29640] (70%) - Loss 0.5161\n",
      "2020-10-21 23:30:40,944 - INFO - Epoch [100/100] - Batch [ 22400/ 29640] (76%) - Loss 0.7360\n",
      "2020-10-21 23:31:50,972 - INFO - Epoch [100/100] - Batch [ 24000/ 29640] (81%) - Loss 0.3344\n",
      "2020-10-21 23:33:00,597 - INFO - Epoch [100/100] - Batch [ 25600/ 29640] (86%) - Loss 0.5221\n",
      "2020-10-21 23:34:09,179 - INFO - Epoch [100/100] - Batch [ 27200/ 29640] (92%) - Loss 0.2849\n",
      "2020-10-21 23:35:16,634 - INFO - Epoch [100/100] - Batch [ 28800/ 29640] (97%) - Loss 0.6140\n",
      "2020-10-21 23:35:51,988 - INFO - Current lr: 0.01\n",
      "2020-10-21 23:35:51,989 - INFO - train, Loss: 0.4847 Acc: 0.7999\n",
      "2020-10-21 23:36:00,855 - INFO - Epoch [100/100] - Batch [     0/  1483] ( 0%) - Loss 3.3896\n",
      "2020-10-21 23:36:35,097 - INFO - Current lr: 0.01\n",
      "2020-10-21 23:36:35,098 - INFO - valid, Loss: 1.4160 Acc: 0.5125\n",
      "0.5148747459231329\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = models.inception_v3(pretrained=is_pretrained, aux_logits=False)\n",
    "logger.info(f\"Model loading            = {model.__class__.__name__}\")\n",
    "\n",
    "# Get number of features in the model\n",
    "n_ftrs = model.fc.in_features\n",
    "logger.info(f\"Model number of features = {n_ftrs}\")\n",
    "\n",
    "# Add linear transformation to the data\n",
    "model.fc = nn.Linear(n_ftrs, len(dataset[\"train\"].classes))\n",
    "\n",
    "######################################################################################\n",
    "# Send model to device, \n",
    "# if CUDA count is greater than 1 use multiple GPUs\n",
    "model = model.to(device)\n",
    "usable_devices =list(range(torch.cuda.device_count()))\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model, device_ids=usable_devices, output_device=device)\n",
    "    logger.info(f\"Let's use {torch.cuda.device_count()} GPUs!\")\n",
    "\n",
    "######################################################################################\n",
    "# Get Optimization and crossentropy\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "######################################################################################\n",
    "results = train_validation_phase(model=model,\n",
    "                               dataset=dataset,\n",
    "                               dataloader = dataloader,\n",
    "                               device=device,\n",
    "                               epochs=epochs,\n",
    "                               criterion=criterion,\n",
    "                               optimizer=optimizer,\n",
    "                               save = model_pth,\n",
    "                               logger=logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results to a pickle file\n",
    "with open(f\"output/{name}_results_copy.pkl\", \"wb\") as RESULTS:\n",
    "    pickle.dump(results, RESULTS, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
